<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>20 Mitmetasemelised mudelid | Bayesi statistika kasutades R keelt</title>
  <meta name="description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs R keeles’ Bayesi statistika materjalid." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="20 Mitmetasemelised mudelid | Bayesi statistika kasutades R keelt" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cyclo.png" />
  <meta property="og:description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs R keeles’ Bayesi statistika materjalid." />
  <meta name="github-repo" content="rstats-tartu/bayesiraamat" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="20 Mitmetasemelised mudelid | Bayesi statistika kasutades R keelt" />
  
  <meta name="twitter:description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs R keeles’ Bayesi statistika materjalid." />
  <meta name="twitter:image" content="img/cyclo.png" />

<meta name="author" content="Taavi Päll" />
<meta name="author" content="Ülo Maiväli" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="keerulisemate-mudelitega-tootamine.html">
<link rel="next" href="brms.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.1/grViz.js"></script>

<script src="https://use.fontawesome.com/e4ba4259a1.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesi statistika kasutades R keelt</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Saateks</a></li>
<li class="part"><span><b>I OSA</b></span></li>
<li class="chapter" data-level="1" data-path="sissejuhatus-maailm-teooria-ja-mudel.html"><a href="sissejuhatus-maailm-teooria-ja-mudel.html"><i class="fa fa-check"></i><b>1</b> Sissejuhatus: maailm, teooria ja mudel</a><ul>
<li class="chapter" data-level="" data-path="sissejuhatus-maailm-teooria-ja-mudel.html"><a href="sissejuhatus-maailm-teooria-ja-mudel.html#suur-ja-vaike-maailm"><i class="fa fa-check"></i>Suur ja väike maailm</a></li>
<li class="chapter" data-level="" data-path="sissejuhatus-maailm-teooria-ja-mudel.html"><a href="sissejuhatus-maailm-teooria-ja-mudel.html#mudeli-vaike-maailm"><i class="fa fa-check"></i>Mudeli väike maailm</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="kusimused-mida-statistika-kusib.html"><a href="kusimused-mida-statistika-kusib.html"><i class="fa fa-check"></i><b>2</b> Küsimused, mida statistika küsib</a><ul>
<li class="chapter" data-level="" data-path="kusimused-mida-statistika-kusib.html"><a href="kusimused-mida-statistika-kusib.html#jata-meelde"><i class="fa fa-check"></i>Jäta meelde</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html"><i class="fa fa-check"></i><b>3</b> Kuidas näevad välja teie andmed</a><ul>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#summaarsed-statistikud"><i class="fa fa-check"></i>Summaarsed statistikud</a></li>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#keskvaartused"><i class="fa fa-check"></i>Keskväärtused</a></li>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#muutuja-sisene-varieeruvus"><i class="fa fa-check"></i>Muutuja sisene varieeruvus</a></li>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#logaritmi-andmed"><i class="fa fa-check"></i>Logaritmi andmed</a></li>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#iseloomusta-andmeid-algses-skaalas-mediaan-mad"><i class="fa fa-check"></i>Iseloomusta andmeid algses skaalas: mediaan (MAD)</a></li>
<li class="chapter" data-level="" data-path="kuidas-naevad-valja-teie-andmed.html"><a href="kuidas-naevad-valja-teie-andmed.html#muutujate-koosvarieeruvus"><i class="fa fa-check"></i>Muutujate koosvarieeruvus</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html"><i class="fa fa-check"></i><b>4</b> Lineaarsed mudelid</a><ul>
<li class="chapter" data-level="4.1" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#sirge-vorrand"><i class="fa fa-check"></i><b>4.1</b> Sirge võrrand</a></li>
<li class="chapter" data-level="4.2" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#ennustus-lineaarsest-mudelist"><i class="fa fa-check"></i><b>4.2</b> Ennustus lineaarsest mudelist</a></li>
<li class="chapter" data-level="4.3" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#neli-moistet"><i class="fa fa-check"></i><b>4.3</b> Neli mõistet</a></li>
<li class="chapter" data-level="4.4" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#mudeli-fittimine"><i class="fa fa-check"></i><b>4.4</b> Mudeli fittimine</a><ul>
<li class="chapter" data-level="4.4.1" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#ule--ja-alafittimine"><i class="fa fa-check"></i><b>4.4.1</b> Üle- ja alafittimine</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#lineaarse-regressiooni-eeldused"><i class="fa fa-check"></i><b>4.5</b> Lineaarse regressiooni eeldused</a><ul>
<li class="chapter" data-level="" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#matemaatilised-eeldused"><i class="fa fa-check"></i>Matemaatilised eeldused:</a></li>
<li class="chapter" data-level="" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#eeldused-praktilise-tahtsuse-jarjekorras"><i class="fa fa-check"></i>Eeldused praktilise tähtsuse järjekorras:</a></li>
<li class="chapter" data-level="" data-path="lineaarsed-mudelid.html"><a href="lineaarsed-mudelid.html#regressioon-kui-kirjeldus-ja-kui-pohjuslik-hupotees"><i class="fa fa-check"></i>Regressioon kui kirjeldus ja kui põhjuslik hüpotees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="kaks-lineaarse-mudeli-laiendust.html"><a href="kaks-lineaarse-mudeli-laiendust.html"><i class="fa fa-check"></i><b>5</b> Kaks lineaarse mudeli laiendust</a><ul>
<li class="chapter" data-level="5.1" data-path="kaks-lineaarse-mudeli-laiendust.html"><a href="kaks-lineaarse-mudeli-laiendust.html#mitme-soltumatu-prediktoriga-mudel"><i class="fa fa-check"></i><b>5.1</b> Mitme sõltumatu prediktoriga mudel</a><ul>
<li class="chapter" data-level="" data-path="kaks-lineaarse-mudeli-laiendust.html"><a href="kaks-lineaarse-mudeli-laiendust.html#ennustused-soltumatute-prediktoritega-mudelist"><i class="fa fa-check"></i>Ennustused sõltumatute prediktoritega mudelist</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="kaks-lineaarse-mudeli-laiendust.html"><a href="kaks-lineaarse-mudeli-laiendust.html#interaktsioonimudel"><i class="fa fa-check"></i><b>5.2</b> Interaktsioonimudel</a><ul>
<li class="chapter" data-level="" data-path="kaks-lineaarse-mudeli-laiendust.html"><a href="kaks-lineaarse-mudeli-laiendust.html#ennustused-interaktsioonimudelist"><i class="fa fa-check"></i>Ennustused interaktsioonimudelist</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><i class="fa fa-check"></i><b>6</b> Vähimruutude meetodiga fititud mudelite töövoog – lm()</a><ul>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#vaatame-mudeli-koefitsiente"><i class="fa fa-check"></i>1. vaatame mudeli koefitsiente</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#testime-mudeli-eeldusi"><i class="fa fa-check"></i>2. Testime mudeli eeldusi</a><ul>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#lineaarsus---residuaalidfitted-plot"><i class="fa fa-check"></i>Lineaarsus - residuaalid~fitted plot</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#mojukuse-plot"><i class="fa fa-check"></i>Mõjukuse plot</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#residuaalide-normaalsus---qq-plot"><i class="fa fa-check"></i>Residuaalide normaalsus - qq plot</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#homoskedastilisus---scale-location-plot"><i class="fa fa-check"></i>Homoskedastilisus - Scale-location plot</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#residuaalid-y-ja-x-muutujate-vastu"><i class="fa fa-check"></i>Residuaalid y ja x muutujate vastu</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#teeme-mudeli-pohjal-ennustusi-marginal-plots"><i class="fa fa-check"></i>3. Teeme mudeli põhjal ennustusi (marginal plots)</a></li>
<li class="chapter" data-level="" data-path="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html"><a href="vahimruutude-meetodiga-fititud-mudelite-toovoog-lm.html#vordleme-mudeleid"><i class="fa fa-check"></i>4. Võrdleme mudeleid</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html"><i class="fa fa-check"></i><b>7</b> Andmete transformeerimine</a><ul>
<li class="chapter" data-level="7.1" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#logaritmimine"><i class="fa fa-check"></i><b>7.1</b> Logaritmimine</a><ul>
<li class="chapter" data-level="" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#miks-ja-millal-muutujaid-logaritmida"><i class="fa fa-check"></i>Miks ja millal muutujaid logaritmida</a></li>
<li class="chapter" data-level="" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#naturaallogaritmitud-andmetega-tootamine"><i class="fa fa-check"></i>Naturaallogaritmitud andmetega töötamine</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#standardiseerimine"><i class="fa fa-check"></i><b>7.2</b> Standardiseerimine</a><ul>
<li class="chapter" data-level="" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#korrelatsioon-ule-regressiooni-ja-regressioon-keskmisele"><i class="fa fa-check"></i>Korrelatsioon üle regressiooni ja regressioon keskmisele</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#tsentreerimine"><i class="fa fa-check"></i><b>7.3</b> Tsentreerimine</a></li>
<li class="chapter" data-level="7.4" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#mudeli-koefitsientide-transformeerimine"><i class="fa fa-check"></i><b>7.4</b> Mudeli koefitsientide transformeerimine</a></li>
<li class="chapter" data-level="7.5" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#pidev-voi-diskreetne-muutuja"><i class="fa fa-check"></i><b>7.5</b> Pidev või diskreetne muutuja?</a></li>
<li class="chapter" data-level="7.6" data-path="andmete-transformeerimine.html"><a href="andmete-transformeerimine.html#mitmese-regressiooni-uldised-printsiibid"><i class="fa fa-check"></i><b>7.6</b> mitmese regressiooni üldised printsiibid</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="veamudel.html"><a href="veamudel.html"><i class="fa fa-check"></i><b>8</b> Veamudel</a><ul>
<li class="chapter" data-level="8.1" data-path="veamudel.html"><a href="veamudel.html#lihtne-varieeruvuse-mudel"><i class="fa fa-check"></i><b>8.1</b> Lihtne varieeruvuse mudel</a></li>
<li class="chapter" data-level="8.2" data-path="veamudel.html"><a href="veamudel.html#protsessimudel-ja-varieeruvuse-mudel-lineaarses-regressioonis"><i class="fa fa-check"></i><b>8.2</b> protsessimudel ja varieeruvuse mudel lineaarses regressioonis</a></li>
<li class="chapter" data-level="" data-path="veamudel.html"><a href="veamudel.html#enimkasutatud-veamudel-on-normaaljaotus"><i class="fa fa-check"></i>Enimkasutatud veamudel on normaaljaotus</a><ul>
<li class="chapter" data-level="" data-path="veamudel.html"><a href="veamudel.html#normaaljaotuse-mudel-vaikestel-valimitel"><i class="fa fa-check"></i>Normaaljaotuse mudel väikestel valimitel</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="veamudel.html"><a href="veamudel.html#normaaljaotuse-ja-lognormaaljaotuse-erilisus"><i class="fa fa-check"></i>Normaaljaotuse ja lognormaaljaotuse erilisus</a><ul>
<li class="chapter" data-level="8.2.1" data-path="veamudel.html"><a href="veamudel.html#normaaljaotuse-ja-lognormaaljaotuse-vordlus"><i class="fa fa-check"></i><b>8.2.1</b> Normaaljaotuse ja lognormaaljaotuse võrdlus</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="veamudel.html"><a href="veamudel.html#teised-veamudelid"><i class="fa fa-check"></i><b>8.3</b> Teised veamudelid</a><ul>
<li class="chapter" data-level="8.3.1" data-path="veamudel.html"><a href="veamudel.html#lognormaaljaotus"><i class="fa fa-check"></i><b>8.3.1</b> Lognormaaljaotus</a></li>
<li class="chapter" data-level="8.3.2" data-path="veamudel.html"><a href="veamudel.html#binoomjaotus"><i class="fa fa-check"></i><b>8.3.2</b> Binoomjaotus</a></li>
<li class="chapter" data-level="8.3.3" data-path="veamudel.html"><a href="veamudel.html#poissoni-jaotus"><i class="fa fa-check"></i><b>8.3.3</b> Poissoni jaotus</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="eda-eksploratoorne-andmeanaluus.html"><a href="eda-eksploratoorne-andmeanaluus.html"><i class="fa fa-check"></i><b>9</b> EDA — eksploratoorne andmeanalüüs</a><ul>
<li class="chapter" data-level="9.1" data-path="eda-eksploratoorne-andmeanaluus.html"><a href="eda-eksploratoorne-andmeanaluus.html#eda-kokkuvote"><i class="fa fa-check"></i><b>9.1</b> EDA kokkuvõte</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html"><i class="fa fa-check"></i><b>10</b> Lausearvutuslik loogika</a><ul>
<li class="chapter" data-level="10.1" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#toetabel"><i class="fa fa-check"></i><b>10.1</b> Tõetabel</a></li>
<li class="chapter" data-level="10.2" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#konjunktsioon"><i class="fa fa-check"></i><b>10.2</b> Konjunktsioon</a></li>
<li class="chapter" data-level="10.3" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#disjunktsioon"><i class="fa fa-check"></i><b>10.3</b> Disjunktsioon</a></li>
<li class="chapter" data-level="10.4" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#konditsionaal"><i class="fa fa-check"></i><b>10.4</b> Konditsionaal</a></li>
<li class="chapter" data-level="10.5" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#tautoloogia-ja-kontradiktsioon"><i class="fa fa-check"></i><b>10.5</b> Tautoloogia ja kontradiktsioon</a></li>
<li class="chapter" data-level="10.6" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#loogiline-argument-ja-valiidne-jareldamine"><i class="fa fa-check"></i><b>10.6</b> loogiline argument ja valiidne järeldamine</a></li>
<li class="chapter" data-level="10.7" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#modus-ponens-ja-modus-tollens"><i class="fa fa-check"></i><b>10.7</b> Modus Ponens ja Modus Tollens</a></li>
<li class="chapter" data-level="10.8" data-path="lausearvutuslik-loogika.html"><a href="lausearvutuslik-loogika.html#lausearvutusest-toenaosuste-loogikasse"><i class="fa fa-check"></i><b>10.8</b> Lausearvutusest tõenäosuste loogikasse</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html"><i class="fa fa-check"></i><b>11</b> Järeldav statistika</a><ul>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#jareldav-statistika-on-toenaosusteooria-kaepikendus"><i class="fa fa-check"></i>Järeldav statistika on tõenäosusteooria käepikendus</a><ul>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#formaalsed-tuletised-toenaosusteooria-aksioomidest"><i class="fa fa-check"></i>Formaalsed tuletised tõenäosusteooria aksioomidest</a></li>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#naited-toenaosusteooria-tuletiste-rakendamisest"><i class="fa fa-check"></i>Näited tõenäosusteooria tuletiste rakendamisest</a></li>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#toenaosuse-episteemiline-tolgendus"><i class="fa fa-check"></i>Tõenäosuse episteemiline tõlgendus</a></li>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#toenaosusteooriast-tulenevad-statistika-pohiprintsiibid"><i class="fa fa-check"></i>Tõenäosusteooriast tulenevad statistika põhiprintsiibid</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#andmed-ei-ole-sama-mis-tegelikkus"><i class="fa fa-check"></i>Andmed ei ole sama, mis tegelikkus</a></li>
</ul></li>
<li class="part"><span><b>II OSA</b></span></li>
<li class="chapter" data-level="12" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>12</b> Bootstrap</a><ul>
<li class="chapter" data-level="12.1" data-path="bootstrap.html"><a href="bootstrap.html#moned-tava-bootstrapi-paketid"><i class="fa fa-check"></i><b>12.1</b> Mõned tava-bootstrapi paketid</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#bayesi-bootstrap"><i class="fa fa-check"></i>Bayesi bootstrap</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#parameetriline-bootstrap"><i class="fa fa-check"></i>Parameetriline bootstrap</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#bootstrappimine-ei-ole-kogu-tode"><i class="fa fa-check"></i>Bootstrappimine ei ole kogu tõde</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bayesi-pohimote.html"><a href="bayesi-pohimote.html"><i class="fa fa-check"></i><b>13</b> Bayesi põhimõte</a><ul>
<li class="chapter" data-level="" data-path="bayesi-pohimote.html"><a href="bayesi-pohimote.html#esimene-naide"><i class="fa fa-check"></i>Esimene näide</a></li>
<li class="chapter" data-level="" data-path="bayesi-pohimote.html"><a href="bayesi-pohimote.html#teine-naide-sonastame-oma-probleemi-umber"><i class="fa fa-check"></i>Teine näide: sõnastame oma probleemi ümber</a></li>
<li class="chapter" data-level="" data-path="bayesi-pohimote.html"><a href="bayesi-pohimote.html#kui-n-1"><i class="fa fa-check"></i>Kui n = 1</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="mudelite-keel.html"><a href="mudelite-keel.html"><i class="fa fa-check"></i><b>14</b> Mudelite keel</a><ul>
<li class="chapter" data-level="" data-path="mudelite-keel.html"><a href="mudelite-keel.html#beta-prior"><i class="fa fa-check"></i>Beta prior</a></li>
<li class="chapter" data-level="" data-path="mudelite-keel.html"><a href="mudelite-keel.html#prioritest-uldiselt"><i class="fa fa-check"></i>Prioritest üldiselt</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="mcmc-pohimote.html"><a href="mcmc-pohimote.html"><i class="fa fa-check"></i><b>15</b> MCMC põhimõte</a></li>
<li class="chapter" data-level="16" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html"><i class="fa fa-check"></i><b>16</b> Lihtne normaaljaotuse mudel</a><ul>
<li class="chapter" data-level="" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html#kui-lai-on-meie-toeparafunktsioon"><i class="fa fa-check"></i>Kui lai on meie tõepärafunktsioon?</a></li>
<li class="chapter" data-level="" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html#lihtne-voi-robustne-normaalne-mudel"><i class="fa fa-check"></i>Lihtne või robustne normaalne mudel?</a></li>
<li class="chapter" data-level="" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html#mcmc-ahelate-kvaliteet"><i class="fa fa-check"></i>MCMC ahelate kvaliteet</a><ul>
<li class="chapter" data-level="" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html#naide-usa-presidentide-keskmine-pikkus"><i class="fa fa-check"></i>Näide: USA presidentide keskmine pikkus</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lihtne-normaaljaotuse-mudel.html"><a href="lihtne-normaaljaotuse-mudel.html#lineaarne-regressioon"><i class="fa fa-check"></i>Lineaarne regressioon</a></li>
<li><a href="lihtne-normaaljaotuse-mudel.html#lm---vahimruutude-meetodiga-fititud-lineaarsed-mudelid"><code>lm()</code> - vähimruutude meetodiga fititud lineaarsed mudelid</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="bayesi-meetodil-lineaarse-mudeli-fittimine.html"><a href="bayesi-meetodil-lineaarse-mudeli-fittimine.html"><i class="fa fa-check"></i><b>17</b> Bayesi meetodil lineaarse mudeli fittimine</a><ul>
<li class="chapter" data-level="" data-path="bayesi-meetodil-lineaarse-mudeli-fittimine.html"><a href="bayesi-meetodil-lineaarse-mudeli-fittimine.html#ennustused-mudelist"><i class="fa fa-check"></i>Ennustused mudelist</a></li>
<li class="chapter" data-level="" data-path="bayesi-meetodil-lineaarse-mudeli-fittimine.html"><a href="bayesi-meetodil-lineaarse-mudeli-fittimine.html#lognormaalne-toeparamudel"><i class="fa fa-check"></i>Lognormaalne tõepäramudel</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="mitme-prediktoriga-lineaarne-regressioon.html"><a href="mitme-prediktoriga-lineaarne-regressioon.html"><i class="fa fa-check"></i><b>18</b> Mitme prediktoriga lineaarne regressioon</a><ul>
<li class="chapter" data-level="" data-path="mitme-prediktoriga-lineaarne-regressioon.html"><a href="mitme-prediktoriga-lineaarne-regressioon.html#miks-multivariaatsed-mudelid-head-on"><i class="fa fa-check"></i>Miks multivariaatsed mudelid head on?</a></li>
<li class="chapter" data-level="" data-path="mitme-prediktoriga-lineaarne-regressioon.html"><a href="mitme-prediktoriga-lineaarne-regressioon.html#mudeldamine-standardiseeritud-andmetega"><i class="fa fa-check"></i>Mudeldamine standardiseeritud andmetega</a></li>
<li class="chapter" data-level="18.1" data-path="mitme-prediktoriga-lineaarne-regressioon.html"><a href="mitme-prediktoriga-lineaarne-regressioon.html#prediktorite-valik-e-milline-on-parim-mudel"><i class="fa fa-check"></i><b>18.1</b> Prediktorite valik e milline on parim mudel</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html"><i class="fa fa-check"></i><b>19</b> Keerulisemate mudelitega töötamine</a><ul>
<li class="chapter" data-level="" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html#predictor-residual-plots"><i class="fa fa-check"></i>Predictor residual plots</a></li>
<li class="chapter" data-level="" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html#ennustavad-plotid"><i class="fa fa-check"></i>Ennustavad plotid</a></li>
<li class="chapter" data-level="" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html#posterior-prediction-plots"><i class="fa fa-check"></i>Posterior prediction plots</a></li>
<li class="chapter" data-level="" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html#interaktsioonid-prediktorite-vahel"><i class="fa fa-check"></i>Interaktsioonid prediktorite vahel</a></li>
<li class="chapter" data-level="" data-path="keerulisemate-mudelitega-tootamine.html"><a href="keerulisemate-mudelitega-tootamine.html#interaktsioonid-pidevatele-tunnustele"><i class="fa fa-check"></i>Interaktsioonid pidevatele tunnustele</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html"><i class="fa fa-check"></i><b>20</b> Mitmetasemelised mudelid</a><ul>
<li class="chapter" data-level="20.1" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#kahetasemeline-mudel-algebra-keeles"><i class="fa fa-check"></i><b>20.1</b> kahetasemeline mudel algebra keeles</a><ul>
<li class="chapter" data-level="20.1.1" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#aegread"><i class="fa fa-check"></i><b>20.1.1</b> Aegread</a></li>
<li class="chapter" data-level="20.1.2" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#temporaalne-autokorrelatsioon"><i class="fa fa-check"></i><b>20.1.2</b> Temporaalne autokorrelatsioon</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#mitmetasemeline-mudel-r-i-mudelikeeles"><i class="fa fa-check"></i><b>20.2</b> mitmetasemeline mudel R-i mudelikeeles</a></li>
<li class="chapter" data-level="20.3" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#mitmetasemeliste-mudelite-lisaeeldused"><i class="fa fa-check"></i><b>20.3</b> Mitmetasemeliste mudelite lisaeeldused</a></li>
<li class="chapter" data-level="20.4" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#mitmetasemeline-mudel-tootab-korraga-mitmel-tasmel"><i class="fa fa-check"></i><b>20.4</b> Mitmetasemeline mudel töötab korraga mitmel tasmel</a><ul>
<li class="chapter" data-level="" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#shrinkage"><i class="fa fa-check"></i>Shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#anova-laadne-mudel"><i class="fa fa-check"></i><b>20.5</b> ANOVA-laadne mudel</a></li>
<li class="chapter" data-level="20.6" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#vabad-interceptid-klassikalises-regressioonimudelis"><i class="fa fa-check"></i><b>20.6</b> Vabad interceptid klassikalises regressioonimudelis</a></li>
<li class="chapter" data-level="20.7" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#vabad-tousud-ja-interceptid"><i class="fa fa-check"></i><b>20.7</b> Vabad tõusud ja interceptid</a></li>
<li class="chapter" data-level="20.8" data-path="mitmetasemelised-mudelid.html"><a href="mitmetasemelised-mudelid.html#hierarhiline-mudel-pidevate-prediktoritega"><i class="fa fa-check"></i><b>20.8</b> Hierarhiline mudel pidevate prediktoritega</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="brms.html"><a href="brms.html"><i class="fa fa-check"></i><b>21</b> brms</a><ul>
<li class="chapter" data-level="21.1" data-path="brms.html"><a href="brms.html#brms-i-toovoog"><i class="fa fa-check"></i><b>21.1</b> brms-i töövoog</a><ul>
<li class="chapter" data-level="21.1.1" data-path="brms.html"><a href="brms.html#kiire-toovoog"><i class="fa fa-check"></i><b>21.1.1</b> Kiire töövoog</a></li>
<li class="chapter" data-level="21.1.2" data-path="brms.html"><a href="brms.html#pohjalikum-toovoog"><i class="fa fa-check"></i><b>21.1.2</b> Põhjalikum töövoog</a></li>
<li class="chapter" data-level="21.1.3" data-path="brms.html"><a href="brms.html#spetsifitseerime-mudeli-vaatame-ja-muudame-vaikeprioreid"><i class="fa fa-check"></i><b>21.1.3</b> Spetsifitseerime mudeli, vaatame ja muudame vaikeprioreid</a></li>
<li class="chapter" data-level="21.1.4" data-path="brms.html"><a href="brms.html#brm-funktsiooni-argumendid"><i class="fa fa-check"></i><b>21.1.4</b> <code>brm()</code> funktsiooni argumendid:</a></li>
<li class="chapter" data-level="21.1.5" data-path="brms.html"><a href="brms.html#fitime-mudeleid-ja-vordleme-fitte."><i class="fa fa-check"></i><b>21.1.5</b> Fitime mudeleid ja võrdleme fitte.</a></li>
<li class="chapter" data-level="21.1.6" data-path="brms.html"><a href="brms.html#vaatame-mudelite-kokkuvotet"><i class="fa fa-check"></i><b>21.1.6</b> Vaatame mudelite kokkuvõtet</a></li>
<li class="chapter" data-level="21.1.7" data-path="brms.html"><a href="brms.html#plotime-posteeriorid-ja-ahelad"><i class="fa fa-check"></i><b>21.1.7</b> Plotime posteeriorid ja ahelad</a></li>
<li class="chapter" data-level="21.1.8" data-path="brms.html"><a href="brms.html#korjame-ahelad-andmeraami-ja-plotime-fititud-koefitsiendid-ci-dega"><i class="fa fa-check"></i><b>21.1.8</b> Korjame ahelad andmeraami ja plotime fititud koefitsiendid CI-dega</a></li>
<li class="chapter" data-level="21.1.9" data-path="brms.html"><a href="brms.html#bayesi-versioon-r-ruudust"><i class="fa fa-check"></i><b>21.1.9</b> Bayesi versioon R-ruudust</a></li>
<li class="chapter" data-level="21.1.10" data-path="brms.html"><a href="brms.html#plotime-mudeli-poolt-ennustatud-valimeid-posterior-predictive-check"><i class="fa fa-check"></i><b>21.1.10</b> Plotime mudeli poolt ennustatud valimeid – posterior predictive check</a></li>
<li class="chapter" data-level="21.1.11" data-path="brms.html"><a href="brms.html#plotime-mudeli-ennustusi---marginal-effects-plots"><i class="fa fa-check"></i><b>21.1.11</b> Plotime mudeli ennustusi - marginal effects plots</a></li>
<li class="chapter" data-level="21.1.12" data-path="brms.html"><a href="brms.html#alternatiivne-tee"><i class="fa fa-check"></i><b>21.1.12</b> Alternatiivne tee</a></li>
<li class="chapter" data-level="21.1.13" data-path="brms.html"><a href="brms.html#alternatiiv-ansambliennustus"><i class="fa fa-check"></i><b>21.1.13</b> Alternatiiv – ansambliennustus</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="brms.html"><a href="brms.html#mudeli-eelduste-kontroll"><i class="fa fa-check"></i><b>21.2</b> Mudeli eelduste kontroll</a><ul>
<li class="chapter" data-level="21.2.1" data-path="brms.html"><a href="brms.html#plotime-residuaalid"><i class="fa fa-check"></i><b>21.2.1</b> Plotime residuaalid</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="brms-mudelid.html"><a href="brms-mudelid.html"><i class="fa fa-check"></i><b>22</b> Brms mudelid</a><ul>
<li class="chapter" data-level="22.1" data-path="brms-mudelid.html"><a href="brms-mudelid.html#robustne-lineaarne-regressioon"><i class="fa fa-check"></i><b>22.1</b> Robustne lineaarne regressioon</a></li>
<li class="chapter" data-level="22.2" data-path="brms-mudelid.html"><a href="brms-mudelid.html#lognormaalne-toeparafunktsioon"><i class="fa fa-check"></i><b>22.2</b> lognormaalne tõepärafunktsioon</a></li>
<li class="chapter" data-level="22.3" data-path="brms-mudelid.html"><a href="brms-mudelid.html#puuduvate-andmete-imputatsioon"><i class="fa fa-check"></i><b>22.3</b> Puuduvate andmete imputatsioon</a><ul>
<li class="chapter" data-level="" data-path="brms-mudelid.html"><a href="brms-mudelid.html#imputatsioon-otse-brms-is"><i class="fa fa-check"></i>Imputatsioon otse brms-is</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="brms-mudelid.html"><a href="brms-mudelid.html#binoomjaotusega-mudelid"><i class="fa fa-check"></i><b>22.4</b> Binoomjaotusega mudelid</a><ul>
<li class="chapter" data-level="22.4.1" data-path="brms-mudelid.html"><a href="brms-mudelid.html#logistiline-regressioon"><i class="fa fa-check"></i><b>22.4.1</b> Logistiline regressioon</a></li>
<li class="chapter" data-level="22.4.2" data-path="brms-mudelid.html"><a href="brms-mudelid.html#y-muutujal-3-kategoorilist-vaartust"><i class="fa fa-check"></i><b>22.4.2</b> Y-muutujal 3+ kategoorilist väärtust</a></li>
<li class="chapter" data-level="22.4.3" data-path="brms-mudelid.html"><a href="brms-mudelid.html#zero-inflated-mudelid"><i class="fa fa-check"></i><b>22.4.3</b> zero inflated mudelid</a></li>
<li class="chapter" data-level="22.4.4" data-path="brms-mudelid.html"><a href="brms-mudelid.html#additiivsed-distributsioonilised-mudelid"><i class="fa fa-check"></i><b>22.4.4</b> additiivsed distributsioonilised mudelid</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="brms-mudelid.html"><a href="brms-mudelid.html#monotoonilised-efektid"><i class="fa fa-check"></i><b>22.5</b> Monotoonilised efektid</a><ul>
<li class="chapter" data-level="22.5.1" data-path="brms-mudelid.html"><a href="brms-mudelid.html#multivariaatsed-mudelid"><i class="fa fa-check"></i><b>22.5.1</b> Multivariaatsed mudelid</a></li>
<li class="chapter" data-level="22.5.2" data-path="brms-mudelid.html"><a href="brms-mudelid.html#mittelineaarsed-mudelid"><i class="fa fa-check"></i><b>22.5.2</b> Mittelineaarsed mudelid</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="brms-suntaks.html"><a href="brms-suntaks.html"><i class="fa fa-check"></i><b>23</b> brms süntaks</a><ul>
<li class="chapter" data-level="23.1" data-path="brms-suntaks.html"><a href="brms-suntaks.html#general-formula-structure"><i class="fa fa-check"></i><b>23.1</b> General formula structure</a><ul>
<li class="chapter" data-level="23.1.1" data-path="brms-suntaks.html"><a href="brms-suntaks.html#special-predictor-terms-s-t2-gp-mo-me-mi-cs"><i class="fa fa-check"></i><b>23.1.1</b> Special predictor terms (s, t2, gp(), mo(), me(), mi(), cs())</a></li>
<li class="chapter" data-level="23.1.2" data-path="brms-suntaks.html"><a href="brms-suntaks.html#additional-response-information"><i class="fa fa-check"></i><b>23.1.2</b> Additional response information</a></li>
<li class="chapter" data-level="23.1.3" data-path="brms-suntaks.html"><a href="brms-suntaks.html#formula-syntax-for-non-linear-models"><i class="fa fa-check"></i><b>23.1.3</b> Formula syntax for non-linear models</a></li>
<li class="chapter" data-level="23.1.4" data-path="brms-suntaks.html"><a href="brms-suntaks.html#formula-syntax-for-predicting-distributional-parameters"><i class="fa fa-check"></i><b>23.1.4</b> Formula syntax for predicting distributional parameters</a></li>
<li class="chapter" data-level="23.1.5" data-path="brms-suntaks.html"><a href="brms-suntaks.html#formula-syntax-for-mixture-models"><i class="fa fa-check"></i><b>23.1.5</b> Formula syntax for mixture models</a></li>
<li class="chapter" data-level="23.1.6" data-path="brms-suntaks.html"><a href="brms-suntaks.html#formula-syntax-for-multivariate-models"><i class="fa fa-check"></i><b>23.1.6</b> Formula syntax for multivariate models</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="brms-suntaks.html"><a href="brms-suntaks.html#brms-likelihoods"><i class="fa fa-check"></i><b>23.2</b> brms likelihoods</a></li>
<li class="chapter" data-level="23.3" data-path="brms-suntaks.html"><a href="brms-suntaks.html#priors"><i class="fa fa-check"></i><b>23.3</b> priors</a><ul>
<li class="chapter" data-level="23.3.1" data-path="brms-suntaks.html"><a href="brms-suntaks.html#population-level-fixed-effects"><i class="fa fa-check"></i><b>23.3.1</b> Population-level (‘fixed’) effects</a></li>
<li class="chapter" data-level="23.3.2" data-path="brms-suntaks.html"><a href="brms-suntaks.html#standard-deviations-of-group-level-random-effects"><i class="fa fa-check"></i><b>23.3.2</b> Standard deviations of group-level (‘random’) effects</a></li>
<li class="chapter" data-level="23.3.3" data-path="brms-suntaks.html"><a href="brms-suntaks.html#correlations-of-group-level-random-effects"><i class="fa fa-check"></i><b>23.3.3</b> Correlations of group-level (‘random’) effects</a></li>
<li class="chapter" data-level="23.3.4" data-path="brms-suntaks.html"><a href="brms-suntaks.html#splines"><i class="fa fa-check"></i><b>23.3.4</b> Splines</a></li>
<li class="chapter" data-level="23.3.5" data-path="brms-suntaks.html"><a href="brms-suntaks.html#gaussian-processes"><i class="fa fa-check"></i><b>23.3.5</b> Gaussian processes</a></li>
<li class="chapter" data-level="23.3.6" data-path="brms-suntaks.html"><a href="brms-suntaks.html#autocorrelation-parameters"><i class="fa fa-check"></i><b>23.3.6</b> Autocorrelation parameters</a></li>
<li class="chapter" data-level="23.3.7" data-path="brms-suntaks.html"><a href="brms-suntaks.html#parameters-for-specific-families"><i class="fa fa-check"></i><b>23.3.7</b> Parameters for specific families</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html"><i class="fa fa-check"></i><b>24</b> Puuduvad andmed</a><ul>
<li class="chapter" data-level="24.1" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#andmete-puudumise-mehhanismid"><i class="fa fa-check"></i><b>24.1</b> Andmete puudumise mehhanismid:</a></li>
<li class="chapter" data-level="24.2" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#uhekaupa-imputatsiooni-meetodid"><i class="fa fa-check"></i><b>24.2</b> Ühekaupa imputatsiooni meetodid</a><ul>
<li class="chapter" data-level="24.2.1" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#na-dega-ridade-eemaldamine"><i class="fa fa-check"></i><b>24.2.1</b> NA-dega ridade eemaldamine</a></li>
<li class="chapter" data-level="24.2.2" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#paariviisiline-deleteerimine"><i class="fa fa-check"></i><b>24.2.2</b> Paariviisiline deleteerimine</a></li>
<li class="chapter" data-level="24.2.3" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#keskmise-imputatsioon-ja-regressiooniga-imputatsioon"><i class="fa fa-check"></i><b>24.2.3</b> Keskmise imputatsioon ja regressiooniga imputatsioon</a></li>
<li class="chapter" data-level="24.2.4" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#stohhastiline-regressiooniga-imputatsioon"><i class="fa fa-check"></i><b>24.2.4</b> Stohhastiline regressiooniga imputatsioon</a></li>
<li class="chapter" data-level="24.2.5" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#eelmise-vaatluse-kopeerimine-locf."><i class="fa fa-check"></i><b>24.2.5</b> Eelmise vaatluse kopeerimine (LOCF).</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#mitmene-imputatsioon"><i class="fa fa-check"></i><b>24.3</b> Mitmene imputatsioon</a></li>
<li class="chapter" data-level="24.4" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#predictive-mean-matching"><i class="fa fa-check"></i><b>24.4</b> Predictive mean matching</a></li>
<li class="chapter" data-level="24.5" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#imputeerimine-mitte-normaalsete-jaotuste-korral"><i class="fa fa-check"></i><b>24.5</b> Imputeerimine mitte-normaalsete jaotuste korral</a></li>
<li class="chapter" data-level="24.6" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#kategoorilised-muutujad"><i class="fa fa-check"></i><b>24.6</b> Kategoorilised muutujad</a></li>
<li class="chapter" data-level="24.7" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#countid-sisaldavad-nulle"><i class="fa fa-check"></i><b>24.7</b> countid (sisaldavad nulle)</a></li>
<li class="chapter" data-level="24.8" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#graafilised-meetodid"><i class="fa fa-check"></i><b>24.8</b> Graafilised meetodid</a></li>
<li class="chapter" data-level="24.9" data-path="puuduvad-andmed.html"><a href="puuduvad-andmed.html#tulemuste-avaldamine"><i class="fa fa-check"></i><b>24.9</b> Tulemuste avaldamine</a></li>
</ul></li>
<li class="appendix"><span><b>Lisa</b></span></li>
<li class="chapter" data-level="A" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html"><i class="fa fa-check"></i><b>A</b> Bayesi ja sagedusliku statistika võrdlus</a><ul>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#kaks-statistikat-ajaloost-ja-toenaosusest"><i class="fa fa-check"></i>Kaks statistikat: ajaloost ja tõenäosusest</a></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#poleemika-kumbki-toenaosus-pole-paris-see-mida-uldiselt-arvatakse"><i class="fa fa-check"></i>Poleemika: kumbki tõenäosus pole päris see, mida üldiselt arvatakse</a></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#vordlev-naide-kahe-grupi-vordlus"><i class="fa fa-check"></i>Võrdlev näide: kahe grupi võrdlus</a><ul>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#bayesiaan"><i class="fa fa-check"></i>Bayesiaan</a></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#sageduslik-statistik"><i class="fa fa-check"></i>Sageduslik statistik</a></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#tulemuste-tolgendamine"><i class="fa fa-check"></i>Tulemuste tõlgendamine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#kahe-paradigma-erinevused"><i class="fa fa-check"></i>Kahe paradigma erinevused</a><ul>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#sageduslik-ja-teaduslik-hupoteesitestimine"><i class="fa fa-check"></i>Sageduslik ja teaduslik hüpoteesitestimine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#statistiline-ennustus-kui-mitmetasandiline-protsess"><i class="fa fa-check"></i>Statistiline ennustus kui mitmetasandiline protsess</a><ul>
<li class="chapter" data-level="A.0.1" data-path="bayesi-ja-sagedusliku-statistika-vordlus.html"><a href="bayesi-ja-sagedusliku-statistika-vordlus.html#ajaloolist-juttu-normaaljaotus-bayes-ja-sageduslik-statistika"><i class="fa fa-check"></i><b>A.0.1</b> Ajaloolist juttu: normaaljaotus, Bayes ja sageduslik statistika</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="sonastik.html"><a href="sonastik.html"><i class="fa fa-check"></i><b>B</b> Sõnastik</a><ul>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#kaks-statistikat-ajaloost-ja-toenaosusest-1"><i class="fa fa-check"></i>Kaks statistikat: ajaloost ja tõenäosusest</a></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#poleemika-kumbki-toenaosus-pole-paris-see-mida-uldiselt-arvatakse-1"><i class="fa fa-check"></i>Poleemika: kumbki tõenäosus pole päris see, mida üldiselt arvatakse</a></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#vordlev-naide-kahe-grupi-vordlus-1"><i class="fa fa-check"></i>Võrdlev näide: kahe grupi võrdlus</a><ul>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#bayesiaan-1"><i class="fa fa-check"></i>Bayesiaan</a></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#sageduslik-statistik-1"><i class="fa fa-check"></i>Sageduslik statistik</a></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#tulemuste-tolgendamine-1"><i class="fa fa-check"></i>Tulemuste tõlgendamine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#kahe-paradigma-erinevused-1"><i class="fa fa-check"></i>Kahe paradigma erinevused</a><ul>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#sageduslik-ja-teaduslik-hupoteesitestimine-1"><i class="fa fa-check"></i>Sageduslik ja teaduslik hüpoteesitestimine</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="sonastik.html"><a href="sonastik.html#statistiline-ennustus-kui-mitmetasandiline-protsess-1"><i class="fa fa-check"></i>Statistiline ennustus kui mitmetasandiline protsess</a><ul>
<li class="chapter" data-level="B.0.1" data-path="sonastik.html"><a href="sonastik.html#ajaloolist-juttu-normaaljaotus-bayes-ja-sageduslik-statistika-1"><i class="fa fa-check"></i><b>B.0.1</b> Ajaloolist juttu: normaaljaotus, Bayes ja sageduslik statistika</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesi statistika kasutades R keelt</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mitmetasemelised-mudelid" class="section level1">
<h1><span class="header-section-number">20</span> Mitmetasemelised mudelid</h1>
<blockquote>
<p>Mitmetasemeline mudel on regressioonimudel, kus andmed on struktureeritud gruppidesse ja mudeli koefitsiendid võivad erineda grupist gruppi.</p>
</blockquote>
<p>Statistika teooria ütleb, et me peaksime oma mudelitesse hõlmama need faktorid, mida kasutati eksperimendi disainis. Mitmetasandilised mudelid on parim viis, kuidas mudelisse panna katsedisainis esinevaid erinevatel tasemetel klastreid ja samas vältida mudeli ülefittimist.
Mitmetasandiline mudel kajastab sellise katse või vaatluse struktuuri, kus andmed ei grupeeru mitte ainult katse- ja kontrolltingimuste vahel, vaid ka lisaklastritesse ehk gruppidesse. Näiteks, kui me mõõdame platseebo-kontrollitud uuringus kümmet patsienti ja teeme igale patsiendile viis kordusmõõtmist (kahetasemeline mudel). Või kui meil on geeniuuring, kus uuritakse korraga 1000 valgu taset ja uuring toimub 10 laboris (3-tasemeline mudel). Või kui mõõdame kalamaksaõli mõju matemaatikaeksami tulemustele kümnes koolis, ja igas neist viies klassis (3-tasemeline mudel).</p>
<p>Tavapärane lähenemine oleks kõigepealt keskmistada andmed iga klassi sees ning seejärel keskmistada iga kooli sees (võtta igale koolile 5 klassi keskmine). Ning seejärel, võttes iga kooli keskmise üheks andmepunktiks, teha soovitud statistiline test (N = 10, sest meil on 10 kooli). Paraku, sellisel viisil talitades alahindame varieeruvust, mistõttu meie statistiline test alahindab ebakindluse määra arvutatud statistiku ümber. Hierarhilised mudelid, mis kajastavad adekvaatselt katse struktuuri, aitavad sellest murest üle saada. Üldine soovitus on, et kui teie katse struktuur seda võimaldab, siis peaksite alustama modelleerimist hierarhilistest mudelitest.</p>
<p>Mitmetasemelised mudelid on eriti kasulikud, kui teil on osades klastrites vähem andmepunkte kui teistes, sest nad vaatavad andmeid korraga nii klastrite vahel kui klastrite sees ning kannavad informatsiooni üle klastritest, kus on rohkem andmepunkte, nendesse klastritesse, kus on vähe andmeid. See tõstab hinnangute täpsust.</p>
<p>Tavapärane regressioonimudel on sageli vaadeldav mitmetasandilise mudeli erijuhuna. Näiteks kujutage ette mudelit, kus laste õppedukust on mõõdetud mitmes koolis. Kui gruppide (koolide) vaheline varieeruvus on väga madal, siis annab mitmetasemeline mudel sarnase tulemuse lihtsa mudeliga, kus kõik koolid on ühte patta kokku pandud. Ja vastupidi, kui koolid on üksteisest väga erinevad, siis võime sama hästi modelleerida iga kooli eraldi ja teistest sõltumatult. Samuti, kui meil on andmeid väga väheste koolide kohta, siis võib mitmetasandilsest mudelist saadav kasu olla tagasihoidlik, sest meil pole piisavalt andmeid, et modelleerida koolide vahelist varieeruvust. Samuti, kui meil on iga kooli kohta piisavalt palju andmeid, siis saame iga kooli eraldi modelleerides praktiliselt sama tulemuse kui mitmetasemelisest mudelist. Muudel juhtudel on tõenäoliselt mõistlikum modelleerida õppedukust kahetasemelises mudelis, korraga õpilase tasemel ja kooli tasemel.</p>
<div id="kahetasemeline-mudel-algebra-keeles" class="section level2">
<h2><span class="header-section-number">20.1</span> kahetasemeline mudel algebra keeles</h2>
<ol style="list-style-type: decimal">
<li>tase on õpilse tase, 2. tase on klassi tase.
meil on j klassi, milles on erinev arv õpilasi. Iga õpilase kohta teame populaarsusindeksit (y - muutuja) ja sugu (x - muutuja). Klassi tasemel teame õpetaja staazi aastates (z - muutuja).
Alustuseks on meil j regressioonivõrrandit, eraldi võrrand igale klassile</li>
</ol>
<p><span class="math display">\[y_{ij} = b_{0j} + b_{1j}X_{ij} + e_{ij}\]</span> (1. võrrand)</p>
<p>kus subskript j tähistab klassi ja i tähistab õpilast. Näit <span class="math inline">\(b_{1j}\)</span> tähendab, et me fitime igale klassile oma <span class="math inline">\(b_1\)</span> koefitsiendi (ja <span class="math inline">\(b_{0j}\)</span>, et fitime igale klassile oma <span class="math inline">\(b_0\)</span>-i). Me eeldame, et igal klassil on erinevad <span class="math inline">\(b_0\)</span> ja <span class="math inline">\(b_1\)</span>, mis tulevad vastavatest klassiülestest normaaljaotustest. Enamasti eeldame, et kõikide klasside varieeruvus on sama. Me modelleerime <span class="math inline">\(b_0\)</span> ja <span class="math inline">\(b_1\)</span> jaotusi, tuues sisse klassi tasemel muutuja z:</p>
<p><span class="math display">\[b_{0j} = \gamma_{00} + \gamma_{01} Z_j + u_{0j}\]</span> (2. võrrand)</p>
<p><span class="math display">\[b_{1j} = \gamma_{10} + \gamma_{11} Z_j + u_{1j}\]</span> (3. võrrand)</p>
<ol start="2" style="list-style-type: decimal">
<li>võrrand ennustab klassi keskmist populaarsusindeksit vastavalt õpetaja staazile.</li>
<li>võrrand ütleb, et populaarsuse ja soo seose tugevus sõltub õpetaja staazist – kui <span class="math inline">\(\gamma_{11} &gt; 0\)</span>, siis on seos seda tugevam, mida staazikam on õpetaja. <span class="math inline">\(u_{0j}\)</span> ja <span class="math inline">\(u_{1j}\)</span> on residuaalide vead klassi tasemel, mille kohta me eeldame, et mean = 0 ja sõltumatust residuaalide vigadest õpilase tasemel (<span class="math inline">\(e_{ij}\)</span>). <span class="math inline">\(u_{0j}\)</span> residuaalide vigade dispersioon on <span class="math inline">\(\sigma^2_{u0}\)</span> jne. <span class="math inline">\(u_{0j}\)</span> ja <span class="math inline">\(u_{1j}\)</span> covariance on <span class="math inline">\(\sigma^2_{u01}\)</span> ja me ei eelda, et see = 0. Gamma koefitsiendid ei varieeru klasside vahel.</li>
</ol>
<p>Asendades 1. võrrandis <span class="math inline">\(b_{0j}\)</span> ja <span class="math inline">\(b_{1j}\)</span>, saame oma võrrandisüsteemi muuta üheks pikaks võrrandiks.</p>
<p><span class="math display">\[Y_{ij} = \gamma_{00} + \gamma_{10} X_{ij} + \gamma_{01} Z_j + \gamma_{11}X_{ij} Z_j + u_{1j} X_{ij} + u_{0j} + e_{ij}\]</span></p>
<p>Siis näeme uues võrrandis liiget <span class="math inline">\(\gamma_1 Z_j X_{ij}\)</span>, mis on interaktsiooniliige.
Ilma interaktsioonita mudel näeb välja niimodi</p>
<p><span class="math display">\[Y_{ij} = \gamma_{00} + \gamma_{10} X_{ij} + \gamma_{01} Z_j + u_{1j} X_{ij} + u_{0j} + e_{ij}\]</span></p>
<p>juhusliku vealiige <span class="math inline">\(u_{ij}\)</span> korrutub <span class="math inline">\(X_{ij}\)</span>-ga, mistõttu sellest tulenev totaalne viga on erinev erinevatel <span class="math inline">\(X_{ij}\)</span> väärtustel. Seega on meie mudel heteroskedastiline ja erineb selle poolest tavalistest lineaarsetest mudelitest, mis eeldavad homoskedastilisust e residuaalvea sõltumatust X-i väärtusest.</p>
<p>Teine oluline erinevus tavalisest lin mudelist on, et gupeeritud andmete puhul ei ole täidetud andmete iseseisvuse eeldus (gruppide sees modelleeritakse andmed korreleerituna - klassisisene korrelatsioon). Klassisisese korrelatsiooni saame intercept-only mudelist</p>
<p><span class="math display">\[Y_{ij} = \gamma_{00} + u_{0j} + e_{ij}\]</span></p>
<p>(selle mudeli saad, kui viskad pikast mudelist välja kõik X ja Z sisaldavad liikmed.) See mudel ajab varieeruvuse lahku kahe iseseisva komponendi vahel: <span class="math inline">\(\sigma^2_e\)</span> (1. taseme vigade dispersioon <span class="math inline">\(e_{ij}\)</span>) ja <span class="math inline">\(\sigma^2_{u0}\)</span> (2. taseme vigade dispersioon <span class="math inline">\(u_{0j}\)</span>).</p>
<p>Klassisisene korrelatsioon:</p>
<p><span class="math display">\[\rho = \frac{\sigma^2_{u0}}{\sigma^2_{u0} + \sigma^2_e}\]</span></p>
<p>rho annab grupistruktuuri poolt seletatud variace proportsiooni, mida võib tõlgendada kui kahe sama grupi juhusliku liikme vahelist oodatavat korrelatsiooni.</p>
<p>Üldiselt on kasulik töötada standardiseeritud regressioonikoefitsientidega, mida saab tõlgendada sd ühikutes. Erandiks on olukord, kus analüüsi eesmärk on võrrelda erinevaid valimeid omavahel. Enamasti on kasulik standardiseerida andmed, mis mudelisse sisse lähevad, aga on võimalik ka standardiseerida koefitsiente kui selliseid.</p>
<p>st_coef = (unstand_coef x sd(X))/sd(Y)</p>
<p>Standardiseeritud andmete kasutamine muudab varieeruvuskomponentide fitte, aga jätab b koefitsientide fitid olemuselt samaks (see kehtib X-muutujate suvaliste lineaarsete transformatsioonide korral). Kui me jagame X-muutuja 2-ga, siis <span class="math inline">\(uus ~b_1 = 2 ~x~vana~ b_1\)</span>. Mudeli poolt seletamata varieeruvuse proportsioon ei muutu. Eelnev kehtib senikaua, kuni mudeli tõusud (<span class="math inline">\(b_1\)</span>) ei ole vabaks lastud, st need ei varieeru klassist klassi.</p>
<p>Tsentreerimine (<span class="math inline">\(x_i - mean(x)\)</span>) mõjutab <span class="math inline">\(b_0\)</span> aga mitte <span class="math inline">\(b_1\)</span> koefitsiente, mis võib rääkida selle meetodi kasuks üle standardiseerimise ((<span class="math inline">\(\frac {x_i - mean(x)}{sd(x)}\)</span>), mis tekitab X muutujate jaotused, mille mean = 0 ja sd = 1.</p>
<p>NB! grupi tasemel tsentreerimine, ehkki vahest kasulik, töötab hoopis teistmoodi kui üle kõikide gruppide tsentreerimine ja viib täiesti erineva mudelini - sellest tuleks hoiduda, senikaua kui te ei tea täpselt, mida te teete.</p>
<blockquote>
<p>Mitmetasemelised mudelid on erilised, sest nad hõlmavad mitut varieeruvuse allikat, ei eelda konsantset vigade jaotust, ning modelleerivad seoseid erinevate mudeli tasemete vahel.</p>
</blockquote>
<div id="aegread" class="section level3">
<h3><span class="header-section-number">20.1.1</span> Aegread</h3>
<p>Aegridasid saab analüüsida mitmetasemilisena, kus korduvad mõõtmised (1. tase) on grupeeritud indiviidide sisse (2. tase). Nii saab analüüsida ka ebaühtlase ajavahemiku järel tehtud mõõtmisi.</p>
<blockquote>
<p>Aegridade analüüsi lisaprobleem võrreldes tavalise mitmetasemelise mudeliga on, et me ei saa enam eeldada, et 1. taseme (indiviidi taseme) vead on üksteisest sõltumatud. Aegridade vaatluste vead on sageli ajas autokorreleeritud.</p>
</blockquote>
<p><span class="math inline">\(Y_{ti}\)</span> - indiviidi i õpitulemus ajapunktis t.</p>
<p><span class="math inline">\(T_{ti}\)</span> - ajapunkt</p>
<p><span class="math inline">\(X_{ti}\)</span> - ajas muutuv covariaat - kas õpilane töötab</p>
<p><span class="math inline">\(Z_t\)</span> - ajast mittesõltuv kovariaat - sugu</p>
<ol style="list-style-type: decimal">
<li>tase (indiviidi tase):</li>
</ol>
<p><span class="math display">\[Y_{ti} = \pi_{0i} + \pi_{1i} x T_{ti} + \pi_{2i} X_{ti} + e_{ti} \]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>tase (üle indiviidie):</li>
</ol>
<p><span class="math display">\[\pi_{0i} = \beta_{00} + \beta_{01} Z_t + u_{01}\]</span></p>
<p><span class="math display">\[\pi_{1i} =\beta_{10} + \beta_{11} Z_t + u_{11}\]</span></p>
<p><span class="math display">\[\pi_{2i} = \beta_{20} + \beta_{21} Z_t + u_{21}\]</span></p>
<p>Oluline punkt: aegridade modelleerimisel pakub meile sageli huvi ka ka korrelatsioon mudeli tõusu ja intercepti vahel. Kahjuks sõltub see näitaja sellest, millises skaalas me ajamuutuja mudelisse sisse anname. Oluline on tagada, et ajaskaala nullpunkt on mõtekas.</p>
<p>To model growth - polynomial, logistic curve (first slow change, then quick, then slow again). Logistic parameters have meaning! Cubic polynomial approximates logistic and exponential curves - but here interpretation is on the level of some predicted growth curves.</p>
<p><a href="https://facebook.github.io/prophet" class="uri">https://facebook.github.io/prophet</a>
sessoonsete andmete fittimine ennustavasse mudelisse</p>
<p><a href="https://github.com/nwfsc-timeseries" class="uri">https://github.com/nwfsc-timeseries</a>
kogu aegridade analüüsi pakette</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(coda)
<span class="co">#library(R2jags)</span>
<span class="kw">library</span>(gridExtra)
<span class="kw">library</span>(broom)</code></pre>
</div>
<div id="temporaalne-autokorrelatsioon" class="section level3">
<h3><span class="header-section-number">20.1.2</span> Temporaalne autokorrelatsioon</h3>
<p>eeldus: Mida lähemal on 2 ajapunkti üksteisele, seda suurem on nende vaheline korrelatsioon (ja residuaalide vaheline korrelatsioon). Tavaline lm eeldab, et see korrelatsioon = 0.
Seda korrelatsiooni saab kas hinnata, või selle vastu võidelda. Meie teeme siin viimast.</p>
<p>Brms mudel näeb välja niimoodi</p>
<pre class="sourceCode r"><code class="sourceCode r">data.temporalCor.brms &lt;-<span class="st">  </span><span class="kw">brm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> d, 
                              <span class="dt">autocor =</span> <span class="kw">cor_ar</span>(<span class="dt">formula =</span> <span class="op">~</span>year))</code></pre>
<p>cor_ar() on brms funktsioon autokorrelatsiooni modelleerimiseks. selle formula on ühepoolne valem ~t või ~ t | g, mis annab ajakovariaadi t ja grupeeriva faktori g. Kui g on antud, siis modelleeritakse iga grupp iseseisvalt ja teistest gruppidest sõltumata (gruppide vahel on korrelatsioon 0).</p>
<p>Teine võimalus inkorporeerib mudelisse AR1 residuaalide autokorrelatsioonistruktuuri, kus korrelatsiooni eksponent väheneb ajas lineaarselt. Me eeldame, et see vähenemine toimub samamoodi sõltumata sellest, millises ajavahemikus me parasjagu oleme (statsionaarsuse eeldus).</p>
<pre class="sourceCode r"><code class="sourceCode r">data.temporalCor.brms =<span class="st"> </span><span class="kw">brm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> d, 
                            <span class="dt">autocor =</span> <span class="kw">cor_ar</span>( <span class="op">~</span>year, <span class="dt">cov =</span> <span class="ot">TRUE</span>))</code></pre>
<p>Lihtsuse mõttes eeldame, et iga ajapunkti oodatud väärtus = tavaline lin prediktor + autokorrelatsiooni parameeter (<span class="math inline">\(\rho\)</span>) korrutatuna eelmise vaatluse residuaaliga + tavapärane sõltumatu müra (<span class="math inline">\(\sigma^2\)</span>).</p>
</div>
</div>
<div id="mitmetasemeline-mudel-r-i-mudelikeeles" class="section level2">
<h2><span class="header-section-number">20.2</span> mitmetasemeline mudel R-i mudelikeeles</h2>
<p>Kui meie muutujad andmetabelis “data” on y = õpilase testiskoor, x = katsetingimus (binaarne faktor katse-kontroll, kalamaksaöli - platseebo), ja kool, siis “ühepajamudel” väljendub R-i mudelikeeles:</p>
<p><code>mudel &lt;- lm(y ~ x, data=data)</code></p>
<p>ja mudel, kus iga kool on eraldi modelleeritud:</p>
<p><code>mudelid &lt;- data %&gt;% group_by(kool) %&gt;% do(model = lm(y ~ x, data = .))</code></p>
<p>või purrr-i abil</p>
<p><code>data %&gt;% split(.$kool) %&gt;% map(~ lm(y ~ x, data = .)) %&gt;% map(summary) %&gt;% map_dfr(~ broom::glance(.), .id = &quot;kool&quot;)</code></p>
<p>Seevastu hierarhiline mudel kirjutatakse kui</p>
<p><code>mudel &lt;- lme4::lmer(y ~ x + (1 + x | kool), data=data)</code></p>
<p>või</p>
<p><code>mudel &lt;- lme4::lmer(y ~ x + (1 | kool), data=data)</code></p>
<p>Esimesel juhul modelleeritakse igale koolile nii tõus kui intercept ja teisel juhul modelleeritakse igale koolile ainult intercept, seeläbi eeldades, et kõikidel koolidel on mudelis sama tõus, ehk kalamaksaõli efekt (ES = testitulemus kalamaksaõli grupis - testitulemus platseebogrupis). Intercept tähendab sellises mudelis enamasti baastaset (kontrolltingimus) ja tõus tähendab katseefekti (katsetingimus - kontrolltingimus). Seega eeldab teine mudel, et igas grupis võib küll olla oma baastase, aga katsefekt sellest ei muutu.</p>
<p>Lisaks, mudel</p>
<p><code>mudel &lt;- lme4::lmer(y ~ x + (1 + x || kool), data=data)</code></p>
<p>modelleerib igale koolile tõusu ja intercepti lisaeeldusega, et tõusude ja interceptide vaheline korrelatsioon puudub. Ilma selle eelduseta püüab mudel selle korrelatsiooni andmete põhjal leida. Kui andmeid on liiga vähe või mudel on liiga keeruline või korrelatsiooni võimalik esinemine tundub teadulsikult väga väheusutav, võib korrelatsiooni hindamisest loobuda, aga muidu tasub seda siiski hinnata.</p>
<p><code>mudel &lt;- lme4::lmer(y ~ x + (1 + x | kool) + (1 + x | linn), data=data)</code></p>
<p>Kui meil on mudelis rohkem kui 2 taset, kirjutame need sõltumata sellest, kas tasemed on hierarhiliselt üksteise sees (õpilane - kool - linn) või mitte (patsient - haigla - ravimi batch)</p>
<p><code>mudel &lt;- lme4::lmer(y ~ x + (1 + x | grupp1) + (1 + x | grupp2), data=data)</code></p>
<p>Kui esimesed 2 mudelit saab fittida lm() funktsiooniga, siis lihtne mitte-bayesiaanlik alternatiiv hierarhilise mudeli tarbeks on lme4 pakett (<a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf" class="uri">https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf</a>), mis on lihtsam, kiirem ja ebatäpsem <em>ad hoc</em> viis arvutada mitmetasemeliseid mudeleid, kui Stan. Selle eelis Stani ees on eelkõige kiirus ja puuduseks on väiksem paindlikus mudelite formuleerimisel ja see, et väikeste valimite ja väheste gruppide puhul töötab lme4 algoritm palju halvemini, kui bayesi lahendused. Seega kasutame me pigem Stani, kui lme4. Samas, suurepärane pakett nimega brms (<a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf" class="uri">https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf</a>) suudab tõlkida lme4 mudeli kirjelduse otse Stani keelde ja seda mudelit seal jooksutada. Brms teeb elu magusaks (vt lisa 2).</p>
<blockquote>
<p>Suurem sõltuvus valimi suurusest ja erinevatest lisaeeldustest võrreldes Bayesi mudelitega on see hind, mida ad hoc lahendused maksavad oma lihtsuse eest. Enamust klassikalisi teste (t test, chi ruut test, jms) võib vaadelda selliste ad hoc lahendustena, mis sageli lagunevad laiali väikesetel valimitel, samas kui bayes töötab väikeste valimitega hästi – tõsi küll, sõltudes väikeste valimite korral rohkem priorist ja andes seal realistlikult laiad usaldusintervallid.</p>
</blockquote>
</div>
<div id="mitmetasemeliste-mudelite-lisaeeldused" class="section level2">
<h2><span class="header-section-number">20.3</span> Mitmetasemeliste mudelite lisaeeldused</h2>
<p>Mitmetasandilised mudelid toovad sisse lisaeelduse, et lineaarsuse/normaalsuse jm eeldused kehtivad igal mudeli tasemel. Samuti, et kõik grupid tulevad samast statistilisest populatsioonist, ja vastavalt sellele on nad mudelis koondatud ühise priori alla. Mitmetasemelises mudelis töötab grupi tasemel mudel priorina indiviidi tasemel mudelile.</p>
</div>
<div id="mitmetasemeline-mudel-tootab-korraga-mitmel-tasmel" class="section level2">
<h2><span class="header-section-number">20.4</span> Mitmetasemeline mudel töötab korraga mitmel tasmel</h2>
<p>Mudeli muudab mitmetasemeliseks see, et me määrame veamudelit kasutades mitte ainult indiviidi tasemel koefitsiente (1. tase), vaid anname neile koefitsientidele omakorda veamudeli (2. tase), mis modelleerib koefitsientide varieeruvust gruppide vahel. Selliseid tasemeid võib lisada põhimõtteliselt ükskõik kui palju. Kõrgema taseme mudel, lisaks sellele, et modelleerida gruppide vahelist varieeruvust, töötab ka priorina madalama taseme suhtes. Seega saab mudeli fittimisel 2. tase informatsiooni 1. tasemelt (andmete näol) ja samal ajal annab informatsiooni esimesele tasemele (priori kujul).</p>
<ol style="list-style-type: decimal">
<li><p>Mitmetasemelised mudelid modelleerivad eksplitsiitselt varieeruvust klasrtite sees ja klastrite vahel.</p></li>
<li><p>Nad modelleerivad indiviidi-tasemel regressioonikoefitsientide varieeruvust.</p></li>
<li><p>Nad võimaldavad paremini määrata indiviidi tasemel regressioonikoefitsiente endid, eriti kui erinevates gruppides on erinev arv indiviide.</p></li>
</ol>
<div id="shrinkage" class="section level3 unnumbered">
<h3>Shrinkage</h3>
<p>Oletame, et te plaanite reisi Kopenhaagenisse ja soovite sellega seoses teada, kui kallis on keskeltläbi õlu selle linna kõrtsides. Teile on teada õlle hind kolmes Kopenhaageni kõrtsis, mida ei ole just palju. Aga sellele lisaks on teile teada ka õlle hind 6-s Viini, 4-s Praha ja 5-s Pariisi kõrtsis. Nüüd on teil põhimõtteliselt kolm võimalust, kuidas sellele probleemile läheneda.</p>
<ol style="list-style-type: decimal">
<li><p>Te arvestate ainult Kopenhaageni andmeid ja ignoreerite teisi, kui ebarelevantseid. See meetod töötab hästi siis, kui teil on Kopenhaageni kohta palju andmeid (aga teil ei ole).</p></li>
<li><p>Te arvestate võrdselt kõiki andmeid, mis teil on — ehk te võtate keskmise kõikidest õllehindadest, hoolimata riigist. See töötab parimini siis, kui päriselt pole vahet, millisest riigist te oma õlle ostate, ehk kui õlu maksab igal pool sama palju. Antud juhul pole see ilmselt parim eeldus.</p></li>
<li><p>Te eeldate, et õlle hinna kujunemisel erinevates riikides on midagi ühist, aga et seal on ka erinevusi. Sellisel juhul tahate te fittida hierarhilise mudeli, kus teie hinnang õlle hinnale Kopenhaagenis sõltuks mingil määral (aga mitte nii suurel määral, kui eelmises punktis) ka teie kogemustest teistes linnades. Sama moodi, teie hinnang õlle hinnale Pariisis, Prahas jne hakkab mingil määral sõltuma kõikide linnade andmetest.</p></li>
</ol>
<blockquote>
<p>Kui teil on olukord, kus te mõõdate erinevaid gruppe, mis küll omavahel erinevad, aga on ka teatud määral sarnased (näiteks testitulemused grupeerituna kooli kaupa), siis on mõistlik kasutada kõikide gruppide andmeid, et adjusteerida iga grupi spetsiifilisi parameetreid. Seda adjusteerimise määra kutsutakse “shrinkage”.</p>
</blockquote>
<p>Shrinkage toimub parameetri keskväärtuse suunas ja mingi grupi shrinkage on seda suurem, mida vähem on selles grupis liikmeid ja mida kaugemal asub see grupp kõikide gruppide keskväärtusest. See viib shrinkage koefitsientide kallutatusele (bias), aga samas ka suuremale täpsusele (precision). See tähendab, et shrinkage koefitsiendi hinnang on keskeltläbi lähemal tõelisele koefitsiendi väärtusele kui hannang tavalisele ühetasandilise mudeli koefitsiendile.</p>
<p>Shrinkage on põhimõtteliselt sama nähtus, mis juba Francis Galtoni poolt avastatud regressioon keskmisele.
Regressioon keskmisele on stohhastiline protsess kus, olles sooritanud n mõõtmist ja arvutanud nende tulemuste põhjal efekti suuruse, see valimi ES peegeldab nii tegelikku ES-i kui juhuslikku valimiviga. Kui valimivea osakaal ES-s on suur, siis lisamõõtmised vähendavad keskeltläbi efekti suurust. Shrinkage erineb sellest ainult selle poolest, et lisamõõtmised meenutavad ainult <strong>osaliselt</strong> algseid mõõtmisi.</p>
<p>Kasutades hierarhilisi mudeleid saab võidelda ka valehäirete ehk mitmese testimise probleemiga.
See probleem on lihtsalt sõnastatav: kui te sooritate palju võrdluskatseid ja statistilisi teste olukorras, kus tegelik katseefekt on tühine, siis tänu valimiveale annavad osad teie paljudest testidest ülehinnatud efekti.
Seega, kui meil on kahtlus, et enamus võrdlusi on “mõttetud” ja me ei oska ette ennustada, millised võrdlused neist (kui üldse mõni) võiks anda tõelise teaduslikult mõtteka efekti, siis on lahendus kõiki saadud efekte kunstlikult pisendada kõikide efektide keskmise suunas.
Mudeli kontekstis kutsutakse sellist lähenemist <em>shrinkage</em>-ks.
Aga kui suurel määral seda teha?
See sõltub nii sellest, kui palju teste me teeme, valimi suurusest, kui ka sellest, kuidas jaotuvad mõõdetud efektisuurused (milline on efektisuuruste varieeruvus testide vahel).</p>
<p>Bayesi lahendus on, et me lisame mudelisse veel ühe hierarhilise priori, mis kõrgub üle gruppide-spetsiifilise priori.
Seega anname me olemasolevale priorile uue kõrgema taseme meta-priori, mis tagab, et informatsiooni jagatakse gruppide vahel ja samal ajal ka gruppide sees.
Sellise lahenduse õigustus on, et me usume, et erinevad alam-grupid pärinevad samast üli-jaotusest ja neil on omavahel midagi ühist (ehkki alam-gruppide vahel võib olla ka reaalseid erinevusi).
Näiteks, et kõik klassid saavad oma lapsed samast lastepopulatsioonist, aga siiski, et leidub ka eriklasse eriti andekatele.</p>
<p>Selline mudel tagab, et samamoodi nagu mudeli ennustused individaalsete andmepunktide kohta iga alam-grupi sees “liiguvad lähemale” oma alam-grupi keskmisele, samamoodi liiguvad ka alam-gruppide keskmised lähemale üldisele grupi keskmisele.
Selle positiivne mõju on valealarmide vähendamine ja oht on, et me kaotame ka tõelisi efekte.
Bayesi eelis on, et see oht realiseerub ainult niipalju, kuipalju meie mudel ei kajasta reaalset katse struktuuri. Klassikalises statistikas rakendatavad multiple testingu korrektsioonid (Bonfferroni, ANOVA jt) on kõik teoreetiliselt kehvemad.</p>
<p>Lihtsaim shrinkage mudeli tüüp on mudel, kus me laseme vabaks interceptid, aga mitte tõusunurgad.
Igale klastrile vastab mudelis oma intercepti parameeter ja oma intercepti prior. Lisaks annab mudel meile fittimise käigus valimi andmete põhjal ise parameetrid kõrgema taseme priorisse, mis on ühine kõikidele interceptidele.
Seega me määrame korraga interceptide parameetrid ja kõrgema taseme priori parameetrid, mis tähendab, et informatsioon liigub mudelit fittides mõlemat pidi — mööda hierarhiat alt ülesse ja ülevalt alla.
Selline mudel usub, et erinevate koolide keskmine tase erineb (seda näitab iga kooli intercept), aga juhul kui me mõõdame näiteks kalamaksaõli mõju õppeedukusele, siis selle mõju suurus ei erine koolide vahel (kõikide koolide tõusuparameetrid on identsed).</p>
<blockquote>
<p>Shrinkage kui nähtuse avastas Francis Galton 1870-ndatel aastatel. Galton ja tema sõbrad veetsid nimelt kümme aastat üle Inglismaa taimi kasvatades ja mõõtes erinevate põlvkondade seemnete suurusi. Eesmärk oli luua tühjale kohale uus teadus, pidevate tunnuste geneetika, ja katsete tulemus oli rabav. Nimelt leiti tugev seaduspära, mille kohaselt suurte seemnetega emataimede tütred andsid keskeltläbi väiksemaid seemneid kui nende vanemad ja vastupidi, väikeste seemnetega emade tütred andsid keskeltläbi suuremaid seemneid. Galtoni usk, et ta on avastanud tähtsa bioloogiaseaduse, purunes ca 1885, kui ta pääses analüüsima tuhatkonna inimese pikkusi andmestikus, mis sisaldas vanemate ja täiskasvanud laste pikkusi, ning leidis seal sama nähtuse. Sertifitseeritud geeniusena mõistis Galton, et ta ei olnud avastanud mitte niivõrd geneetikaseaduse, vaid peaaegu, et loogikaseaduse. Tema enda sõnadega: The average regression of the offspring to a constant fraction of their mid-parental deviations, is now shown to be a perfectly reasonable law which might have been deductively foreseen. It is of so simple a character that I have made an arrangement with pulleys and weights by which the probable average height of the children of known parents can be mechanically reckoned. (vt joonis). Sellega avastas Galton regressiooni keskmisele, mis on sisuliselt sama asi, mis shrinkage. Galton nägi, et shrinkagel on järgmised omadused:
1. “The mean filial regression towards mediocrity was directly proportional to the parental deviation from it.” Ehk, mida kaugemal on vanemad keskmisest, seda suurema amplituudiga on nende laste shrinkage
2. “The child inherits partly from his parents, partly from his ancestry. …the further his genealogy goes back, the more numerous and varied will his ancestry become … Their mean stature will then be the same as that of the race; in other words, it will be mediocre.” Ehk, shrinkage toimub alati, kui tunnuse väärtus ei ole deterministlikult määratud (shrinkage taandub korrelatsioonile vanemate ja laste varieeruvuse vahel)
3. “This law tells heavily against the full hereditary transmission of any gift. The more exceptional the amount of the gift, the more exceptional will be the good fortune of a parent who has a son who equals him in that respect.” Ehk, pidevate tunnuste korral on korrelatsioon alati &lt;1 &amp; &gt;-1
4. “The law is even-handed; it levies the same heavy succession-tax on the transmission of badness as well as of goodness. If it discourages the extravagant expectations of gifted parents that their children will inherit all their powers, it no less discountenances extravagant fears that they will inherit all their weaknesses and diseases.” Ehk shrinkage töötab võrdselt mõlemas suunas (ülevalt alla ja alt üles, aga ka vanematelt lastele ja lastelt vanematele). Seega ei ole shrinkage ajas toimuv, põhjuslik, ega isegi mitte füüsikaline protsess, vaid tõenäosusteooriast tulenev loogiline paratamatus.
Samamoodi nagu shrinkage esineb vanemate-laste vahel esineb see ka valimi-kordusvalimi vahel kõigi valimite keskmise suunas (valimiefektid taanduvad välja sedamõõda, kuidas valimeid juurde tuleb). Ja samamoodi, kui me võtame valimi testitulemusi mitmest koolist, siis eeldusel, et õpilased on kõikides koolides sarnased (aga mitte identsed), toimub shrinkage kõikide koolide keskmise suunas. Seega, nihutades mingi kooli keskmist testitulemust koolide keskmise suunas, saame parema hinnangu selle kooli õpilaste teadmisetele kui pelgalt selles koolis õpilaste teadmisi mõõtes!</p>
</blockquote>
<div class="figure"><span id="fig:parun"></span>
<img src="img/galton.jpg" alt="(ref:Galton (1886), The Journal of the Anthropological Institute of Great Britain and Ireland, Vol. 15, pp. 246-263)" width="150%" />
<p class="caption">
Joonis 11.3: (ref:Galton (1886), The Journal of the Anthropological Institute of Great Britain and Ireland, Vol. 15, pp. 246-263)
</p>
</div>
</div>
</div>
<div id="anova-laadne-mudel" class="section level2">
<h2><span class="header-section-number">20.5</span> ANOVA-laadne mudel</h2>
<p>Lihtne ANOVA on sageduslik test, mis võrdleb gruppide keskmisi mitmese testimise kontekstis.
Siin ehitame selle Bayesi analoogi, mis samuti hindab gruppide keskmisi mitmese testimise kontekstis.
Põhiline erinevus seisneb selles, et kui ANOVA punktennustus iga grupi keskväärtusele võrdub valimi keskväärtusega ja ANOVA pelgalt kohandab usaldusintervalle selle keskväärtuse ümber, siis bayesiaanlik mudel püüab ennustada igale grupile selle tegelikku kõige tõenäolisemat keskväärtust arvestades kõigi gruppide andmeid.
Shrinkage-i roll on ekstreemseid gruppe “tagasi tõmmates” vähendada ebakindlust iga grupi keskmise ennustuse ümber.
Shrinkage käigus tõmmatakse gruppe kõikide gruppide keskmise poole seda tugevamalt, mida kaugemal nad sellest keskmisest on.
Sellega kaasneb paratamatult mõningane süstemaatiline viga, kus tõelised efektid tulevad välja väiksematena, kui nad tegelikult on.
Kui ilma tegelike efektideta gruppide arv on väga suur võrreldes päris efektidega gruppidega, siis võib shrinkage meie pärisefektid sootuks ära kaotada.
Kahjuks on see loogiline paratamatus; alternatiiviks on olukord, kus meie üksikud pärisefektid upuvad sama suurte pseudoefektide merre.</p>
<p>Ok, aitab mulast, laadime vajalikud raamatukogud ja andmed ning vaatame mis saab.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(stringr)
<span class="kw">library</span>(rethinking)
<span class="kw">library</span>(psych)</code></pre>
<p>Andmed: <em>The data contain GCSE exam scores on a science subject. Two components of the exam were chosen as outcome variables: written paper and course work. There are 1,905 students from 73 schools in England. Five fields are as follows.</em></p>
<ol style="list-style-type: decimal">
<li><p>School ID</p></li>
<li><p>Student ID</p></li>
<li><p>Gender of student</p></li>
</ol>
<p>0 = boy</p>
<p>1 = girl</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Total score of written paper</p></li>
<li><p>Total score of coursework paper</p></li>
</ol>
<p>Missing values are coded as -1.</p>
<pre class="sourceCode r"><code class="sourceCode r">schools &lt;-<span class="st"> </span><span class="kw">read_csv</span>( <span class="st">&quot;data/schools.csv&quot;</span>)
schools &lt;-<span class="st"> </span>schools <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">complete.cases</span>(.)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(sex, school), as.factor)
<span class="co">## map2stan requires data.frame</span>
<span class="kw">class</span>(schools) &lt;-<span class="st"> &quot;data.frame&quot;</span></code></pre>
<p>Alustuseks mitte-hierarhiline mudel, mis arvutab keskmise score1 igale koolile eraldi. See on intercept-only mudel, mis tähendab, et me hindame testitulemuse keskväärtust kooli kaupa ja igale koolile sõltumatult kõigist teistest koolidest. Me ei püüa siin ennustada testitulemuste väärtusi x-i väärtuste põhjal. Selles mudelis on tavapärased ühetasemelised priorid, ainult mu on ümber nimetatud a_school-iks ja sellele on antud indeks [school], mis tähendab, et mudel arvutab a_school-i, ehk keskmise testitulemuse, igale koolile. Kuna siin puuduvad kõrgema taseme priorid, siis vaatab mudel igat kooli eraldi ja ühegi kooli hinnang ei arvesta ühegi teise kooli andmetega.</p>
<pre class="sourceCode r"><code class="sourceCode r">schoolm2 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),
    mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>v_Intercept[school],
    Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">50</span>),
    v_Intercept[school] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">50</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>)
  ), <span class="dt">data =</span> schools)</code></pre>
<p>Vaata koefitsente.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schoolm2, <span class="dt">depth =</span> <span class="dv">2</span>)</code></pre>
<p>Igale koolile antud hinnang on sõltumatu kõigist teistest koolidest.</p>
<p>Ja nüüd hierarhiline mudel, mis teab koolide vahelisest varieeruvusest. Siin leiab a_school-i priorist teise taseme meta-parameetri nimega sigma_school, millele on defineeritud oma meta-prior.</p>
<pre class="sourceCode r"><code class="sourceCode r">schoolm3 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
  score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),
  mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>v_Intercept[school],
  Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">50</span>),
  v_Intercept[school] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, sigma_school),
  sigma_school <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>),
  sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>)
), <span class="dt">data =</span> schools)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schoolm3, <span class="dt">depth =</span> <span class="dv">2</span>)</code></pre>
<p>Nagu näha on sigma_school &lt; sigma, mis tähendab, et koolide vaheline varieeruvus on väiksem kui õpilaste vaheline varieeruvus neis koolides. Seega sõltub testi tulemus rohkem sellest, kes testi teeb kui sellest, mis koolis ta käib. Loogika on siin järgmine: samamoodi nagu testitulemustel on jaotus õpilasekaupa, on neil ka jaotus koolikaupa. Koolikaupa jaotus töötab priorina õpilasekaupa jaotusele. Aga samas vajab kooli kaupa jaotus oma priorit — ehk meta-priorit. Seega saame me samast mudelist hinnangu nii testitulemustele kõikvõimalike õpilaste lõikes, kui ka kõikvõimalike koolide lõikes. Mudel ennustab ka nende koolide ja õpilaste tulemusi, keda tegelikult olemas ei ole, aga kes võiksid kunagi sündida.</p>
<p>Ning veel üks hierarhiline mudel, mis teab nii koolide skooride keskmiste varieeruvust kui koolide vahelist varieeruvust.</p>
<p>Võrdleme mudeleid.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compare</span>(schoolm2, schoolm3)</code></pre>
<p>Siit nähtub, et m3 on parim mudel, aga ka m2 omab mingit kaalu.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coeftab_plot</span>(<span class="kw">coeftab</span>(schoolm2, schoolm3), <span class="dt">cex =</span> <span class="fl">0.5</span>)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-14"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-14-1.png" alt="Mudelite koefitsiendid." width="672" />
<p class="caption">
Joonis 4.6: Mudelite koefitsiendid.
</p>
</div>
<p>Siin on hästi näha shrinkage m3 puhul võrreldes m2-ga, mis ei tee multiple testingu korrektsiooni.
Nende koolide puhul, kus usaldusintervall on laiem, on ka suurem shrinkage (mudel võtab nende kohta suhteliselt rohkem infot teistest koolidest sest need koolid ise on mingil põhjusel suhteliselt infovaesed).</p>
</div>
<div id="vabad-interceptid-klassikalises-regressioonimudelis" class="section level2">
<h2><span class="header-section-number">20.6</span> Vabad interceptid klassikalises regressioonimudelis</h2>
<p>Ennustame score1 sõltuvust sex-ist. Küsimus: kui palju poiste ja tüdrukute matemaatikaoskused erinevad? Fitime mudeli, mis laseb vabaks intercepti. <strong>Selle mudeli eeldus on, et igal koolil on oma baastase (oma intercept), aga kõikide koolide efektid (mudeli tõusu-koefitsient) on identsed.</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describe</span>(schools)
<span class="co">#&gt;         vars    n    mean      sd median trimmed   mad  min  max  range</span>
<span class="co">#&gt; school*    1 1523   38.36   19.98   40.0   38.84  23.7 1.00   73   72.0</span>
<span class="co">#&gt; student    2 1523 1016.45 1836.14  129.0  628.65 124.5 1.00 5516 5515.0</span>
<span class="co">#&gt; sex*       3 1523    1.59    0.49    2.0    1.61   0.0 1.00    2    1.0</span>
<span class="co">#&gt; score1     4 1523   46.50   13.48   46.0   46.68  13.3 0.60   90   89.4</span>
<span class="co">#&gt; score2     5 1523   73.38   16.44   75.9   74.65  16.5 9.25  100   90.8</span>
<span class="co">#&gt;          skew kurtosis    se</span>
<span class="co">#&gt; school* -0.18    -1.08  0.51</span>
<span class="co">#&gt; student  1.69     0.98 47.05</span>
<span class="co">#&gt; sex*    -0.37    -1.87  0.01</span>
<span class="co">#&gt; score1  -0.12    -0.05  0.35</span>
<span class="co">#&gt; score2  -0.75     0.51  0.42</span></code></pre>
<p>Me kasutame prediktorina binaarset kategoorilist muutujat. See on analoogiline olukord ANOVA mudelile, mis võtab arvesse multiple testingu olukorra, mis meil siin on.</p>
<pre class="sourceCode r"><code class="sourceCode r">schools_f1 &lt;-<span class="st"> </span><span class="kw">glimmer</span>(score1 <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> schools)
<span class="co">#&gt; alist(</span>
<span class="co">#&gt;     score1 ~ dnorm( mu , sigma ),</span>
<span class="co">#&gt;     mu &lt;- Intercept +</span>
<span class="co">#&gt;         b_sex1*sex1 +</span>
<span class="co">#&gt;         v_Intercept[school],</span>
<span class="co">#&gt;     Intercept ~ dnorm(0,10),</span>
<span class="co">#&gt;     b_sex1 ~ dnorm(0,10),</span>
<span class="co">#&gt;     v_Intercept[school] ~ dnorm(0,sigma_school),</span>
<span class="co">#&gt;     sigma_school ~ dcauchy(0,2),</span>
<span class="co">#&gt;     sigma ~ dcauchy(0,2)</span>
<span class="co">#&gt; )</span></code></pre>
<p>Kuna glimmeri priorite parametriseeringud on vales skaalas (liiga väikesed), muudame neid nii, et intercept (keskmine testitulemus üle koolide) oleks tsentreeritud 50-le (max testi tulemus on 100) ja standardhälve on 20. Igaks juhuks tõstame veidi ka beta koefitsiendi priori sigmat. v_intercept peaks olema alati nullile tsentreeritud.</p>
<p>Glimmeri väljundis on sama palju koolide veerge, kui palju on erinevaid koole, miinus üks. Selline binaarne numbriline väljund on Stani-le vajalik. Seega ei saa me faktortunnuste korral kasutada algset andmetabelit.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(schools_f1<span class="op">$</span>d)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">schools_m1 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
    score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu , sigma ),
    mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>b_sex1<span class="op">*</span>sex1 <span class="op">+</span><span class="st"> </span>v_Intercept[school],
    Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">50</span>, <span class="dv">20</span>),
    b_sex1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">15</span>),
    v_Intercept[school] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, sigma_school),
    sigma_school <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>,<span class="dv">2</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>,<span class="dv">2</span>)
), <span class="dt">data =</span> schools_f1<span class="op">$</span>d) <span class="co"># use the data table generated by glimmer() </span>
<span class="co">#glimmer converts factors to Stan-eatable form.</span></code></pre>
<p>Siin on v_Intercept kooli-spetsiifiline korrektsioonifaktor, mis tuleb liita üldisele Interceptile. mean(v_Intercept) == 0. Me eeldame, et korrektsioonid on normaaljaotusega.
Alternatiivne viis seda mudelit kirjutada oleks <code>mu &lt;- Intercept[school] + b_sex1*sex1</code> ja see töötab smamoodi (nüüd on iga kooli intercept kohe eraldi).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">precis</span>(schools_m1, <span class="dt">depth =</span> <span class="dv">2</span>), <span class="dt">cex =</span> <span class="fl">0.5</span>)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-20-1.png" alt="Mudeli koefitsiendid" width="672" />
<p class="caption">
Joonis 17.2: Mudeli koefitsiendid
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schools_m1)
<span class="co">#&gt;               Mean StdDev lower 0.89 upper 0.89 n_eff Rhat</span>
<span class="co">#&gt; Intercept    49.21   0.98      47.89      51.01   227    1</span>
<span class="co">#&gt; b_sex1       -2.44   0.60      -3.37      -1.52  1000    1</span>
<span class="co">#&gt; sigma_school  7.06   0.71       5.87       8.09  1000    1</span>
<span class="co">#&gt; sigma        11.18   0.20      10.85      11.50  1000    1</span></code></pre>
<p>sex = 1 ehk sex1 on tüdruk.</p>
<p>Intercept annab siin sex = 0 (poisid) keskmise skoori kooli kaupa (kui liita üldisele interceptile kooli-spetsiifiline intercept). Kui tahame näiteks hinnangut 2. kooli tüdrukute skoorile (ehk tõelisele matemaatikavõimekusele) siis:</p>
<p><code>Intercept + b_sex1 + intercept[2]</code></p>
<p>annab meile selle posteeriori. Poistele sama 2. kooli kohta:</p>
<p><code>Intercept + intercept[2]</code></p>
<p>Ja poiste-tüdrukute erinevus skooripunktides võrdub</p>
<p><code>b_sex1</code></p>
<p>Arvutame siis kooli nr 2 tüdrukute keskmise skoori posteeriori.</p>
<pre class="sourceCode r"><code class="sourceCode r">schools_m1_samples &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(schools_m1<span class="op">@</span>stanfit)
school_<span class="dv">2</span>_girls &lt;-<span class="st"> </span>schools_m1_samples<span class="op">$</span>Intercept <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>schools_m1_samples<span class="op">$</span>b_sex1 <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>schools_m1_samples<span class="op">$</span><span class="st">`</span><span class="dt">v_Intercept[2]</span><span class="st">`</span>
<span class="co">## Plot density histogram of intercepts</span>
<span class="kw">dens</span>(school_<span class="dv">2</span>_girls)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-22"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-22-1.png" alt="Tüdrukute skoori posteerior" width="672" />
<p class="caption">
Joonis 20.1: Tüdrukute skoori posteerior
</p>
</div>
<p>Ja Poiste oma</p>
<pre class="sourceCode r"><code class="sourceCode r">school_<span class="dv">2</span>_boys &lt;-<span class="st"> </span>schools_m1_samples<span class="op">$</span>Intercept <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>schools_m1_samples<span class="op">$</span><span class="st">`</span><span class="dt">v_Intercept[2]</span><span class="st">`</span>
<span class="co">## Plot density histogram of intercepts</span>
<span class="kw">dens</span>(school_<span class="dv">2</span>_boys)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-23-1.png" alt="Poiste skoori posteerior." width="672" />
<p class="caption">
Joonis 19.3: Poiste skoori posteerior.
</p>
</div>
<p>Siin on eeldus, et kõikides koolides on sama poiste ja tüdrukute vaheline erinevus (b_sex1), kuid erinevad matemaatikateadmiste baastasemed (mudeli intercept on koolide vahel vabaks lastud, kuid tõus mitte).</p>
</div>
<div id="vabad-tousud-ja-interceptid" class="section level2">
<h2><span class="header-section-number">20.7</span> Vabad tõusud ja interceptid</h2>
<p>Milline näeb välja mudel, kus me laseme vabaks nii intercepti kui tõusu?</p>
<pre class="sourceCode r"><code class="sourceCode r">schools_f2 &lt;-<span class="st"> </span><span class="kw">glimmer</span>(score1 <span class="op">~</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>sex <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> schools)
<span class="co">#&gt; alist(</span>
<span class="co">#&gt;     score1 ~ dnorm( mu , sigma ),</span>
<span class="co">#&gt;     mu &lt;- Intercept +</span>
<span class="co">#&gt;         b_sex1*sex1 +</span>
<span class="co">#&gt;         v_Intercept[school] +</span>
<span class="co">#&gt;         v_sex1[school]*sex1,</span>
<span class="co">#&gt;     Intercept ~ dnorm(0,10),</span>
<span class="co">#&gt;     b_sex1 ~ dnorm(0,10),</span>
<span class="co">#&gt;     c(v_Intercept,v_sex1)[school] ~ dmvnorm2(0,sigma_school,Rho_school),</span>
<span class="co">#&gt;     sigma_school ~ dcauchy(0,2),</span>
<span class="co">#&gt;     Rho_school ~ dlkjcorr(2),</span>
<span class="co">#&gt;     sigma ~ dcauchy(0,2)</span>
<span class="co">#&gt; )</span></code></pre>
<p>nüüd on meil lisaparameetrid v_sex1, mis annab tõusu igale koolile eraldi ning Rho-school, mis annab korrelatsiooni intercepti ja tõusu vahel. Nüüd me jagame informatsiooni erinevat tüüpi parameetrite, nimelt interceptide ja tõusude, vahel. Selleks ongi vaja Rho lisa-parameetrit. Nüüd ei modelleeri me intercepti ja tõusu enam 2 eraldi normaaljaotuste abil vaid ühe 2-dimensionaalse normaaljaotusega (mvnorm2).</p>
<p>Prior korrelatsioonile Interceptide ja tõusude vahel on <code>rethinking::lkjcorr()</code>.
Selle ainus parameeter on K.
Mida suurem K, seda rohkem on prior konsentreeritud 0 korrelatsiooni ümber. K = 1 annab tasase priori.
Meie kasutame K = 2, mis töötab laia vahemiku mudelitega.</p>
<pre class="sourceCode r"><code class="sourceCode r">R &lt;-<span class="st"> </span><span class="kw">rlkjcorr</span>(<span class="fl">1e4</span>, <span class="dt">K =</span> <span class="dv">2</span>, <span class="dt">eta =</span> <span class="dv">2</span>)
<span class="kw">dens</span>(R[, <span class="dv">1</span>, <span class="dv">2</span>] , <span class="dt">xlab =</span> <span class="st">&quot;correlation&quot;</span>)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-25"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-25-1.png" alt="Korrelatsiooni prior on nõrgalt informatiivne -- suunab posteeriori eemale ekstreemsetest korrelatsioonidest." width="672" />
<p class="caption">
Joonis 4.8: Korrelatsiooni prior on nõrgalt informatiivne – suunab posteeriori eemale ekstreemsetest korrelatsioonidest.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">schools_m2 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
    score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu , sigma ),
    mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span>
<span class="st">        </span>b_sex1<span class="op">*</span>sex1 <span class="op">+</span>
<span class="st">        </span>v_Intercept[school] <span class="op">+</span>
<span class="st">        </span>v_sex1[school]<span class="op">*</span>sex1,
    Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">50</span>, <span class="dv">20</span>),
    b_sex1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">20</span>),
    <span class="kw">c</span>(v_Intercept,v_sex1)[school] <span class="op">~</span><span class="st"> </span><span class="kw">dmvnorm2</span>(<span class="dv">0</span>, sigma_school, Rho_school),
    sigma_school <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>,<span class="dv">2</span>),
    Rho_school <span class="op">~</span><span class="st"> </span><span class="kw">dlkjcorr</span>(<span class="dv">2</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>,<span class="dv">2</span>)
), schools_f2<span class="op">$</span>d)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">precis</span>(schools_m2, <span class="dt">depth =</span> <span class="dv">2</span>), <span class="dt">cex =</span> <span class="fl">0.5</span>)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-28"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-28-1.png" alt="Mudeli m2 koefitsiendid." width="672" />
<p class="caption">
Joonis 20.2: Mudeli m2 koefitsiendid.
</p>
</div>
<p>Posteerior korrelatsioonile intercepti ja tõusu vahel:</p>
<pre class="sourceCode r"><code class="sourceCode r">schools_m2_samples &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(schools_m2)
df1 &lt;-<span class="st"> </span>schools_m2_samples<span class="op">$</span>Rho_school <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()
<span class="co">#df1 #corr matrix- we need only the V2 col</span>
<span class="kw">dens</span>(df1<span class="op">$</span>V2)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-29"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-29-1.png" alt="Posteerior korrelatsioonile intercepti ja tõusu vahel." width="672" />
<p class="caption">
Joonis 19.4: Posteerior korrelatsioonile intercepti ja tõusu vahel.
</p>
</div>
<p>Meil on negatiivne korrelatsioon intercepti ja tõusu vahel. Seega, mida väiksem on poiste keskmine skoor koolis (=intercept), seda suurem om erinevus poiste ja tüdrukute skooride vahel (= tõus).</p>
<p>Nüüd saab 2. kooli skoori tüdrukutele valemiga:</p>
<p><em>Intercept + b_sex1 + v_intercept[2] + v_sex1[2]</em></p>
<p>Sama skoor poistele:</p>
<p><em>Intercept + v_intercept[2]</em></p>
<p>ja tüdrukute ja poiste erinevus 2. koolile:</p>
<p><em>b_sex1 + v_sex1[2]</em></p>
<p>tüdrukute-poiste erinevus üle kõikide koolide:</p>
<p><em>b_sex1</em></p>
<p>tüdrukute keskmine skoor üle kõikide koolide:</p>
<p><em>Intercept + b_sex1</em></p>
<p>ja poiste keskmine skoor üle kõikide koolide:</p>
<p><em>Intercept</em></p>
<p>Tõmbame mudelist ennustused 1., 2. ja 37. kooli poiste skooridele järgmisel semestril:</p>
<pre class="sourceCode r"><code class="sourceCode r">d.pred &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">school =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">37</span>),
  <span class="dt">sex1 =</span> <span class="dv">0</span>
)

schools_sim &lt;-<span class="st"> </span>rethinking<span class="op">::</span><span class="kw">sim</span>(schoolm2, <span class="dt">data =</span> d.pred) 
<span class="co">#&gt; [ 100 / 1000 ]</span>
[ <span class="dv">200</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">300</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">400</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">500</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">600</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">700</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">800</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">900</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
pred.p &lt;-<span class="st"> </span><span class="kw">apply</span>(schools_sim, <span class="dv">2</span>, mean)
pred.p.PI &lt;-<span class="st"> </span><span class="kw">apply</span>(schools_sim, <span class="dv">2</span> , PI)</code></pre>
<p>NB! kasutades <code>rethinking::sim()</code> saame me enustused andmepunktide (üksikute poiste tasemel).
Antud juhul jääb ennustuse kohaselt esimeses koolis 89% individuaalseid skoore vahemikku 61-132 punkti 200-st võimalikust.</p>
<p>Kui meid huvitab hoopis nende koolide keskmine skoor järgmisel semestril, siis kasuta <code>rethinking::sim()</code> asemel <code>rethinking::link()</code> funktsiooni.</p>
<pre class="sourceCode r"><code class="sourceCode r">schools_sim &lt;-<span class="st"> </span><span class="kw">link</span>(schools_m2, <span class="dt">data =</span> d.pred) 
<span class="co">#&gt; [ 100 / 1000 ]</span>
[ <span class="dv">200</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">300</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">400</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">500</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">600</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">700</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">800</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">900</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
[ <span class="dv">1000</span> <span class="op">/</span><span class="st"> </span><span class="dv">1000</span> ]
pred.p &lt;-<span class="st"> </span><span class="kw">apply</span>(schools_sim, <span class="dv">2</span>, mean)
pred.p.PI &lt;-<span class="st"> </span><span class="kw">apply</span>(schools_sim, <span class="dv">2</span>, PI)
pred.p.PI
<span class="co">#&gt;     [,1] [,2] [,3]</span>
<span class="co">#&gt; 5%  32.6 34.4 44.3</span>
<span class="co">#&gt; 94% 46.2 39.9 49.7</span></code></pre>
<p>Esimeses koolis jääb keskmine poiste skoor 89% tõenäosusega vahemikku 33 kuni 46 punkti.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compare</span>(schools_m1, schools_m2)
<span class="co">#&gt;             WAIC pWAIC dWAIC weight   SE  dSE</span>
<span class="co">#&gt; schools_m1 11734  55.8   0.0    0.7 57.2   NA</span>
<span class="co">#&gt; schools_m2 11736  60.8   1.7    0.3 57.2 1.38</span></code></pre>
<p>Tundub, et tõusude vabakslaskmine oli hea mõte.
Ma saan hästi pihta, et erinevad koolid õpetavad matemaatikat erineva kvaliteediga.
Aga miks peaks erinevates Inglismaa koolides olema erinev vahe poiste ja tüdrukute matemaatikateadmistel?
Kas olukorras kus meil on hea kool, läheb see vahe väiksemaks või suuremaks?
Tehke kindlaks!!! võrrelge graafiku slope vs. intercept.</p>
<div class="figure"><span id="fig:unnamed-chunk-33"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-33-1.png" alt="mida suurem on koolis poiste skoor, seda väiksem on poiste ja tüdrukute erinevus" width="672" />
<p class="caption">
Joonis 16.13: mida suurem on koolis poiste skoor, seda väiksem on poiste ja tüdrukute erinevus
</p>
</div>
<p>Tõepoolest: mida suurem on koolis poiste skoor (parem kool), seda väiksem on poiste ja tüdrukute erinevus. Aga seos on kaunis nõrk!</p>
<p>Muide sel joonisel tähendavad negatiivsed väärtused alla keskmist väärtust, mitte tingimata negatiivset erinevust või negatiivset skoori. Miks?</p>
<p>Arvutage nüüd poiste ja tüdrukute keskmine skoor kooli kaupa ja vaadake uuesti sõltuvust samasse erinevusesse. Mis on õigem viis: kas fittida ilma interceptita mudel (nagu eelmises peatükis) ja kasutada otse selle koefitsiente või kasutada meie m2 mudelit ning arvutada selle mudeli koefitsientide põhjal uus statistik (kaalutud keskmine näiteks)? Miks?</p>
</div>
<div id="hierarhiline-mudel-pidevate-prediktoritega" class="section level2">
<h2><span class="header-section-number">20.8</span> Hierarhiline mudel pidevate prediktoritega</h2>
<p>Siin püüame ennustada score1 mõju score2 väärtusele.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(schools<span class="op">$</span>score2, schools<span class="op">$</span>score1)
<span class="kw">abline</span>(<span class="kw">lm</span>(score1 <span class="op">~</span><span class="st"> </span>score2, <span class="dt">data =</span> schools))</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-34"></span>
<img src="16_hierarhiline_mudel_files/figure-html/unnamed-chunk-34-1.png" alt="score1 vs. score2" width="672" />
<p class="caption">
Joonis 20.3: score1 vs. score2
</p>
</div>
<p>Kõigepealt lihtne regressioon <code>lm()</code> funktsiooniga (see ei ole hierarhiline mudel).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(score1 <span class="op">~</span><span class="st"> </span>score2, <span class="dt">data =</span> schools)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = score1 ~ score2, data = schools)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)       score2  </span>
<span class="co">#&gt;      17.971        0.389</span></code></pre>
<p>score2 tõus 1 punkti võrra tõstab score1-e 0.39 punkti võrra.</p>
<p>Modelleerime seost üle Bayesi hierarhilise mudeli, kus ainult Intercept on vabaks lastud.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimmer</span>(score1 <span class="op">~</span><span class="st"> </span>score2 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> schools)
<span class="co">#&gt; alist(</span>
<span class="co">#&gt;     score1 ~ dnorm( mu , sigma ),</span>
<span class="co">#&gt;     mu &lt;- Intercept +</span>
<span class="co">#&gt;         b_score2*score2 +</span>
<span class="co">#&gt;         v_Intercept[school],</span>
<span class="co">#&gt;     Intercept ~ dnorm(0,10),</span>
<span class="co">#&gt;     b_score2 ~ dnorm(0,10),</span>
<span class="co">#&gt;     v_Intercept[school] ~ dnorm(0,sigma_school),</span>
<span class="co">#&gt;     sigma_school ~ dcauchy(0,2),</span>
<span class="co">#&gt;     sigma ~ dcauchy(0,2)</span>
<span class="co">#&gt; )</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">schoolm7 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
    score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),
    mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span>
<span class="st">        </span>b_score2 <span class="op">*</span><span class="st"> </span>score2 <span class="op">+</span>
<span class="st">        </span>v_Intercept[school],
    Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">50</span>, <span class="dv">50</span>),
    b_score2 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),
    v_Intercept[school] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, sigma_school),
    sigma_school <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>)
), <span class="dt">data =</span> schools)</code></pre>
<p>Siin ei ole individuaalsed interceptid tõlgenduslikult informatiivsed, aga nende sissepanek parandab mudeli ennustust beta koefitsiendile (beta läheb väiksemaks ja ebakindlus selle hinnangu ümber kasvab).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schoolm7, <span class="dt">depth =</span> <span class="dv">2</span>)</code></pre>
<p>Siin tuleb beta veidi väiksem - 0.36. Kuna sigma_school &lt; sigma, siis tundub, et koolide vaheline varieeruvus on väiksem kui laste vaheline varieeruvus (sigma on üle kõigi koolide). iga kooli baastase tuleb Intercept + v_Intercept[] aga selle mudeli järgi on kõikide koolide score2 ja score1 sõltuvus sama tugevusega.</p>
<p>Laseme siis ka tõusud vabaks</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimmer</span>(score1 <span class="op">~</span><span class="st"> </span>score2 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st">  </span>score2 <span class="op">|</span><span class="st"> </span>school), <span class="dt">data =</span> schools)
<span class="co">#&gt; alist(</span>
<span class="co">#&gt;     score1 ~ dnorm( mu , sigma ),</span>
<span class="co">#&gt;     mu &lt;- Intercept +</span>
<span class="co">#&gt;         b_score2*score2 +</span>
<span class="co">#&gt;         v_Intercept[school] +</span>
<span class="co">#&gt;         v_score2[school]*score2,</span>
<span class="co">#&gt;     Intercept ~ dnorm(0,10),</span>
<span class="co">#&gt;     b_score2 ~ dnorm(0,10),</span>
<span class="co">#&gt;     c(v_Intercept,v_score2)[school] ~ dmvnorm2(0,sigma_school,Rho_school),</span>
<span class="co">#&gt;     sigma_school ~ dcauchy(0,2),</span>
<span class="co">#&gt;     Rho_school ~ dlkjcorr(2),</span>
<span class="co">#&gt;     sigma ~ dcauchy(0,2)</span>
<span class="co">#&gt; )</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r">schoolm5 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
    score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu , sigma ),
    mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>b_score2 <span class="op">*</span><span class="st"> </span>score2 <span class="op">+</span><span class="st"> </span>
<span class="st">      </span>v_Intercept[school] <span class="op">+</span><span class="st"> </span>
<span class="st">      </span>v_score2[school] <span class="op">*</span><span class="st"> </span>score2,
    Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">50</span>, <span class="dv">25</span>),
    b_score2 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),
    <span class="kw">c</span>(v_Intercept, v_score2)[school] <span class="op">~</span><span class="st"> </span><span class="kw">dmvnorm2</span>(<span class="dv">0</span>, sigma_school, Rho_school),
    sigma_school <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>),
    Rho_school <span class="op">~</span><span class="st"> </span><span class="kw">dlkjcorr</span>(<span class="dv">2</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>)
), <span class="dt">data =</span> schools)</code></pre>
<p>nüüd saame igale koolile arvutada oma intercepti ja oma tõusu (ikka samamoodi: Intercept + v_intercept[] ja b_score2 + v_score2[])</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schoolm5, <span class="dt">depth =</span> <span class="dv">2</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">schoolm6 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(<span class="kw">alist</span>(
  score1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu , sigma),
  mu &lt;-<span class="st"> </span>Intercept <span class="op">+</span><span class="st"> </span>b_score2 <span class="op">*</span><span class="st"> </span>score2,
  Intercept <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">50</span>, <span class="dv">50</span>),
  b_score2 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),
  sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>)
), <span class="dt">data =</span> schools)</code></pre>
<p>m2 on selgelt parem mudel, kuigi m3 hinnangud interceptidele on suurema ebakindlusega. beta on nyyd 0.35</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compare</span>(schoolm7, schoolm6, schoolm5)
<span class="co">#&gt;           WAIC pWAIC dWAIC weight   SE  dSE</span>
<span class="co">#&gt; schoolm5 11380  78.4   0.0      1 56.4   NA</span>
<span class="co">#&gt; schoolm7 11416  59.5  35.5      0 56.0 11.6</span>
<span class="co">#&gt; schoolm6 11862   3.3 482.0      0 54.6 41.6</span></code></pre>
<p>0-mudel, mis on kõige kehvem, on kõige suurema betaga ja kõige väiksema ebakindlusega selle ümber. See on tavaline — hierarhiline mudel modelleerib ebakindlust paremini (realistlikumalt) ja vähendab üle-fittimise ohtu (beta tuleb selle võrra väiksem).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(schoolm7, <span class="dt">depth =</span> <span class="dv">2</span>)</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="keerulisemate-mudelitega-tootamine.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="brms.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstats-tartu/bayesiraamat/edit/master/16_hierarhiline_mudel.Rmd",
"text": "Editeeri"
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
