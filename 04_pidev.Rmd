
# Ennustame Pidevat suurust

```{r}
library(tidyverse)
library(modelr)
library(broom)
library(car)
library(gapminder)
library(rethinking)
```

## Lihtne normaaljaotuse mudel

Kui me eelmises peatükis modelleerisime diskreetseid binaarseid sündmusi (elus või surnud) üle binoomjaotuse, siis edasi tegeleme pidevate suurustega ehk parameetritega, millele saab omistada iga väärtuse vahemikus -Inf kuni Inf. 

Proovime veelkord USA presidentide keskmist pikkust ennustada (sama näide oli bootstrappimisel). 
Selleks on meil on vaja kahte asja: (1) tõepära mudelit ning (2) igale tõepära mudeli parameetrile oma priorit.

Selline on täismudeli (tõepära ja priorid) struktuur:
```{r eval=FALSE}
heights ~ dnorm(mu, sigma),  # normal likelihood
mu ~ dnorm(mean = 0, sd = 200), # normal prior for mean
sigma ~ dcauchy(0, 20) #half-cauchy prior for sd 
```

Tõepära on siin modeleeritud normaaljaotusena, milles on 2 tuunitavat parameetrit: mu (keskmine) ja sigma (standardhälve).
Pelgalt nende kahe parameetri fikseerimine annab meile unikaalse normaaljaotuse. 
See, et keskmise pikkuse prior on tsentreeritud nullile viib õige pisukesele (nõnda laia priori juures küll pigem märkamatule) mu hinnangu nihkumisele nulli suunas. 
Selle nihke õigustus on püüd vältida mudeli üle-fittimist ehk teisisõnu ülespoole kallutatud hinnangut keskmisele pikkusele.
Sama hästi võiksime kasutada ka priorit *mu ~ dnorm(mean = 178, sd = 10)*, kus 178 on ameerika meeste keskmine pikkus. 

Alati tasub mudeli priorid välja plottida, et veenduda, et nad tõesti kajastavad meile taustateadmisi ja on sobivas parameetrivahemikus (bayesi programmide default priorid on sageli kas liiga laiad või vastupidi eeldavad, et parameetriväärtused jäävad alla 10 ühiku).

```{r}
x <- 0:100
y <- dcauchy(x, 0, 20)
plot(y ~ x, type = "l" , main = "Cauchy prior for sd")
```

```{r}
x <- 150:200
y <- dnorm(x, 0, 200)
plot(y ~ x, type = "l", main = "Normal prior for mu")
```


```{r}
x <- 150:200
y <- dnorm(x, 178, 10)
plot(y ~ x, type = "l", main = "Another normal prior for mu")
```

Siin on valida kahe priori vahel mu-le. Võib-olla eelistaksid sina mõnda kolmandat? 
Kui jah, siis pole muud kui tee valmis ja kasuta!

Sama hästi võiksime tõepära modelleerida ka mõne muu jaotusega (Studenti t jaotus, eksponentsiaalne jaotus, lognormaaljaotus jne). 
Sel juhul oleksid meil erinevad parameetrid, mida tuunida, aga põhimõte on sama. 
Bayes on modulaarne --- kui sa põhimõtet tead, pole tehniliselt suurt vahet, millist mudelit soovid kasutada.

Näiteks:
```{r eval=FALSE}
heights ~ student_t(nu, mu, sigma) , # t likelihood
nu~ dunif( 1, 100), # uniform prior for the shape parameter
mu ~ dnorm(mean = 0, sd = 200), # normal prior for mean
sigma ~ dcauchy(0, 20) # half-cauchy prior for sd
```

Normaaljaotusel on 2 parameetrit, millele posteerior arvutada: mu (mean) ja sigma (sd). 
Seega on vaja ka kahte priorit, üks mu-le ja teine sigma-le.
Studenti t jaotuse korral lisandub veel üks parameeter: nu ehk jaotuse kuju määrav parameeter. 
nu-d saab tuunida 1 ja lõpmatuse vahel. 
Mida väiksem on nu, seda paksemad tulevad jaotuse sabad. 
Kui nu on suur, siis on t jaotuse kuju sama, mis normaaljaotusel. 
Siin andsime nu-le tasase priori 1 ja 100 vahel, hiljem proovime ka teisi prioreid nu-le.   

Studenti t jaotus on põnev alternatiiv normaaljaotusele, sest see on vähem tundlik outlieritele. 
Kuna normaaljaotus langeb servades väga kiiresti siis, kui meil on mõni andmepunkt, mis jääb jaotuse tipust kaugele, on ainus võimalus selle punkti normaaljaotuse alla mahutamiseks omistada jaotusele väga suur standardhälve. 
See muudab outlierit sisaldava normaaljaotuse ülemäära laiaks, mis viib analüüsis asjatult kaotatud efektidele. 
Seevastu t jaotuse sabasid saab nu abil üles-alla liigutada vastavalt sellele, kas andmed sisaldavad outliereid (selleks tuleb lihtsalt fittida nu parameeter andmete põhjal).

Outlierid toovad meile paksema sabaga jaotuse, mis tipu ümber ei lähe aga kaugeltki nii laiaks, kui samade andmetega fititud normaaljaotus.
    
    
### Kui lai on meie tõepärafunktsioon? 

Normaaljaotusega modelleeritud tõepärafunktsioon on normaaljaotus, mille `keskväärtus = mean(valim)` ja mille `standardhälve = sd(valim) / sqrt(N)`, kus N on valimi suurus. 
See tõepärafunktsioon modelleerib meie valimi keskväärtuse kohtamise tõenäosust igal võimalikul parameetriväärtusel. 
Kui oleme huvitatud USA presidentide keskmisest pikkusest, siis tõepärafunktsioon ütleb iga võimaliku pikkuse kohta, millise tõenäosusega kohtaksime oma valimi keskväärtust juhul, kui just see oleks tegelik presidentide keskmine pikkus. 
Sigma, mille posteeriori me mudelist arvutame, on aga standardhälve algsete andmepunktide tasemel. 
See on väga oluline eristus, sest sigma kaudu saab simueerida uusi andmepunkte.  

### Lihtne või robustne normaalne mudel? 

Proovime mudeldada simuleeritud andmete keskväärtust.

```{r}
set.seed(890775)
a <- rnorm(20, mean = 0, sd = 1) # expected mean = 0, sd = 1
b <- c(a, 5, 9) # plus 2 outliers
```

Siin kasutame andmeid, mille keskväärtus on `r round(mean(a), 2)` ja sd = `r round(sd(a))` ja millele on lisatud kaks outlierit (`r paste(setdiff(b, a), collapse = " ja ")`). Proovime neid andmeid mudeldada normaaljaotusega tõepäramudeliga ja seejärel üle studenti t jaotuse. 
Me fitime 4 mudelit, neist 3 koos outlieritega. 
Mudeli fittimine käib nii, et mcmc ahelad sammuvad parameetriruumis ja iga samm annab meile ühe juhusliku väärtuse posteeriorist. 
Defaultina on meil üks ahel, mis teeb 1000 sammu (seda saab muuta: vt `?map2stan`). 
Kuna ahelad veedavad rohkem aega seal, kus posterioorne tõenäosuspilv on tihedam, siis saab nõnda sämplitud posteeriori juhuvalimi histogrammist posterioorse jaotuse kuju. 
Veelgi enam, selle asemel, et tegeleda posterioorsete jaotuste matemaatilise analüüsiga (integreerimisega) võime analüüsida oma mcmc sämpleid otse, mis tähendab, et kõrgema matemaatika asemel vajame 2. klassi aritmeetikat.

Kõigepealt ilma outlieriteta mudel normaalse tõepärafuktsiooniga. 
Me kasutame sd priorina pool-Cauchy jaotust, mille tipp on 0 kohal ja millel on piisavalt paks saba suuremate numbrite poole.
See on väheinformatiivne prior, mis on nähtud sd-de puhul mcmc algoritmides hästi töötavat. 
Andmed võime `map2stan()` funktsiooni sisestada nii listina kui data.frame-na (aga mitte tibble kujul). 

```{r, eval=FALSE}
# Ilma outlierita andmed
m0 <- map2stan(
  alist(
    y ~ dnorm(mu, sigma),  # normal likelihood
    mu ~ dnorm(0, 5), # normal prior for mean
    sigma ~ dcauchy(0, 2.5) # half-cauchy prior from sd 
  ),
  data = list(y = a))
```

```{r, include=FALSE}
m0 <- readRDS("data/stan_m0.rds")
m0@stanfit
```


Sama mudel, aga outlieritega andmed. `map2stan()` tõlgib sisestatud mudeli Stan keelde ja see mudel kompileeritakse C++ keelde, milles on kodeeritud Stani mcmc mootor. 
Kuna kompileerimine on ajakulukas, kasutame m1 fittimiseks rstan raamatukogu (see loetakse sisse rethinkingu depency-na) ja juba komplieeritud m0 mudelit, millele lisame andmed kahe elemendina: N annab andmete arvu ja y tegelikud andmeväärtused. 
Selline andmete sisestamise viis on omane Stanile - `map2stan()` arvutab ise kapoti all N-i.
```{r, eval=FALSE}
m1 <- stan(fit = m0@stanfit,
           data = list(N = length(b), 
                       y = b),
           chains = 4)
```

```{r, include=FALSE}
m1 <- readRDS("data/stan_m1.rds")
m1
```

Nüüd studenti t jaotusega tõepäramudel. 
Argumendid cores = 4, chains = 4 tähendavad, et me jooksutame 4 mcmc ahelat kasutades selleks oma arvuti 4 tuuma. 
Mudeli m2 juures tähendab argument constraints(list(nu = "lower=1")), et mcmc sämpleri ahelad ei lähe kunagi allapoole ühte. 
See on siin kuna definitsiooni kohaselt ei saa nu olla väiksem kui 1.
Argument start annab listi, mis annab iga parameetri jaoks väärtuse, millest mcmc ahel posteeriori sämplimist alustab. See on vahest vajalik, sest kui mcmc ahelad hakkavad posteeriori tõenäosuspilve otsima kaugel selle tegelikust asukohast n-mõõtmelises ruumis (n = mudeli parameetrite arv), siis võib juhtuda, et mudeli fittimine ebaõnnestub ja te saate veateate. 

```{r, eval=FALSE}
m2 <- map2stan(
  alist(
    y ~ student_t(nu, mu, sigma),
    nu ~ dnorm(5, 10), 
    mu ~ dnorm(0, 5),
    sigma ~ dcauchy(0, 2.5)
    ),
  data = list(y = b),
  constraints = list(nu = "lower=1"),
  start = list(mu = mean(b), sigma = sd(b), nu = 10),
  cores = 4,
  chains = 4
)
```

```{r}
m2 <- readRDS("data/stan_m2.rds")
m2@stanfit
```

Ja viimasena studenti t mudel, kus nu on fikseeritud konstandina. Kuna me ei fiti nu-d mudeli parameetrina, pole meil vaja ka priorit nu-le. Me teeme selle mudeli, sest nu täpsel väärtusel pole väga suurt mõju tulemustele. Me lihtsalt fikseerime nu suvalisele väärtusele, mis annab t jaotusele piisavalt paksud sabad.

```{r, eval=FALSE}
m3 <- map2stan(
  alist(
    y ~ student_t(4, mu, sigma),
    mu ~ dnorm(0, 5),
    sigma ~ dcauchy(0, 2.5)
  ),
  data = list(y = b),
  constraints = list(nu = "lower=1"),
  start = list(mu = mean(b), sigma = sd(b)),
  cores = 4,
  chains = 4)
```


```{r, include=FALSE}
m3 <- readRDS("data/stan_m3.rds")
m3@stanfit
```


Üks esimesi asju mida koos parameetrite vaatamisega teha on lisaks vaadata, kas ka ahelad konvergeerusid.
Selleks saab mugavalt kasutada `rethinking::tracerplot()` funktsiooni.

```{r}
tracerplot(m2)
```

Pildilt on näha, et neli ahelat (4 värvi) on hästi konvergeerunud. Hall ala on nn warmup ala, mille tulemusi ei salvestata. Muidu astub iga ahel sammu kaupa ja iga edukas samm salvestatakse ühe posteeriori väärtusena. Ahel sämplib korraga mu, sigma ja nu väärtusi n-mõõtmelises ruumis (n = mudeli parameetrite arv), mis tähendab, et ahela iga samm salvestatakse n kõrvuti numbrina. 

Kui näit sigma kõrgema väärtusega kaasneb keskeltäbi kõrgem (või madalam) mu väärtus, on sigma ja mu omavahel korreleeritud. 
Et kontrollida parameetrite posterioorsete väärtuste korrelatsioone kasutame funktsiooni `rethinking::pairs()`:

```{r}
pairs(m2)
```

Normaaljaotus on selle poolest eriline, et tema parameetrid mu ja sigma ei ole korreleeritud. 
Paljud teised mudelid ei ole nii lahked. 
Siin on meil mõõdukas korrelatsioon nu ja sigma vahel. 
See on igati loogiline ja ei häiri meid.

### MCMC ahelate kvaliteet

Kui Rhat on 1, siis see tähendab, et MCMC ahelad on ilusti jooksnud ja posteeriori sämplinud. Kui Rhat > 1.1, siis on kuri karjas. Suur Rhat viitab, et ahel(ad) pole jõudnud konvergeeruda. Kui ahelad ei konvergeeru, siis võib karta, et nad ei sämpli ka sama posteeriori jaotust. Kontrolli, kas mudeli kood ei sisalda vigu. Kui ei, siis vahest aitab, kui pikendada warm-up perioodi (map2stan(..., iter= 3000, warmup=2000) pikendab warm-upi 2 korda). Vahest aitab mudeli re-parametriseerimine (siin on lihtne trikk tekitada priorid, mis ei erineks väga palju oma vahemiku poolest; sellega kaasneb sageli andmete tsentreerimine või standardiseerimine; vt allpool).

n_eff on efektiivne valimi suurus, mis hindab iseseisvalt sämplitud andmete arvu ning see ei tohi olla väga väike. Kui n_eff on palju väiksem kui jooksutatud markovi ahela pikkus (iga ahel on defaultina 1000 iteratsiooni pikk), on ahel jooksnud ebaefektiivselt. See ei tähenda tingimata, et posteerior vale oleks. Reegilina peaks Neff/N > 0.1

Ahelad peavad plotitud kujul välja nägema nagu karvased tõugud, mis on ilma paljaste laikudeta.
Kui ahelad omavad pikki sirgeid lõike (n_eff tuleb siis väga madal), kus ahel ei ole töötanud, siis see rikub korralikult posteeriori. Tüüpiliselt aitavad nõrgalt informatiivsed priorid --- priorite õige valik on sama palju arvutuslik vajadus kui taustainfo lisamine. Igal juhul tuleb vältida aladefineeritud tasaseid prioreid, mis võimaldavad ahelatel sämplida lõpmatust ja sel viisil õige tee kaotada. Peale selle, tasased priorid, mis ütlevad, et kõik parameetri väärtused on võrdselt tõenäolised, kajastavad harva meie tegelikke taustateadmisi.

halvad WARNING-ud: divergent transitions (too many), BMFI too low --- võivad tähendada, et ahelad ei tööta korralikult. WARNING-ute kohta saad abi siit http://mc-stan.org/misc/warnings.html.

Ilusamad parameetriplotid saab kasutades "bayesplot" raamatukogu funktsioone.

Esiteks usalduspiirid:
```{r}
library(bayesplot)
fit2d <- as.data.frame(m2@stanfit)
pars <- names(fit2d)

# inner interval = 50% CI and outer interval = 95% CI.
mcmc_intervals(fit2d, 
               pars = pars[1:3], 
               prob = 0.5, 
               prob_outer = 0.90)
```

Ja teiseks täis posteeriorid.
```{r}
mcmc_areas(fit2d, pars = pars[1:2], prob = 0.8)
```


Funktsiooniga `rethinking::extract.samples()` saame koos sämplitud parameetrite numbrid kõrvuti (rea kaupa) tabelisse. 

```{r}
m2sampl <- extract.samples(m2) %>% 
  as.data.frame() %>% 
  mutate(CV = sigma / mu)
```

Sellest tabelist võib arvutada posteerioreid ka uutele "väljamõeldud" parameetritele. 
Näiteks arvutame posteeriori CV-le:

```{r}
ggplot(m2sampl, aes(CV)) + 
  geom_density(breaks = seq(0, 1, by = 0.1)) + 
  xlim(0, 10)
```

Kuna posteerior iseloomustab meie teadmiste piire, siis võime selle abil küsida, kui suure tõenäosusega jääb tõeline CV näiteks parameetrivahemikku 2 kuni 5?

```{r}
intv <- filter(m2sampl, between(CV, 2, 5)) %>% nrow(.) / nrow(m2sampl)
intv
```

Vastus on, et me arvame `r round(intv*100)` kindlusega, et tõde jääb kuskile sellesse vahemikku.

Võime ka küsida, millesesse vahemikku jääb näiteks 67% meie usust mu tõelise väärtuse kohta? 

```{r}
HPDI(m2sampl$CV, prob = 0.67)
```

Nüüd võrdleme nelja fititud mudelit, et otsustada, milline mudel kirjeldab kõige paremini outlieritega andmeid. 
m0 on ilma outlierita mudel ja me tahame teada, milline mudel m1, m2 või m3 annab sellele kõige lähedasemad tulemused. 

```{r}
coeftab_plot(coeftab(m0, m1, m2, m3), 
             pars = c("mu", "sigma"), 
             prob = 0.5)
```

Me sättisime usalduspiirid 0.5 peale, mis tähendab, et need ennustavad, kuhu peaks mudeli järgi jääma parameetri tegelik väärtus 50%-se tõenäosusega. 
Nagu näha, on m2 ja m3 posteeriorid palju lähemal m0-le kui normaaljaotusega fititud m1 oma.
Eriti drastilised on erinevused sigma hinnangule. 
Lisaks, m1 mudeli mu usaldusintervall on palju laiem kui m0, m2 ja m3 oma --- mudel nagu saaks aru, et andmed lõhnavad kala järgi.

### Näide: USA presidentide keskmine pikkus

Läheme tagasi normaaljatuse ja USA presidentide juurde. 
Kõigepealt defineerime priorid. 
Alati on mõistlik priorid välja joonistada ja vaadata, kas nad vastavad meie ootustele. 
Pea meeles, et sigma ehk sd on samades ühikutes, mis mõõtmisandmed. 

Kui sulle need priorid ei meeldi, tuuni priorite parameetreid ja proovi uuesti plottida.

```{r}
x <- -500:500
y <- dnorm(x, 0, 200)
plot(x, y, main = "Prior for mu", type = "l")
```

Siin kasutame nõrgalt informatiivseid prioreid. 
Idee on selles, et normaaljaotus, mis on tsentreeritud 0 ümber, tõmbab meie posteeriorit nõrgalt nulli poole (nõrgalt, sest jaotus on hästi lai võrreldes tõepärafunktsiooniga). 
Pane tähele, et oma priori kohaselt usume me, et 50% tõenäususega on USA presidentide keskmine pikkus negatiivne. 
See prior on tehniline abivahend, mitte meie tegelike uskumuste peegeldus presidentide kohta. 
Aga tehniliselt kõik töötab selles mõttes, et andmed domineerivad posteeriori üle ja priori sisuliselt ainus ülesanne on veidi MCMC mootori tööd lihtsustada. 

Sigma priorina kasutame half-Cauchy jaotust, mis on samuti väheinformatiivne. 
Half-Cauchy ei saa olla < 0 ja on meile soodsa kujuga sest annab suurema tõenäosuse nullile lähemal asuvatele sd-väärtustele --- aga samas, kuna ta on paksu sabaga, ei välista see ka päris suuri sd väärtusi.

```{r}
x <- 0:200
y <- dcauchy(x , 0, 10)
plot(x, y, main = "Prior for sigma", type = "l")
```

Tekitame andmeraami analüüsiks ja mudeli, mis põhineb normaalsel tõepärafunktsioonil.

```{r, eval=FALSE}
heights <- c(183, 192, 182, 183, 177, 185, 188, 188, 182, 185)
us_presidents <- data.frame(Height = heights, id = "usa")
potusm1 <- map2stan(
  alist(
    Height ~ dnorm(mu, sigma), # normal likelihood
    mu ~ dnorm(0, 200), # normal prior for mean
    sigma ~ dcauchy(0, 10) # half-cauchy prior from sd 
  ), data = us_presidents
)
```

```{r, include=FALSE}
heights <- c(183, 192, 182, 183, 177, 185, 188, 188, 182, 185)
us_presidents <- data.frame(Height = heights, Country = "USA")
potusm1 <- readRDS("data/potusm1.rds")
```

Mudeli koefitsiendid:

```{r}
precis(potusm1)
```

Nüüd teeme katse võrrelda USA presidentide ja Euroopa ning mujalt pärit riigijuhtide keskmisi pikkusi.
Kõigepealt loome analüüsitava andmeraami.
```{r}
world_leaders <- read.csv2("data/world_leaders.csv")
presidents <- world_leaders %>% 
  select(Country, Height) %>% 
  bind_rows(us_presidents)
presidents
```

Ja siin on mudel. 
Nüüd on mu ümber defineeritud kui mu1[indeks], mis tähendab, et mu1 saab kaks hulka väärtusi, üks kummagil indeks muutuja tasemel. 
Sellega jagame oma andmed kahte ossa (USA versus Euroopa ja muu maailm), mida analüüsime eraldi. 
Sigma on mõlemale kontinendile sama, mis tähendab, et mudel eeldab, et presidentide pikkuste jaotus on mõlemal kontinendil identne.


```{r}
# Split into 2 groups
presidents <- presidents %>% 
  mutate(Groups = case_when(
    Country == "USA" ~ "USA",
    Country != "USA" ~ "World"
  ))
```

Adult human height varies country-by-country, we take 170 cm as relatively safe prior for male height.
```{r, eval=FALSE}
potusm2 <- map2stan(
  alist(
    Height ~ dnorm(mu, sigma),
    mu <- mu_1[Groups], # mu is redifined as mu_1, which takes values at each indeks level
    mu_1[Groups] ~ dnorm(170, 10), # normal prior for mean
    sigma ~ dcauchy(0, 10) # half-cauchy prior from sd 
  ),
  data = presidents)
```

```{r, include=FALSE}
potusm2 <- readRDS("data/potusm2.rds")
```

```{r}
precis(potusm2, depth = 2)
```

Me võime ka vaadata 2 grupi standardhälbeid lahus.
Järgnevas mudelis on mõistlik ahelale stardipositsioon ette anda.

```{r}
## Calculate start values
startvalues <- presidents %>% 
  group_by(Groups) %>% 
  summarise_at(vars(Height), funs(mean, sd))
## Fit model
potusm2.1 <- map2stan(
  alist(
    Height ~ dnorm(mu, sigma),
    mu <- mu_1[Groups],
    sigma <- sigma_1[Groups],
    mu_1[Groups] ~ dnorm(170, 10), # normal prior for mean
    sigma_1[Groups] ~ dcauchy(0, 10) # half-cauchy prior from sd 
  ),
  data = presidents, 
  start = list(mu_1 = startvalues$mean,
               sigma_1 = startvalues$sd)
)
```

```{r}
potusm2.1 <- readRDS("data/potusm21.rds")
precis(potusm2.1, depth = 2)
```


```{r}
tracerplot(potusm2.1, n_cols = 2)
```


Tulemus ES-i osas tuleb üsna sarnane.
```{r}
plot(coeftab(potusm2, potusm2.1))
```


```{r}
precis(potusm2, depth = 2)
```

Siin tuleb kasulik trikk: me lahutame rea kaupa mu1[1] posteeriori sampli liikmed mu1[2] sampli liikmetest. 
Nii saame posteeriori efekti suurusele ehk hinnangu sellele, mitme cm võrra on USA presidendid keskmiselt pikemad kui Euroopa omad!

```{r}
samplespm2 <- extract.samples(potusm2) %>% 
  as.data.frame() %>% 
  mutate(ES = mu_1.1 - mu_1.2)
dens(samplespm2$ES)
```

```{r}
## Mean ES
median(samplespm2$ES)
## 90% HDI
HPDI(samplespm2$ES, prob = 0.9)
## Probability of ES being smaller than 0
mean(samplespm2$ES < 0)
```

Võrdse SD-ga mudeli järgi on USA presidendid keskeltläbi `r round(median(samplespm2$ES), 1)` cm pikemad, ebakindlus selle hinnangu ümber on suur -- 90% HDI on `r paste(round(HPDI(samplespm2$ES, prob = 0.9), 1), collapse = " kuni ")` ja tõenäosus et pikkuste erinevus on väiksem kui 0 on `r round(mean(samplespm2$ES < 0), 2)`.

```{r}
samplesm2.1 <- extract.samples(potusm2.1) %>% 
  as.data.frame() %>% 
  mutate(ES = mu_1.1 - mu_1.2)
median(samplesm2.1$ES)
HPDI(samplesm2.1$ES, prob = 0.9)
mean(samplesm2.1$ES < 0)
```

Erineva SD-ga mudeli järgi on riigijuhtide pikkuste vahe `r round(median(samplespm2.1$ES), 1)` cm, ebakindlus väiksem -- 90% HDI on `r paste(round(HPDI(samplespm2.1$ES, prob = 0.9), 1), collapse = " kuni ")` ja tõenäosus et pikkuste erinevus on väiksem kui 0 on `r round(mean(samplespm2.1$ES < 0), 2)`.

See ei tähenda tingimata, et me peaksime eelistama teist mudelit. Oluline on, mida me teoreetiliselt usume, kas seda, et tegelik presidentide varieeruvus on USAs ja Euroopas võrdne, või mitte.

## Lineaarne regressioon

Eelmises peatükis hindasime ühe andmekogu (näiteks mõõdetud pikkuste) põhjal ehitatud mudelite parameetreid (näiteks keskmist ja statndardhälvet). Nüüd astume sammu edasi ja hindame kahe muutuja (näiteks pikkuse ja kaalu) koos-varieeruvust. Selleks ehitame mudeli, mis sisaldab mõlemaid muutujaid ja küsime: kui palju sõltub y varieeruvus x varieeruvusest. Lihtsaim viis sellele küsimusele läheneda on lineaarse regressiooni kaudu. Me ehitame lineaarse mudeli, mis vaatab kaalu-pikkuse paare (igal subjektil mõõdeti kaal ja pikkus ning mudel vaatab kaalu ja pikkuse koos-varieeruvust subjektide vahel). Enam ei tohiks tulla üllatusena, et meie arvutused ei anna numbrilist hinnangut mitte teaduslikule küsimusele selle kohta kuidas *y*-i väärtused sõltuvad *x*-i väärtustest, vaid mudeli parameetritele. Meie mudel on sirge võrrand $y = a + b*x$ ja tavapärases R-i notatsioonis kirjutatakse see *y~x*. 

Kuna pikkused ja kaalud on igavad, proovime vaadata kuidas riigi keskmine eluiga on seotud riigi rikkusega.

## `lm()` - vähimruutude meetodiga fititud lineaarsed mudelid

```{r}
library(gapminder)
# Select only data from year 2007
g2007 <- gapminder %>% filter(year == 2007)
g2007
```

Enne kui SKP ja eluea seoseid otsima hakkame, vaatame, mis juhtub, kui me arvutame ainult interceptiga mudeli, kus puudub SKP (kasutades lihtsuse mõttes mudeli fittimiseks nn vähimruutude meetodit `lm()` funktsiooni abil).

```{r}
gapmod1 <- lm(lifeExp ~ 1, data = g2007)
summary(gapmod1)
```

Ok, intercept = 67. 
Mida see tähendab?
```{r}
mean(g2007$lifeExp)
```

See on lihtsalt parameetri, mida me ennustame, keskmine väärtus ehk keskmine eluiga üle kõikide riikide.

Nüüd fitime mudeli, kus on olemas SKP ja eluea seos aga puudub intercept.
```{r}
gapmod2 <- lm(lifeExp ~ -1 + gdpPercap, data = g2007)
summary(gapmod2)
plot(g2007$gdpPercap, g2007$lifeExp, ylim = c(0, max(g2007$lifeExp)))
abline(gapmod2)
```

Nüüd on intercept surutud väärtusele y = 0.

Ja lõpuks täismudel
```{r}
gapmod3 <- lm(lifeExp ~ gdpPercap, data = g2007)
summary(gapmod3)
plot(g2007$gdpPercap, g2007$lifeExp, ylim = c(0, max(g2007$lifeExp)))
abline(gapmod2)
abline(gapmod3, col = "red", lwd = 2)
```

Kuidas me seda m3 mudelit tõlgendame?
```{r}
summary(gapmod3)
```

Esiteks, Intercept on 59.6, mis tähendab, et mudel ennustab, et kui riigi SKP = 0 USD, siis selle riigi elanime keskmine euliga on 60 aastat. 
See on selgelt imelik, sest ühegi riigi SKP ei ole null, ja kui oleks, oleks seal ka eluiga 0. (selle järgi peaksime eelistama m2, kus me oleme intercepti nulli surunud).

Teiseks, koefitsient b = 6.37 x 10-4, mis on üsna väike arv. See tähendab, et SKP tõus 1 USD võrra tõstab eluiga keskmiselt 0.000637 aasta võrra (ja SKP tõus 1000 USD võrra tõstab eluiga 0.6 aasta võrra). Muidugi ainult siis, kui uskuda mudelit.

Kolmandaks, adjusted R squared on 0.457, mis tähendab et mudeli järgi seletab SKP varieerumine 45.7% eluea varieeruvusest riikide vahel.


Hea küll, aga milline mudel on siis parim? 
```{r}
AIC(m1, m2, m3)
```

AIC on Aikake Informatsiooni Kriteerium, mis võtab arvesse nii mudeli fiti headuse kui mudeli parameetrite arvu. Kuna R saab parameetreid lisades ainult kasvada ja me teame, et mingist hetkest oleme niikuinii oma mudeli üle fittinud, siis otsime AIC-i abil kompromissi: võimalult hea fit võimalikult väikese parameetrite arvuga. AIC on suhteline mõõt, selle absoluutnäit ei oma mingit tähendust. Mee eelistame väiksema AIC-ga mudelit nende mudelite seast, mida me võrdleme. See ei tähenda, et võitnud mudel oleks hea mudel --- alati on võimalik, et kõik head mudelid jäid võrdlusest välja. 

Seega parim mudel on m3 ja kõige kehvem on m2, mille intercept on realistlikult nulli fikseeritud! 


## Bayesi kaudu lineaarse mudeli fittimine

Nüüd Bayesi mudelid. Glimmer on abivahend, mis konverteerib lm() mudeli kirjelduse Bayesi mudeli kirjelduseks kasutades normaaljaotusega tõepära mudelit.
```{r}
glimmer(lifeExp~1, data = g2007)
```

Ainult interceptiga mudel. Keksväärtus ehk mu on ümber defineeritud kui intercept, aga see annab talle lihtsalt uue nime. Sama hästi oleksime võinud fittida mudeilt, kus hindame otse mu keskväärtust (nagu me eelmises peatükis tegime). Pane tähele, et võrreldes `lm()` funktisiooniga on meil mudelis lisaparameeter --- sigma. Kui Intercept annab meile keskmise eluea, siis sigma annab eluigade standardhälbe riikide vahel.

> Kui me tahame fittida lineaarset mudelit, siis peab tõepära funktsioon olema kas normaaljaotus või studenti t jaotus.


```{r results="hide"}
g2007 <- as.data.frame(g2007)
m4 <- map2stan(alist(
  lifeExp ~ dnorm(mu, sigma),
  mu <- Intercept,
  Intercept ~ dnorm(0, 10),
  sigma ~ dcauchy(0, 2)
), data = g2007)
```

```{r}
precis(m4)
```

Nüüd ilma interceptita mudel
```{r}
glimmer(lifeExp ~ -1 + gdpPercap, data = g2007)
```

Bayesi mudel on ilusam kui `lm()` sest ta toob mudeli eksplitsiitselt välja (samas kui lm notatsioon ütleb, et mudel on "miinus intercept") 

```{r results="hide"}
m5 <- map2stan(alist(
  lifeExp ~ dnorm(mu , sigma ),
  mu <- b_gdpPercap * gdpPercap,
  b_gdpPercap ~ dnorm(0, 10),
  sigma ~ dcauchy(0, 2)
), data = g2007)
```

```{r}
precis(m5)
```

Ja lõpuks täismudel:
```{r results="hide"}
m6 <- map2stan(alist(
    lifeExp ~ dnorm(mu, sigma),
    mu <- Intercept + b_gdpPercap * gdpPercap,
    Intercept~ dnorm(0, 100),
    b_gdpPercap ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
), data = g2007)

```

```{r}
compare(m4, m5, m6)
```

Jälle on täismudel võija ja kui intercept nulli suruda, saame kehveima tulemuse.
Siin me kasutame AIC-i Bayesi analoogi WAIC, mis nende mudelite peal peaks töötama veidi paremini, kui AIC. Aga see on tehniline detail...
WAIC abil mudeleid võrreldes saame muuhulgas mudeli kaalu. Antud juhul on m6-l 100% kaalust ja ülejäänud mudelitele ei jää midagi.

```{r}
plot(coeftab(m4, m5, m6))
```



Viime SKP andmed log-skaalasse ja proovime uuesti. See tähendab, et me arvame, et iga SKP kümnekordne tõus võiks kaasa tuua eluea tõusu x aasta võrra.
```{r results="hide"}
g2007 <- g2007 %>% mutate(l_GDP = log10(gdpPercap))
g2007 <- as.data.frame(g2007)
m7 <- map2stan(alist(
    lifeExp ~ dnorm(mu, sigma),
    mu <- b_gdp * l_GDP,
    b_gdp ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2)
), data = g2007)

m8 <- map2stan(alist(
    lifeExp ~ dnorm(mu, sigma),
    mu <- Intercept + b_gdp * l_GDP,
    Intercept ~ dnorm(0, 100),
    b_gdp ~ dnorm(0, 10),
    sigma ~ dcauchy(0, 2)
), data = g2007)

```

```{r}
compare(m4, m5, m6, m7, m8)

```


Now, as it happens, in log scale the intercept-fixed-at-0 model is almost as good as the full model. This is, however, not a general feature of modelling.

```{r}
cf7 <- coef(m7)
cf7
cf8 <- coef(m8)
cf8

g2007 %>% 
  ggplot(aes(l_GDP, lifeExp)) + 
  geom_point() +
  geom_abline(intercept = 0, 
              slope = cf7["b_gdp"], 
              color = "blue") + 
  geom_abline(intercept = cf8["Intercept"], 
              slope = cf8["b_gdp"], 
              color = "red" ) +
  coord_cartesian(ylim = c(0, max(g2007$lifeExp) ), xlim = c(0, 5))
```

Kuna Bayesi mudelite fittimine on keerulisem kui lm() abil, on eriti tähtis fititud mudel välja plottida. See on esimene kaitseliin lollide vigade ja halvasti jooksvate markovi ahelate vastu. 

Kui Bayesi mudeleid on raskem fittida, siis milleks me peaksime neid eelistama tavalistele vähimruutude meetodil fititud mudelitele? Tegelikult alati ei peagi. Aga siiski, Bayesi mudelid sisaldavad eksplitsiitset veakomonenti (sigma), mis on kasulik mudelist uusi andmeid ennustades. Samuti annavad nad parima hinnangu ebakindlusele parmeetrite väärtuste hinnangute ümber, võimaldavad mudeli fittimisel siduda andmeid taustainfoga (prior) ning, mis kõige tähtsam, võimaldavad paindlikumalt fittida hierarhilisi mudeleid (nende juurde tuleme hiljem). 

Samas, kui prior on väheinformatiivne, siis Bayesi hinnangud mudeli koefitsientide kõige tõenäolisematele väärtustele on praktiliselt samad, kui vähimruutude meetodiga lm() abil saadud punkt-hinnangud. 

Siin me fitime pedagooglistel kaalutlustel kõike Bayesiga aga praktikas jätavad paljud mõistlikud inimesed Bayesi hierarhiliste mudelite jaoks ja kasutavad lihtsate mudelite jaoks lm(). 

Hea küll, tagasi m7 ja m8 mudelite juurde. Plotime nende koefitsiendid koos usalduspiiridega.
```{r}
plot(coeftab(m7, m8))
```

Pane tähele, et m8 b_gdp koefitsiendi posteerior on plaju laiem kui m7 b_gdp oma. See on üldine nähtus, mis tuleneb sellest, et m7-s on vähem parameetreid. **Iga lisatud parameeter kipub vähendama teiste parameetrite hindamise täpsust.**


## Ennustused mudelist

Kuidas plottida meie hinnangud ebakindlusele parameetri tegeliku väärtuse ümber?
Siin tuleb appi link().

Nii tõmbame posteriorist igale meie andmetes esinevale log GDP väärtusele vastavad 1000 ennustust keskmise eluea kohta sellel l_GDP väärtusel: 

```{r eval=FALSE}
linked <- link(m8)
linked <- as_tibble(linked)
linked_mean <- apply(linked, 2, HPDI, prob = 0.95)
```

Sel viisil saab tabeli, kus igale 142-le andmepunktist vastab üks veerg, milles on 1000 posteeriorist arvutatud ennustust lifeExp väärtusele.

Praktikas soovime aga enamasti meie poolt ette antud l_GDP väärtustel põhinevaid ennustusi keskmise eluea kohta. See käib nii:

```{r}
#first we create an evenly spced grid of l_GDP values, 
#for which we wish to obtain 95% CI-s 
width <- seq(2, 6, 0.1)

# link() draws from the posterior 1000 mu values for each l_GDP value in the width object; out pops a table with 1000 rows and 41 columns. 
mu1 <- as_tibble(link(m8, data = data.frame(l_GDP = width)))
```

Nüüd on meil mu1 objektis 41 l_GDP väärtust, millest igale vastab 1000 ennustust keskmise eluea kohta sellel l_GDP-l. Järgmiseks arvutame igale neist 41-st tulbast keskmise ja 95% HPDI ning plotime need koos andmepunktidega kasutades base-R graafikasüsteemi.


Pane tähele, et hall riba näitab ebakindlust ennustuse ümber keskmisele elueale üle kõikide riikide, mis võiksid sellist l_GDP-d omada (ehk ebakindlust regressioonijoonele). Kui me aga tahame ennustada ka keskmiste eluigade varieeruvust riigi tasemel (kasutades Bayesi hinnangut sigma parameetrile), siis on meil vaja sim() funktsiooni:

```{r}
mu.mean <- apply(mu1, 2, mean ) # applies the FUN mean() to each column
mu.HPDI <- apply(mu1, 2, HPDI , prob = 0.95 )
sim.length <- as_tibble(rethinking::sim(m8, data = list(l_GDP = width)))
height.PI <- apply(sim.length, 2, PI, prob = 0.95)

plot(lifeExp ~ l_GDP, data = g2007, col = col.alpha(rangi2, 0.5))
lines(width, mu.mean) # mu.mean tuleb eelmisest koodiplokist
shade(mu.HPDI, width) # mu.HPDI tuleb eelmisest koodiplokist
shade(height.PI, width) # draw PI region for simulated heights
```

Nüüd ütleb laiem hall ala, et me oleme üsna kindlad, et nende riikide puhul, mille puhul mudel töötab, kohtame individaalsete riikide keskmiseid eluigasid halli ala sees ja mitte sealt väljas. 
Nagu näha, on meil ka riike, mis jäävad hallist alast kaugele ja mille keskmine eluiga on kõvasti madalam, kui mudel ennustab. 
Need on äkki riigid, kus parasjagu on sõda üle käinud ja mille eluiga ei ole näiteks seetõttu SKP-ga lihtsas põhjuslikus seoses. 
Igal juhul tasuks need ükshaaval üle vaadata sest punktid, mida mudel ei seleta, võivad varjata endas mõnd huvitavat saladust, mis pikisilmi ootab avastajat. 
Lisaks: pane tähele, et mudel eeldab, et riikide keskmise eluea SD on muutumatu igal GDP väärtusel.


Sama pilt ggplot-ga.
```{r}
linked_ci <- link(m8) %>% 
  as_tibble() %>% 
  apply(2, HPDI, prob = 0.95)
sim_ci <- rethinking::sim(m8) %>% 
  as_tibble() %>% 
  apply(2, HPDI, prob = 0.95)
coef <- coef(m8)

ggplot(g2007, aes(l_GDP, lifeExp)) + 
  geom_point(aes(color = continent), size = 0.8) +
  geom_abline(slope = coef[2], intercept = coef[1]) +
  geom_ribbon(aes(ymin = linked_ci[1,], ymax = linked_ci[2,]), alpha = 0.2) +
  geom_ribbon(aes(ymin = sim_ci[1,], ymax = sim_ci[2,]), alpha = 0.1, color = "grey70")
```

Kuidas saada ennustusi kindlale l_GDP väärtusele? Näiteks tulp V10 vastab l_GDP väärtusele 2.9. Järgnevalt arvutame oodatavad keskmised eluead sellele SKP väärtusele (fiksionaalsetele riikidele, millel võiks olla täpselt selline SKP):
```{r}
dens(sim.length$V10)
HPDI(sim.length$V10, prob = 0.95)
```

Nagu näha, võib mudeli kohaselt sellise riigi keskmine eluiga tulla nii madal, kui 40 aastat ja nii kõrge kui 67 aastat.

### Lognormaalne tõepäramudel

See mudel on alternatiiv andmete logaritmimisele, kui Y-muutuja (see muutuja, mille väärtust te ennustate) on lognormaalse jaotusega. 


> Lognormaalne Y-i tõepäramudel on mittelineaarne. Lognormaaljaotus defineetitakse üle mu ja sigma, mis aga vastavd hoopis log(Y) normaaljaotuse mu-le ja sigmale.

Seekord ennustame GDP-d keskmise eluea põhjal (mis, nagu näha jooniselt, ei ole küll päris lognormaalne).

```{r}
ggplot( g2007, aes( gdpPercap ) ) +
  geom_density() +
  stat_function( fun = dlnorm, 
                args = list( mean = mean( log( g2007$gdpPercap ) ),
                             sd = sd( log( g2007$gdpPercap ) ) ), 
                colour = "red" ) +
  theme_classic()

```

Mustaga on näidatud empiiriline SKP jaotus, punasega fititud lognormaalne mudel sellest samast jaotusest. Järgnevalt ennustame SKP-d keskmise eluea põhjal, milleks fitime lognormaalse tõepäramudeli, kus mu on ümber defineeritud regressioonivõrrandiga:

```{r}
m_ln1 <- map2stan(
  alist(
   gdpPercap  ~ dlnorm( mu , sigma ),
    mu <- a + b * lifeExp,
    a ~ dnorm( 0, 10 ),
    b ~ dnorm( 0, 10 ),
    sigma ~ dcauchy( 0, 2 ) 
   ), 
  data = g2007, 
  start = list( a = 3, b = 0, sigma = 0.5 ) 
  )
```


```{r}
precis(m_ln1)
plot(m_ln1)
```

Logormaalses mudelis muutuvad parameetrite tähendused ja need tuleb lineaarse mudeli intercepti ja tõusu interpretatsioonidega kooskõlla viimiseks ümber arvutada. Kõigepealt avaldame tõusu. Kuna meil on tegemist mitte-lineaarse mudeliga, sõltub tõusu väärtus ka mudeli interceptist: $slope = exp(α + β) − exp(α)$. See ei ole lineaarne seos: b omab seda suuremat mõju efektile (tõusule), mida suurem on a. [Kui meil on tegu binaarse X-ga (prediktoriga), siis kodeerime selle 2 taset kui -1 ja 1. Sellises mudelis on slope sama, mis efekti suurus ES, ja $ES = exp(α + β) − exp(α - β)$]

```{r}
a <- seq( 0, 10, length.out = 1000 )
b <- 2
b1 <- 3
y <- exp( a + b ) - exp( a )
y1 <- exp( a + b1 ) - exp( a )

plot( a, y, type = "l", xlab = "a value", ylab = "slope" )
lines( a, y1, col = "red" )
```

Must joon näitab mudeli tõusu sõltuvust parameetri a väärtusest, kui parameeter b = 2. Punane joon teeb sedasama, kui b = 3.

Selline on siis mudeli tõusude (beta) posteerior:

```{r}
s_ln1 <- extract.samples( m_ln1 ) %>% as.data.frame()
beta <- exp( s_ln1$a + s_ln1$b ) - exp( s_ln1$a )                                   

dens( beta ) 
```


Lognormaaljaotusega mudelis täidab normaaljaotusega mudeli intercepti rolli eelkõige meedian, mis on defineeritud kui exp(a), aga arvutada saab ka keskmise:
```{r}
i_median <- exp( s_ln1$a )
mean(grand_median)

i_mean <- exp( s_ln1$a + s_ln1$sigma**2/2 )
mean(grand_mean)
```

Siin ennustame fititud mudelist uusi andmeid (väljamõeldud riikide rikkust):

```{r}
sim_ci <- rethinking::sim(m_ln1) %>% as_tibble() %>% apply(2, HPDI, prob=0.95)

ggplot( g2007, aes( lifeExp, gdpPercap ) ) + 
  geom_point( aes( color = continent ), size = 0.8 )+
  geom_ribbon( aes( ymin = sim_ci[1,], ymax = sim_ci[2,]), alpha = 0.2 ) +
  theme_classic()
```

Ka see mudel jääb hätta Aafrika outlieritega, mille eluiga ei suuda ennustada rikkust.

## Mitme prediktoriga lineaarne regressioon

```{r}
library(gapminder)
gapminder <- gapminder
g2007 <- gapminder %>% filter( year == 2007 )
g2007 <- g2007 %>% mutate( l_GDP = log10( gdpPercap ) )
g2007 <- g2007 %>% mutate( l_pop = log10( pop ), 
                           lpop_s = (l_pop - mean( l_pop ) )/sd( l_pop ),
                           lGDP_s = (l_GDP - mean( l_GDP ) )/sd( l_GDP ) ) %>% 
  as.data.frame()
```


Meil on võimalik lisada regressioonivõrrandisse lisaprediktoreid. Nüüd ei küsi me enam, kuidas mõjutab l_GDP varieeruvus keskmise eluea varieeruvust vaid: kuidas mõjutavad muutujad l_GDP, continent ja logaritm pop-ist (rahvaarvust) keskmist eluiga. Me modelleerime selle lineaarselt nii, et eeldusena varieeruvad need x-i muutujad üksteisest sõltumatult: y = a + b1x1 + b2x2 + b3x3

Sellise mudeli tõlgendus on suhteliselt lihtne: 

  > koef b1 ütleb meile, 
      kui mitme ühiku võrra tõuseb/langeb muutuja y (eluiga) 
      kui muutuja x1 (l_GDP) tõuseb 1 ühiku võrra; 
      tingimusel, et me hoiame kõigi teiste muutujate väärtused konstantsed. 
      
      
Sarnane definitsioon kehtib ka kõigi teiste prediktorite (x-de) kohta.

Kui meil on mudelis SKP ja pop, siis saame küsida 

1) kui me juba teame SKP-d, millist ennustuslikku lisaväärtust annab meile ka populatsiooni suuruse teadmine? ja

2) kui me juba teame populatsiooni suurust, millist lisaväärtust annab meile ka SKP teadmine?

Järgenval mudelil on 4 parameetrit (intercept + 3 betat).

```{r}
m1 <- lm( lifeExp ~ l_GDP + continent + log10( pop ), data = g2007 )
summary( m1 )
```

loeme mudelis "+" märki nagu "või". Ehk, "eluiga võib olla funktsioon SKP-st **või** rahvaarvust".

Intercept 19 ei tähenda tõlgenduslikult midagi. l-GDP tõus ühiku võrra tõstab eluiga 10.7 aasta võrra. 

võrdluseks lihtne mudel
```{r}
m2 <- lm( lifeExp ~ l_GDP, data = g2007 )
summary( m2 )
```

Siin on l_GDP mõju suurem, 16.6 aastat. Millisel mudelil on siis õigus? Proovime veel ülejäänud variendid

```{r}
m3 <- lm( lifeExp ~ l_GDP + continent, data = g2007 )
summary( m3 )

m4 <- lm( lifeExp ~ l_GDP + log10( pop ), data = g2007 )
AIC( m1, m2, m3, m4 )
```

Võitja mudel on hoopis m3, mis võtab arvesse kontinendi. Siin on l_GDP mõju samuti 10.7 aastat. Lisaks näeme, et kui riik ei asu Aafrikas, siis on l_GDP mõju elueale u 11 aasta võrra suurem. Seega elu Aafrika kisub alla keskmise eluea riigi rikkusest sõltumata. Võib olla on põhjuseks sõjad, võib-olla AIDS ja malaaria, võib-olla midagi muud. 

Millise mudeli me peaksime siis avaldama? Vastus on, et need kõik on olulised, et vastata küsimusele, millised faktorid kontrollivad keskmist eluiga? Mudelite võrdlusest näeme, et rahvaarvu mõju elueale on väike või olematu ning et SKP mõju avaldub log skaalas (viitab teatud tüüpi eksponentsiaalsetele protsessidele, kus rikkus tekitab uut rikkust) ning, et Aafrikaga on midagi pahasti ja teistmoodi kui teiste kontinentidega. Aafrikast tasub otsida midagi, mida meie senised mudelid ei kajasta.

Miks ei ole mudeli summary tabelis Aafrikat? Põhjus on tehniline. Kategoorilisi muutujaid, nagu kontinent, vaatab mudel paariviisilises võrdluses, mis tähendab et k erineva tasemega muutujast tekitatakse k - 1 uut muutujat, millest igaühel on kaks taset (0 ja 1). See algne muutuja, mis üle jääb (antud juhul Africa), jääb ilma oma uue muutujata. Me saame teisi uusi kontinendi põhjal tehtud muutujaid tõlgendada selle järgi, kui palju nad erinevad Africa-st.

#### Miks multivariaatsed mudelid head on?

1) nad aitavad kontrollida "confounding" muutujaid. Confounding muutuja võib olla korreleeritud mõne teise muutujaga, mis meile huvi pakub. See võib nii maskeerida signaali, kui tekitada võlts-signaali, kuni y ja x1 seose suuna muutmiseni välja.

2) ühel tagajärjel võib olla mitu põhjust.

3) Isegi kui muutujad ei ole omavahel üldse korreleeritud, võib ühe tähtsus sõltuda teise väärtusest. Näiteks taimed vajavad nii valgust kui vett. Aga kui ühte ei ole, siis pole ka teisel suurt tähtsust.

### Mudeldamine standardiseeritud andmetega.

Kui me lahutame igast andmepunktist selle muutuja keskväärtuse siis saame 0-le tsentreeritud andmed. Kui me sellisel viisil saadud väärtused omakorda läbi jagame muutuja standardhälbega, siis saame standardiseeritud andmed, mille keskväärtus on null ja SD = 1.

$Standard.andmed = (x - mean(x))/sd(x)$ 

Nii on lihtsam erinevas skaalas muutujaid omavahel võrrelda (1 ühikuline muutus võrdub alati muutusega 1 standardhäve võrra) ja mudeli arvutamine üle mcmc ahelate on ka lihtsam.

```{r results="hide"}

m5 <- map2stan(
    alist(
        lifeExp ~ dnorm( mu , sigma ) ,
        mu <- a + b_GDP * lGDP_s + b_pop * lpop_s ,
        a ~ dnorm( 0 , 10 ) ,
        c(b_GDP, b_pop) ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 10 )
),
    data = g2007 )

```

```{r}
precis( m5 )
```

kui l_GDP kasvab 1 sd võrra, siis eluiga kasvab 6.9 aasta võrra. 

```{r}
 f1 <- glimmer( lifeExp ~ lGDP_s + lpop_s + continent, data = g2007 )
```
See on mudeli struktuur, mis sisaldab uusi kategoorilisi muutujaid

Siin on tähtis anda map2stan()-le ette glimmeri poolt eeltöödeldud andmed:
```{r results="hide"}
m6 <- map2stan(
  f1$f, 
  data = f1$d
)
```

```{r}
precis( m6 )

```

### Keerulisemate mudelitega töötamine

Kasuta graafilisi meetodied. Mudeli koefitsientide jõllitamine üksi ei päästa.

#### Predictor residual plots. 

Plotime varieeruvuse, mida mudel ei oota ega seleta.

```{r}
names( coef( m5 ) )
```

Kõigepealt lihtne residuals plot, kus meil on y-teljel residuaalid ja x-teljel X1 muutuja tegelikud  valimiväärtused. Y = 0 tähistab horisontaalse joonena mudeli ennustatud Y (eluea) väärtusi kõigil prediktori X1 (lGDP_s) väärtustel ja residuaal on defineeritud kui tegelik Y miinus mudeli poolt ennustatud eluiga sellel X1 väärtusel. Mudeli ennustuse saamiseks anname mudelile ette fikseeritud parameetrite (koefitsientide) a, b_GDP ja b_pop väärtused ning arvutame oodatava keskmise eluea üle kõigi valimis leiduvate lGDP_s ja lpop_s väärtuste. Seega saame sama palju keskmise eluea ennustusi, kui palju on meie andmetabelis ridu.

```{r}
# Using the fitted model compute the expected value of y (mu) 
# for each of the 142 data rows.

mu <- coef( m5 )[ 'a' ] + 
  coef( m5 )[ 'b_GDP' ] * g2007$lGDP_s + 
  coef( m5 )[ 'b_pop' ] * g2007$lpop_s


# compute residuals - a vector w. 142 values
m.resid <- g2007$lifeExp - mu


library(ggthemes)
ggplot( g2007, aes( lGDP_s, m.resid ) ) + 
  geom_segment( aes( xend = lGDP_s, yend = 0 ), size = 0.2 ) +
  geom_point( size = 0.5, type = 1 ) + 
  theme_tufte()
  

```


Me näeme, et seal kus SKP on väiksem kipuvad residuaalid olema negatiivsed, mis tähendab, et mudel ülehindab keskmist eluiga. Ja vastupidi, seal kus SKP on üle keskmise, mudel kipub alahindma keskmist eluiga.

See seos tuleb eriti selgelt välja järgmisel pildil, kus plotime residuaalide sõltuvuse elueast (kui eelmine plot oli m.resid ~ X1, siis nüüd plotime  m.resid ~ Y). Lisaks joonistame selguse mõttes regressioonisirge. Kui residuaalid oleks ühtlaselt jaotunud mõlemale poole mudeli ennustust, siis saaksime horisontaalse regressioonisirge. Tegeliku sirge tõus näitab, et suuremad eluead omavad eelistatult poitiivseid residuaale ja väiksemad eluead negatiivseid residuaale. See tähendab, et mudel alahindab eluiga seal, kus SKP on kõrge ja vastupidi, ülehindab eluiga seal, kus SKP on madal.
```{r}
g2007$m.resid <- m.resid
ggplot(g2007, aes(lifeExp, m.resid)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey", linetype = 2)
```

Horisontaalne punktiirjoon näitab, kus mudel vastab täpselt andmetele. 

####  ennustavad plotid: 

Plot, kus me ennustame keskmise eluea sõltuvust SKP-st nii riikide kaupa eraldi (andmepunktide paupa) kui üldiselt kõikide riikide keskmisena, millel on mingi kindel SKP (mudeli parima ennustuse ehk sirge asendi ümber valitsevat ebakindlust). Et seda teha, hoiame rahvaarvu konstantsena oma keskväärtusel, mis standardiseeritud andmetl võrdub alati nulliga. link() funktsioon annab meile keskmiste eluigade ennustused meie poolt ette antud X1 ja X2 väärtustel, ning sim() annab meile eluigade ennustused fiktsionaalsete riikide kaupa samadel X1 ja X2 väärtustel. Nagu näha, on meie mudeli arvates riikide kaupa ennustamine palju laiema varieeruvusega kui üle kõikväimalike riikide kesmise kaupa ennustamine.

```{r}
# prepare new counterfactual data
pred.data <- tibble(
    lGDP_s = seq(-3, 3, length.out = 30), # need meie poolt valitud lGDP_s väärtused, millele me ennustame vastavad eluead 
    lpop_s = 0 # rahvaarv fikseeritakse muutuja keskmisele tasemele, mis standardiseeritud andmete korral = 0
)

# compute counterfactual mean lifeExp (mu)
mu <- link(m5, data = pred.data)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI)

# simulate counterfactual lifeExpectancies of individual countries
R.sim <- rethinking::sim(m5, data = pred.data)
R.sim <- na.omit(R.sim)
R.PI <- apply(R.sim, 2, PI)

ggplot(pred.data, aes(lGDP_s, mu.mean)) +
  geom_line(y = mu.mean) +
  geom_ribbon(ymin = mu.PI[1,], ymax = mu.PI[2,], color = "grey", alpha = 0.2) +
  geom_ribbon(ymin = R.PI[1,], ymax = R.PI[2,], color = "grey", alpha = 0.2)
```

Näeme, kuidas ennustus sobib/ei sobi andmetega. Võrdle eelneva ennustuspildiga, kus mudel ei sisalda rahvaarvu. Ennustuse intervallid on originaalandmete skaalas (aastates), mis on hea.


### Posterior prediction plots 

Posterioorsed ennustusplotid panevad kõrvuti (või üksteise otsa) Y-i algandmed ja mudeli ennustused Y-väärtustele. Kui meie valimi suurus on N, siis me tõmbame mudelist näiteks 5 valimit, igaüks suurusega N ja plotime need kõrvuti valimiandmete plotiga. Siis me vaatame sellele plotile peale ja otsustame, kas mudeli ennustused on piisavalt lähedal valimi andmetele. Kui ei, siis on tõenäoline, et meie mudelis on midagi mäda ja me peame hakkama sealt vigu otsima. Tõsi küll, keerulisemate hierarhiliste mudelite korral on vahest raske otsustada, millised peaksid tulema eduka mudeli ennustused võrreldes algandmetega --- aga siiski, see on arvatavasti kõige tähtsam plot, mida oma mudelist teha!

1) võrdle mudeli ennustusi andmetega. (Aga arvesta sellega, et mitte kõik mudelid ei püüagi täpselt andmetele vastata.)

```{r}
library(bayesplot)
yrep <- sim(m5)
ppc_dens(g2007$lifeExp, yrep[1:5, ])
```

 
2) Millisel viisil täpselt meie mudel ebaõnnestub? See plot annab mõtteid, kuidas mudelit parandada.

Ploti ennustused andmepunktide vastu, pluss jooned, mis näitavad igale ennustusele omistatud usaldusintervalli. Lisaks veel sirge, mis näitab täiuslikku ennustust (slope = 1, intercept = 0). 

Loeme gapminderi andmed uuesti sisse:
```{r}
library(gapminder)
gapminder <- gapminder
g2007 <- gapminder %>% filter( year == 2007 )
g2007 <- g2007 %>% mutate( l_GDP = log10( gdpPercap ) )
g2007 <- g2007 %>% mutate( l_pop = log10( pop ), 
                           lpop_s = (l_pop - mean( l_pop ) )/sd( l_pop ),
                           lGDP_s = (l_GDP - mean( l_GDP ) )/sd( l_GDP ) ) %>% 
  as.data.frame()
```

Ja nüüd plotime ennustused Y-le tegelike Y valimi väärtuste vastu:
```{r}

mu <- link(m5)  
mu.mean <- apply(mu, 2, mean)

mu.PI <- apply( mu , 2 , PI )

g2007$mu.mean <- mu.mean

ggplot( g2007, aes( lifeExp, mu.mean ) ) +
  geom_point()+
  geom_crossbar( ymin = mu.PI[1,], ymax = mu.PI[2,] ) +
  geom_abline( intercept= 0, slope =  1, lty = 2 ) +
  ylab( "predicted life expectancy" ) + 
  xlab( "observed life expectancy" ) +
  coord_cartesian( xlim=c( 40, 85 ), ylim=c( 40, 85 ) )+ 
  theme_tufte()

```

Siin on ennustus ja seda ümbritsev ebakindlus iga riigi keskmisele elueale.

Järgnev plot annab ennustusvea igale riigile. Siin tähistab 89% CI näiteks Vietnamile eluigade vahemikku, millese jääb mudeli ennustuse kohaselt 89% kõikvõimalike fiktsionaalsete riikide keskmistest eluigadest, mille SKP ja rahvaarv võrdub Vietnami omaga. Kuna me tsentreerime CI Vietnami tegeliku keskmise eluea residuaalile (erinevusele mudeli ennustusest), näitab see, kui palju erineb Vietnami eluiga mudeli ennustusest riikidele, nagu Vietnam. See plot annab meile riigid, mille suhtes mudel jänni jääb. Enamasti leiame need riigid Aafrikast.
 
```{r fig.height=8, fig.width= 4 }

# compute residuals
life.resid <- g2007$lifeExp - mu.mean

mu_sim <- rethinking::sim( m5 )  
sim.PI <- apply( mu_sim , 2 , PI )

ggplot( g2007, aes( x = life.resid, y = reorder( country, life.resid ) ) ) +
  geom_point() +
  geom_errorbarh( aes( xmin = lifeExp - sim.PI[1,], 
                       xmax = lifeExp - sim.PI[2,] ), 
                  color = "red") +
  geom_vline( xintercept = 0 ) + 
  theme_tufte() + 
  ylab(NULL)
  
```

punased jooned näitavad 89% ennustuspiire igale residuaalile riigi tasemel (89% kõikvõimalike riikide keskmiste eluigade residuaalidest sellel SKPl jääb punasesse vahemikku).

### interaktsioonid prediktorite vahel

Eelnevad mudelid eeldavad, et prediktorite varieeruvused on üksteisest sõltumatud. Aga mis siis, kui see nii ei ole ja ühe prediktori mõju suurus sõltub teisest prediktorist, ehk prediktorite vahel on interaktsioon? Lihtsaim viis sellist interaktsiooni modelleerida on lisades interaktsiooni aditiivsele mudelile korrutamisetehtena:

$y = a + b1x1 + b2x2 + b3x1x2$

Sellise mudeli järgi erineb sirge tõus b1 erinevatel b2 väärtustel, ja erinevuse määr sõltub b3-st (b3 annab interaktsiooni tugevuse). Samamoodi ja sümmeetriliselt erineb ka tõus b2 sõltuvalt b1 väärtusest. See on ühine paljude hierarhiliste mudelitega, mida võib omakorda vaadelda massivsete interaktsioonimudelitena. Seevastu y = a + b1x1 + b2x2 tüüpi mudel annab b1-le konstantse tõusunurga, kuid laseb intercepti muutuma sõltuvalt b2 väärtusest (ja vastupidi). 

Interaktsioonimudeli fittimises pole midagi erilist võrreldes sellega, mida me oleme juba õppinud. Aga fititud parameetrite tõlgendamine on keeruline. 
Alustame diskreetse muutujaga, continent, ja mudeldame selle interaktsiooni SKP-ga.

```{r}
f1 <- glimmer(lifeExp~ lGDP_s*continent, data=g2007)
```

```{r}
m1 <- map2stan(f1$f, f1$d)
plot(precis(m1))
```

Africa on siin võrdluseks.

Interaktsioon on sümmeetriline. Me võime sama hästi küsida, kui palju SKP mõju elueale sõltub kontinendist, kui seda, kui palju kontinendi mõju eluale sõltub SKP-st.

Nüüd joonistame välja regressioonisirge Aafrika ja Euroopa jaoks eraldi m1 mudeli põhjal

```{r}
c1 <- coef(m1)
names(c1)
```

Kõigepealt defineerime X1 ja X2 väärtused, millele teeme ennustused link() funktsiooni abil. Link tabelist veergude keskmine annab keskmise eluea ennustuse vastavale mandrile ja SKP-le. PI() abil saame 89% CI igale ennustusele. 

```{r}
dd <- as.data.frame(f1$d) #we use the dataframe made by glimmer()
#in dd all continents are in separate 2-level columns (except Africa)
dd1 <- dd %>% filter(continentAmericas==0, 
                     continentAsia==0, 
                     continentEurope==0, 
                     continentOceania==0)
mu.Africa <- link(m1, dd1)
mu.Africa.mean <- apply( mu.Africa , 2 , mean )
mu.Africa.PI <- apply( mu.Africa , 2 , PI , prob=0.9 )

ggplot(data=dd1, aes(lGDP_s, lifeExp)) +
  geom_point()+
  geom_ribbon( aes(ymin=mu.Africa.PI[1,], ymax=mu.Africa.PI[2,]), alpha=0.15)+
  geom_line( aes( y=mu.Africa.mean)) + theme_tufte()
```

```{r}
dd1 <- dd %>% filter(continentEurope==1)
mu.Europe <- link(m1, dd1)
mu.Europe.mean <- apply( mu.Europe , 2 , mean )
mu.Europe.PI <- apply( mu.Europe , 2 , PI , prob=0.9 )

ggplot(data=dd1, aes(lGDP_s, lifeExp)) +
  geom_point()+
  geom_ribbon( aes(ymin=mu.Europe.PI[1,], ymax=mu.Europe.PI[2,]), alpha=0.15)+
  geom_line( aes( y=mu.Europe.mean))+ theme_tufte()
```

Nagu näha, on meil nüüd üsna erinevad sirge tõusunurgad.


#### Interaktsioonid pidevatele tunnustele

Kasutame standardiseeritud prediktoreid, sest nende koefitsiente saab paremini tõlgendada (tegelikult piisab prediktorite tsentreerimisest). Meie andmed käsitlevad diabeedimarkereid Ameerika lõunaosariikide neegritel 1960-ndatel. Me ennustame siin sõltuvalt vanusest ja vööümbermõõdust hdl-i --- high density cholesterol --- mis on nn hea kolesterool.

```{r}
#diabetes <- read.table( file = 'data/diabetes.csv', header = TRUE, sep = ';', dec = ',' )
diabetes <- read.csv2( "data/diabetes.csv" )
d1 <- diabetes %>% select( hdl, age, waist ) %>% na.omit()
d2 <- d1 %>% mutate( age_st = ( age - mean( age ) )/sd( age ), 
                    waist_st = ( waist - mean( waist ) )/sd( waist ) )
m2 <- map2stan(
    alist(
        hdl ~ dnorm( mu , sigma ) ,
        mu <- a + bR*age_st + bA*waist_st + bAR*age_st*waist_st,
        a ~ dnorm( 0, 100 ),
        bR ~ dnorm( 0, 2 ),
        bA ~ dnorm( 0, 2 ),
        bAR~ dnorm( 0, 2),
        sigma ~ dcauchy( 0, 1 )
), data = d2 )

plot(precis( m2 ) )
```

**NB!** Järgmised interpretatsioonid kehtivad ainult siis, kui mudeldame nullile tsentreeritud andmeid.

a - hdl-i oodatav keskväärtus siis kui võõ-ümbermõõt ja vanus on fikseeritud oma keskmistel väärtustel. 
bR - oodatav hdl-i muutus, kui vanus kasvab 1 aasta võrra ja võõ-ümbermõõt on fikseeritud oma keskväärtusel
bA - sama, kui võõ-ümbermõõt kasvab 1 ühiku (inch) võrra 
bAR - kaks ekvivalentset tõlgendust: 1) oodatav muutus vanuse mõju määrale hdl-le, kui vöö-ümbermõõt kasvab 1 ühiku võrra. 2) oodatav muutus vöö-ümbermõõdu mõju määrale hdl-le, kui vanus kasvab 1 ühiku võrra.

Negatiivne bAR tähendab, et vanus ja vöö-ümbermõõt omavad vastandlikke mõjusid hdl-i tasemele, aga samas kumgki tõstab teise tähtsust hdl-le.


```{r}
m3 <- map2stan(
    alist(
        hdl ~ dnorm( mu , sigma ) ,
        mu <- a + bR*age_st + bA*waist_st,
        a ~ dnorm( 0, 100 ),
        c(bR, bA) ~ dnorm( 0, 2 ),
        sigma ~ dcauchy( 0, 1 )
), data = d2)

compare(m2, m3)
```

Siin on tegelikult eelistatud ilma interaktsioonita mudel. Aga kuna interaktsioonimudeli kaal on ikkagi 23%, tasub meil ennustuste tegemisel mõlemat mudelit koos arvestada vastavalt oma kaalule. 

```{r}
coeftab(m2, m3)
```

Tõesti, bA ja bR on mõlemas mudelis väga sarnased. m3 on kindlasti lihtsamini tõlgendatav.

Ensemble teeb ära nii link()-i kui sim()-i, kasutades mõlemat mudelit vastavalt nende mudelite WAIC-i kaaludele ja toodab listi, mille elementideks on link() toodetud maatriks ja sim() toodetud maatriks.

Teeme 3 plotti: waist = 0 (keskmine), waist = -1 (miinus üks sd) ja waist = 1

```{r}
d.pred <- data.frame(
  age_st = seq( -2, 2, length.out = 20 ),
  waist_st = 0
) #siia lähevad kõik prediktorid nende väärtuste kombinatsioonidega, millele me tahame ennustada hdl-i väärtusi.
e <- ensemble( m2, m3, data = d.pred )
hdl <- apply( e$link , 2 , mean )
mu.PI <- apply( e$link , 2 , PI , prob=0.97 )

ggplot(d.pred, aes( x = age_st ) ) +
  geom_line( aes( y = hdl ) ) +
  geom_line( aes( y = mu.PI[1,] ), linetype = 2 ) +
  geom_line( aes( y = mu.PI[2,] ), linetype = 2 ) + 
  theme_tufte()
```

```{r}
d.pred <- data.frame(
  age_st=seq( -2, 2, length.out = 20 ),
  waist_st = -1
) #siia lähevad kõik prediktorid nende väärtuste kombinatsioonidega, millele me tahame ennustada hdl-i väärtusi.
e <- ensemble( m2, m3, data = d.pred )
hdl <- apply( e$link , 2 , mean )
mu.PI <- apply( e$link , 2 , PI , prob=0.97 )

ggplot( d.pred, aes( x = age_st ) ) +
  geom_line( aes( y = hdl ) ) +
  geom_line( aes( y = mu.PI[1,] ), linetype = 2 ) +
  geom_line( aes( y = mu.PI[2,] ), linetype = 2) + 
  theme_tufte()
```

```{r}
d.pred <- data.frame(
  age_st = seq( -2, 2, length.out = 20 ),
  waist_st = 1
) #siia lähevad kõik prediktorid nende väärtuste kombinatsioonidega, millele me tahame ennustada hdl-i väärtusi.
e <- ensemble( m2, m3, data = d.pred )
hdl <- apply( e$link , 2 , mean )
mu.PI <- apply( e$link , 2 , PI , prob = 0.97 )

ggplot( d.pred, aes( x = age_st ) ) +
  geom_line( aes( y = hdl ) ) +
  geom_line( aes( y = mu.PI[1,] ), linetype = 2 ) +
  geom_line( aes( y = mu.PI[2,] ), linetype = 2 ) + 
  theme_tufte()
```

sama base plotis
```{r}
d.pred <- data.frame(
  age_st=seq(-2, 2, length.out = 20),
  waist_st=0
) #siia lähevad kõik prediktorid nende väärtuste kombinatsioonidega, millele me tahame ennustada hdl-i väärtusi.
e <- ensemble(m2, m3, data=d.pred)

# make a plot window with three panels in a single row
par(mfrow=c(1,3)) # 1 row, 3 columns
# loop over values of age_st and plot predictions
age.seq <- seq(-2, 2, length.out = 20)
for ( w in -1:1 ) { #me soovime 3 joonist 3-l waisti näidul: -1, 0, 1.
    plot( hdl ~ age_st , data=d2 , type="n" ,
        main=paste("waist =",w) , xaxp=c(-1,1,2) , ylim=c(40,60) , xlim=c(-2,2),
        xlab="age (centered)" )
    mu.mean <- apply( e$link , 2 , mean )
    mu.PI <- apply( e$link , 2 , PI , prob=0.97 )
    lines( age.seq , mu.mean )
    lines( age.seq , mu.PI[1,] , lty=2 )
    lines( age.seq , mu.PI[2,] , lty=2 )
}
```


Ja sama ainult m2-ga
```{r}
# make a plot window with three panels in a single row
par(mfrow=c(1,3)) # 1 row, 3 columns
# loop over values of age_st and plot predictions
age.seq <- seq(-2, 2, length.out = 20)
for ( w in -1:1 ) {
    plot( hdl ~ age_st , data=d2 , type="n" ,
        main=paste("waist =",w) , xaxp=c(-1,1,2) , ylim=c(40,60) , xlim=c(-2,2),
        xlab="age (centered)" )
    mu <- link( m2 , data=data.frame(waist_st=w, age_st=age.seq) )
    mu.mean <- apply( mu , 2 , mean )
    mu.PI <- apply( mu , 2 , PI , prob=0.97 )
    lines( age.seq , mu.mean )
    lines( age.seq , mu.PI[1,] , lty=2 )
    lines( age.seq , mu.PI[2,] , lty=2 )
}
```

Nüüd on hästi näha, et interaktsioonimudel laseb sirge tõusunurgad vabaks!

Üldiselt tasub interaktsioon mudelisse sisse kirjutada siis, kui see interaktsioon on teoreetiliselt mõtekas (ühe prediktori mõju võiks sõltuda teise prediktori tasemest).
Interaktsiooni koefitsiendi määramine võib suurendada ebakindlust teiste parameetrite määramisel, seda eriti siis kui interaktsiooni parameeter on korreleeritud oma komponentide parameetritega (vt pairs(model)).

Isegi kui interaktsiooniparameetri posteerior hõlmab 0-i, tuleb interaktsiooni parameetrit mudelisse pannes arvestada, et individuaalsete prediktorite mõju ei saa summeerida pelgalt läbi nende koefitsientide. Selle asemel tuleb vaadata sirge tõusu erinevatel teiste prediktorite väärtustel (nagu eelneval joonisel)

Kui tavaline interaktsioonimudel on $y = a + b1x1 + b2x2 + b3x1x2$, siis mis juhtub, kui meie mudel on $y = b1x1 + b3x1x2$? See tähendab, et me surume b2 väärtuse nulli, mis võib ära rikkuda mudeli teiste parameetrite posteeriorid! Kui teil on alust arvata, et b2-l puudub otsene mõju y väärtusele (kuid tal on mõju b1 väärtusele), siis võib muidugi ka sellist mudelit kasutada. Aga see on haruldane juhtum.

## Hierarhilised mudelid 

Hierarhiline mudel kajastab sellise katse või vaatluse struktuuri, kus andmed ei grupeeru mitte ainult katse- ja kontrolltingimuste vahel, vaid ka nende gruppide sees klastritesse ehk alamgruppidesse. Näiteks, kui me mõõdame platseebo-kontrollitud uuringus kümmet patsienti ja teeme igale patsiendile viis kordusmõõtmist (kahetasemeline mudel). Või kui mõõdame kalamaksaõli mõju matemaatikaeksami tulemustele kümnes koolis, ja igas neist viies klassis (kolmetasemeline mudel). 
Tavapärane lähenemine oleks kõigepealt keskmistada andmed iga klassi sees ning seejärel keskmistada iga kooli sees (võtta igale koolile 5 klassi keskmine). Ning seejärel, võttes iga kooli keskmise üheks andmepunktiks, teha soovitud statistiline test (N = 10, sest meil on 10 kooli). Paraku, sellisel viisil talitades alahindame varieeruvust, mistõttu meie statistiline test alahindab ebakindluse määra arvutatud statistiku ümber. Hierarhilised mudelid, mis kajastavad adekvaatselt katse struktuuri, aitavad sellest murest üle saada. Üldine soovitus on, et kui teie katse struktuur seda võimaldab, siis peaksite alustama modelleerimist hierarhilistest mudelitest.

Hierarhilised mudelid on eriti kasulikud, kui teil on osades klastrites vähem andmepunkte kui teistes, sest nad vaatavad andmeid korraga nii klastrite vahel kui klastrite sees ning kannavad informatsiooni üle klastritest, kus on rohkem andmepunkte, nendesse klastritesse, kus on vähe andmeid. See parandab hinnangute täpsust.

> Hierarhilised mudelid modelleerivad eksplitsiitselt varieeruvust klasrtite sees ja klastrite vahel.

### Shrinkage

Oletame, et te plaanite reisi Kopenhaagenisse ja soovite sellega seoses teada, kui kallis on keskeltläbi õlu selle linna kõrtsides. Teile on teada õlle hind kolmes Kopenhaageni kõrtsis, mida ei ole just palju. Aga sellele lisaks on teile teada ka õlle hind 6-s Viini, 4-s Praha ja 5-s Pariisi kõrtsis. Nüüd on teil põhimõtteliselt kolm võimalust, kuidas sellele probleemile läheneda. 

1. Te arvestate ainult Kopenhaageni andmeid ja ignoreerite teisi, kui ebarelevantseid. See meetod töötab hästi siis, kui teil on Kopenhaageni kohta palju andmeid (aga teil ei ole).

2. Te arvestate võrdselt kõiki andmeid, mis teil on --- ehk te võtate keskmise kõikidest õllehindadest, hoolimata riigist. See töötab parimini siis, kui päriselt pole vahet, millisest riigist te oma õlle ostate, ehk kui õlu maksab igal pool sama palju. Antud juhul pole see ilmselt parim eeldus.

3. Te eeldate, et õlle hinna kujunemisel erinevates riikides on midagi ühist, aga et seal on ka erinevusi. Sellisel juhul tahate te fittida hierarhilise mudeli, kus teie hinnang õlle hinnale Kopenhaagenis sõltuks mingil määral (aga mitte nii suurel määral, kui eelmises punktis) ka teie kogemustest teistes linnades. Sama moodi, teie hinnang õlle hinnale Pariisis, Prahas jne hakkab mingil määral sõltuma kõikide linnade andmetest.



> Kui teil on olukord, kus te mõõdate erinevaid gruppe, mis küll omavahel erinevad, aga on ka teatud määral sarnased (näiteks testitulemused grupeerituna kooli kaupa), siis on mõistlik kasutada kõikide gruppide andmeid, et adjusteerida iga grupi spetsiifilisi parameetreid. Seda adjusteerimise määra kutsutakse "shrinkage". 

Shrinkage toimub parameetri keskväärtuse suunas ja mingi grupi shrinkage on seda suurem, mida vähem on selles grupis liikmeid ja mida kaugemal asub see grupp kõikide gruppide keskväärtusest. Shrinkage on põhimõtteliselt sama nähtus, mis juba Francis Galtoni poolt avastatud regressioon keskmisele.
Regressioon keskmisele on stohhastiline protsess kus, olles sooritanud n mõõtmist ja arvutanud nende tulemuste põhjal efekti suuruse, see valimi ES peegeldab nii tegelikku ES-i kui juhuslikku valimiviga. Kui valimivea osakaal ES-s on suur, siis lisamõõtmised vähendavad keskeltläbi efekti suurust. Shrinkage erineb sellest ainult selle poolest, et lisamõõtmised meenutavad ainult **osaliselt** algseid mõõtmisi. 

Kasutades hierarhilisi mudeleid saab edukalt võidelda ka *multiple testingu* ehk mitmese testimise probleemiga. See probleem on lihtsalt sõnastatav: kui te sooritate palju võrdluskatseid ja statistilisi teste olukorras, kus tegelik katseefekt on tühine, siis tänu valimiveale annavad osad teie paljudest testidest ülehinnatud efekti. Seega, kui meil on kahtlus, et enamus võrdlusi on "mõttetud" ja me ei oska ette ennustada, millised võrdlused neist (kui üldse mõni) võiks anda tõelise teaduslikult mõtteka efekti, siis on lahendus kõiki saadud efekte kunstlikult pisendada kõikide efektide keskmise suunas. Mudeli kontekstis kutsutakse sellist lähenemist *shrinkage*-ks. Aga kui suurel määral seda teha? See sõltub nii sellest, kui palju teste me teeme, valimi suurusest, kui ka sellest, kuidas jaotuvad mõõdetud efektisuurused (milline on efektisuuruste varieeruvus testide vahel). 

Bayesi lahendus on, et me lisame mudelisse veel ühe hierarhilise priori, mis kõrgub üle gruppide-spetsiifilise priori. Seega anname me olemasolevale priorile uue kõrgema taseme meta-priori, mis tagab, et informatsiooni jagatakse gruppide vahel ja samal ajal ka gruppide sees. Sellise lahenduse õigustus on, et me usume, et erinevad alam-grupid pärinevad samast üli-jaotusest ja neil on omavahel midagi ühist (ehkki alam-gruppide vahel võib olla ka reaalseid erinevusi). Näiteks, et kõik klassid saavad oma lapsed samast lastepopulatsioonist, aga siiski, et leidub ka eriklasse eriti andekatele. 

Selline mudel tagab, et samamoodi nagu mudeli ennustused individaalsete andmepunktide kohta iga alam-grupi sees "liiguvad lähemale" oma alam-grupi keskmisele, samamoodi liiguvad ka alam-gruppide keskmised lähemale üldisele grupi keskmisele. Selle positiivne mõju on valealarmide vähendamine ja oht on, et me kaotame ka tõelisi efekte. Bayesi eelis on, et see oht realiseerub ainult niipalju, kuipalju meie mudel ei kajasta reaalset katse struktuuri. Klassikalises statistikas rakendatavad multiple testingu korrektsioonid (Bonfferroni, ANOVA jt) on kõik teoreetiliselt kehvemad. 

Lihtsaim shrinkage mudeli tüüp on mudel, kus me laseme vabaks interceptid, aga mitte tõusunurgad. Igale klastrile vastab mudelis oma intercepti parameeter ja oma intercepti prior. Lisaks annab mudel meile fittimise käigus valimi andmete põhjal ise parameetrid kõrgema taseme priorisse, mis on ühine kõikidele interceptidele. Seega me määrame korraga interceptide parameetrid ja kõrgema taseme priori parameetrid, mis tähendab, et informatsioon liigub mudelit fittides mõlemat pidi --- mööda hierarhiat alt ülesse ja ülevalt alla. Selline mudel usub, et erinevate koolide keskmine tase erineb (seda näitab iga kooli intercept), aga juhul kui me mõõdame näiteks kalamaksaõli mõju õppeedukusele, siis selle mõju suurus ei erine koolide vahel (kõikide koolide tõusuparameetrid on identsed).

### ANOVA-laadne mudel

Lihtne ANOVA on sageduslik test, mis võrdleb gruppide keskmisi mitmese testimise kontekstis. Siin ehitame selle Bayesi analoogi, mis samuti hindab gruppide keskmisi mitmese testimise kontekstis. Põhiline erinevus seisneb selles, et kui ANOVA punktennustus iga grupi keskväärtusele võrdub valimi keskväärtusega ja ANOVA pelgalt kohandab usaldusintervalle selle keskväärtuse ümber, siis bayesiaanlik mudel püüab ennustada igale grupile selle tegelikku kõige tõenäolisemat keskväärtust arvestades kõigi gruppide andmeid. Shrinkage-i roll on ekstreemseid gruppe "tagasi tõmmates" vähendada ebakindlust iga grupi keskmise ennustuse ümber. Shrinkage käigus tõmmatakse gruppe kõikide gruppide keskmise poole seda tugevamalt, mida kaugemal nad sellest keskmisest on. Sellega kaasneb paratamatult mõningane süstemaatiline viga, kus tõelised efektid tulevad välja väiksematena, kui nad tegelikult on. Kui ilma tegelike efektideta gruppide arv on väga suur võrreldes päris efektidega gruppidega, siis võib shrinkage meie pärisefektid sootuks ära kaotada. Kahjuks on see loogiline paratamatus; alternatiiviks on olukord, kus meie üksikud pärisefektid upuvad sama suurte pseudoefektide merre. 

*The data contain GCSE exam scores on a science subject. Two components of the exam were chosen as outcome variables: written paper and course work. There are 1,905 students from 73 schools in England. Five fields are as follows.*

1. School ID

2. Student ID

3. Gender of student
  
  0 = boy
  
  1 = girl
  
4. Total score of written paper

5. Total score of coursework paper

Missing values are coded as -1.

```{r, eval=F}
df <- read.table(file = "data/Gcsemv.txt", sep = " ", dec = ".", header = FALSE) 

df$V4[df$V4==-1] <- NA
df$V5[df$V5==-1] <- NA
colnames(df) <- c("school", "student", "sex", "score1", "score2")

df$school <- as.factor(df$school)
df$student <- as.factor(df$student)
#write.csv(df, "schools.csv")
```


Alustuseks mitte-hierarhiline mudel, mis arvutab keskmise score1 igale koolile eraldi. See on intercept-only mudel, mis tähendab, et me hindame testitulemuse keskväärtust kooli kaupa ja igale koolile sõltumatult kõigist teistest koolidest. Me ei püüa siin ennustada testitulemuste väärtusi x-i väärtuste põhjal. Selles mudelis on tavapärased ühetasemelised priorid, ainult mu on ümber nimetatud a_school-iks ja sellele on antud indeks [school], mis tähendab, et mudel arvutab a_school-i, ehk keskmise testitulemuse, igale koolile. Kuna siin puuduvad kõrgema taseme priorid, siis vaatab mudel igat kooli eraldi ja ühegi kooli hinnang ei arvesta ühegi teise kooli andmetega.

```{r, eval=F}
df1 <- na.omit(df)
df2 <- df %>% filter(score1>0) 
#muide, need mudelid töötavad ka df-ga, imputeerides NAd

#m1 <- map2stan(
    #alist(
        #score1~ dnorm( mu , sigma ) ,
        #mu <- a + a_school[school] ,
        #a ~ dnorm(50, 30),
        #a_school[school] ~ dnorm( 0 , 20 ),
        #sigma ~ dcauchy(0,1)
#), data=df2 )
#see mudel arvutab keskmise intercepti ja 
#grupispetsiifilised interceptid tuleb sellega liita
#siit tuleb hästi ülevaatlik võrdlus iga kooli erinevuse kohta keskmisest

#järgmine mudel arvutab lihtsalt grupi-spetsiifilised interceptid

m2 <- map2stan(
    alist(
        score1~ dnorm( mu , sigma ) ,
        mu <- a_school[school],
        a_school[school]  ~ dnorm(50, 30),
        sigma ~ dcauchy(0,1)
), data=df2 )
precis(m2, depth = 2)

```

Igale koolile antud hinnang on sõltumatu kõigist teistest koolidest.


Ja nüüd hierarhiline mudel, mis teab koolide vahelisest varieeruvusest. Siin leiab a_school-i priorist teise taseme meta-parameetri nimega sigma_school, millele on defineeritud oma meta-prior. 

```{r, eval=F}
#glimmer(score1 ~ (1|school), data=df1) #intercept-only hierarhiline mudel

m3 <- map2stan(
    alist(
        score1~ dnorm( mu , sigma ) ,
        mu <- a_school[school],
        a_school[school]  ~ dnorm(50, sigma_school), #50 võiks olla keskmine testi tulemus
        sigma_school~ dcauchy(0,1),
        sigma ~ dcauchy(0,1)
), data=df2 )
precis(m3, depth = 2)
```

Nagu näha on sigma_school < sigma, mis tähendab, et koolide vaheline varieeruvus on väiksem kui õpilaste vaheline varieeruvus neis koolides. Seega sõltub testi tulemus rohkem sellest, kes testi teeb kui sellest, mis koolis ta käib. Loogika on siin järgmine: samamoodi nagu testitulemustel on jaotus õpilasekaupa, on neil ka jaotus koolikaupa. Koolikaupa jaotus töötab priorina õpilasekaupa jaotusele. Aga samas vajab kooli kaupa jaotus oma priorit --- ehk meta-priorit. Seega saame me samast mudelist hinnangu nii testitulemustele kõikvõimalike õpilaste lõikes, kui ka kõikvõimalike koolide lõikes. Mudel ennustab ka nende koolide ja õpilaste tulemusi, keda tegelikult olemas ei ole, aga kes võiksid kunagi sündida.    


ning veel üks hierarhiline mudel, mis teab nii koolide skooride keskmiste varieeruvust kui koolide vahelist varieeruvust.

```{r, eval=F}
m4 <- map2stan(
    alist(
        score1~ dnorm( mu , sigma ) ,
        mu <- a_school[school],
        a_school[school]  ~ dnorm(mu_school, sigma_school),
        mu_school~ dnorm(50, 20),
        sigma_school~ dcauchy(0,1),
        sigma ~ dcauchy(0,1)
), data=df2 )
precis(m4, depth = 2)
```

```{r, eval=F}
compare(m2, m3, m4)
```

m3 on parim mudel, aga ka m4 ja m2 omavad mingit kaalu.

```{r fig.height=10, fig.width=4, eval=F}
#coeftab(m2, m3, m4)
plot(coeftab(m2, m3, m4))
```

Siin on hästi näha shrinkage m3 ja m4 puhul, võrreldes m2-ga, mis ei tee multiple testingu korrektsiooni. Nende koolide puhul, kus usaldusintervall on laiem, on ka suurem shrinkage (mudel võtab nende kohta suhteliselt rohkem infot teistest koolidest sest need koolid ise on mingil põhjusel suhteliselt infovaesed)

### Vabad interceptid klassikalises regressioonimudelis

Ennustame score1 ja score2 summa sõltuvust sex-ist. Küsimus: kui palju poiste ja tüdrukute matemaatikaoskused erinevad? Fitime mudeli, mis laseb vabaks intercepti. **Selle mudeli eeldus on, et igal koolil on oma baastase (oma intercept), aga kõikide koolide efektid (mudeli tõusu-koefitsient) on identsed.**

Me kasutame prediktorina binaarset kategoorilist muutujat. See on analoogiline olukord ANOVA mudelile, mis võtab arvesse multiple testingu olukorra, mis meil siin on.
```{r}
#df2 <- schools
df2 <- read.csv( "data/schools.csv")
df2 <- df2 %>% mutate(summa=score1 + score2) %>% na.omit()
df2$sex <- as.factor(df2$sex)
f1 <- glimmer(summa~ sex + (1 | school), data=df2)
```

```{r }
m1 <- map2stan(alist(
    summa ~ dnorm( mu , sigma ),
    mu <- Intercept +
        b_sex1*sex1 +
        v_Intercept[school],
    Intercept ~ dnorm(0,200),
    b_sex1 ~ dnorm(0,10),
    v_Intercept[school] ~ dnorm(0,sigma_school),
    sigma_school ~ dcauchy(0,2),
    sigma ~ dcauchy(0,2)
), data= f1$d #siin tuleb kasutada glimmeri poolt loodud andmetabelit sest glimmer teeb factorid Stanile sõõdavaks
)
```

Siin on v_Intercept kooli-spetsiifiline korrektsioonifaktor, mis tuleb liita üldisele Interceptile. mean(v_Intercept) == 0. Me eeldame, et korrektsioonid on normaaljaotusega.
Alternatiivne viis seda mudelit kirjutada oleks `mu <- Intercept[school] + b_sex1*sex1` ja see töötab smamoodi (nüüd on iga kooli intercept kohe eraldi). 

```{r fig.height=8, fig.width=6}
plot(precis(m1, depth = 2))
```


sex=1 ehk sex1 on tüdruk. Ja selle soo tulemused on tõesti paremad kui 0-seksi omad. intercept annab siin sex=0 (poisid) keskmise  skoori kooli kaupa (kui liita üldisele interceptile kooli-spetsiifiline intercept). Kui tahame näiteks hinnangut 2. kooli tüdrukute skoorile (ehk tõelisele matemaatikavõimekusele) siis: 

*Intercept + b_sex1 + intercept[2]* 

annab meile selle posteeriori. Poistele sama 2. kooli kohta:

*Intercept + intercept[2]*

Ja poiste-tüdrukute erinevus skooripunktides võrdub 

*b_sex1* 

```{r}
s1 <- as.data.frame(m1@stanfit)
sch2_intercept <- s1$Intercept + s1$b_sex1 + s1$`v_Intercept[2]`
#median(sch2_intercept)
#HPDI(sch2_intercept)
dens(sch2_intercept)
```


Siin on eeldus, et kõikides koolides on sama poiste ja tüdrukute vaheline erinevus (b_sex1), kuid erinevad matemaatikateadmiste baastasemed (mudeli intercept on koolide vahel vabaks lastud, kuid tõus mitte). 

### vabad tõusud ja interceptid

Milline näeb välja mudel, kus me laseme vabaks nii intercepti kui tõusu?

```{r }
f2 <- glimmer(summa~ sex + (1 + sex | school), data=df2)
```

nüüd on meil lisaparameetrid v_sex1, mis annab tõusu igale koolile eraldi ning Rho-school, mis annab korrelatsiooni intercepti ja tõusu vahel. Nüüd me jagame informatsiooni erinevat tüüpi parameetrite, nimelt interceptide ja tõusude, vahel. Selleks ongi vaja Rho lisa-parameetrit. Nüüd ei modelleeri me intercepti ja tõusu enam 2 eraldi normaaljaotuste abil vaid ühe 2-dimensionaalse normaaljaotusega (mvnorm2).

prior korrelatsioonile Interceptide ja tõusude vahel on lkjcorr. Selle ainus parameeter on K. Mida suurem K, seda rohkem on prior konsentreeritud 0 korrelatsiooni ümber. K = 1 annab tasase priori. Meie kasutame K = 2, mis töötab laia vahemiku mudelitega.
```{r}
R <- rlkjcorr( 1e4 , K=2 , eta=2 )
dens( R[,1,2] , xlab="correlation" )
```
*Joonis: korrelatsiooni prior (nõrgalt informatiivne --- suunab posteeriori eemale ekstreemsetest korrelatsioonidest).*


```{r fig.height=10, fig.width=6}
m2 <- map2stan(alist(
    summa ~ dnorm( mu , sigma ),
    mu <- Intercept +
        b_sex1*sex1 +
        v_Intercept[school] +
        v_sex1[school]*sex1,
    Intercept ~ dnorm(100,100),
    b_sex1 ~ dnorm(0,10),
    c(v_Intercept,v_sex1)[school] ~ dmvnorm2(0,sigma_school,Rho_school),
    sigma_school ~ dcauchy(0,2),
    Rho_school ~ dlkjcorr(2),
    sigma ~ dcauchy(0,2)
), f2$d)
plot(precis(m2, depth = 2))
```



```{r}
s <- extract.samples(m2)
dens( s$Rho_school[,1,2] )
```

Meil on negatiivne korrelatsioon intercepti ja tõusu vahel. Seega, mida väiksem on poiste keskmine skoor koolis (=intercept), seda suurem om erinevus poiste ja tüdrukute skooride vahel (= tõus).


Nüüd saab 2. kooli skoori tüdrukutele valemiga: 

*Intercept + b_sex1 + v_intercept[2] + v_sex1[2]* 

Sama skoor poistele:

*Intercept + v_intercept[2]*  

ja tüdrukute ja poiste erinevus 2. koolile: 

*b_sex1 + v_sex1[2]*

tüdrukute-posite erinevus üle kõikide koolide:

*b_sex1*

tüdrukute keskmine skoor üle kõikide koolide:

*Intercept + b_sex1*

ja poiste keskmine skoor üle kõikide koolide:

*Intercept*

Tõmbame mudelist ennustused 1., 2. ja 37. kooli poiste skooridele järgmisel semestril:
```{r}
df2$school <- as.factor(df2$school)
d.pred <- list(
  school=c(1, 2, 37),
  sex1= 0
)

sim_sch <- sim(m2, data= d.pred) 
pred.p <- apply( sim_sch , 2 , mean )
pred.p.PI <- apply( sim_sch , 2 , PI )

pred.p.PI
```

NB! kasutades sim() saame me enustused andmepunktide (üksikute poiste tasemel). Antud juhul jääb ennustuse kohaselt esimeses koolis 89% individuaalseid skoore vahemikku 61-132 punkti 200-st võimalikust. 

Kui meid huvitab hoopis nende koolide keskmine skoor järgmisel semestril, siis kasuta sim() asemel link() funktsiooni.
```{r}
sim_sch <- link(m2, data= d.pred) 
pred.p <- apply( sim_sch , 2 , mean )
pred.p.PI <- apply( sim_sch , 2 , PI )

pred.p.PI
```

Esimeses koolis jääb keskmine poiste skoor 89% tõenäosusega vahemikku 80-112 punkti.

```{r}
compare(m1, m2)
```

Tundub, et tõusude vabakslaskine oli hea mõte. Ma saan hästi pihta, et erinevad koolid õpetavad matemaatikat erineva kvaliteediga. Aga miks peaks erinevates Inglismaa koolides olema erinev vahe poiste ja tüdrukute matemaatikateadmistel? Kas olukorras, kus meil on hea kool, läheb see vahe väiksemaks või suuremaks? Tehke kindlaks!!! ploti slope vs. intercept.

```{r}
s2 <- as.data.frame(m2@stanfit)
ss2 <- apply(s2,2,mean)
ss2 <- as.data.frame(ss2) 
ss2$names <- colnames(s2)
ss2 <- spread(ss2, key=names, value = ss2) #alternatiiv oleks regexpr kasutamine koos filter() verbiga.
ss3 <- ss2 %>% select(starts_with("v_Int")) %>% gather
ss4 <- ss2 %>% select(starts_with("v_sex")) %>% gather

plot(ss3$value, ss4$value, xlab="poiste skoor", ylab="erinevus poiste-tydrukute vahel")
abline(lm(ss4$value~ss3$value))

```

Tõepoolest: mida suurem on koolis poiste skoor (parem kool), seda väiksem on poiste ja tüdrukute erinevus. Aga seos on kaunis nõrk! 

Muide sel joonisel tähendavad negatiivsed väärtused alla keskmist väärtust, mitte tingimata negatiivset erinevust või negatiivset skoori. Miks?

Arvutage nüüd poiste ja tüdrukute keskmine skoor kooli kaupa ja vaadake uuesti sõltuvust samasse erinevusesse. Mis on õigem viis: kas fittida ilma interceptita mudel (nagu eelmises peatükis) ja kasutada otse selle koefitsiente või kasutada meie m2 mudelit ning arvutada selle mudeli koefitsientide põhjal uus statistik (kaalutud keskmine näiteks)? Miks?

```{r}
postcheck(m2)
```

### 4.15.4. hierarhiline mudel pidevate prediktoritega

Siin püüame ennustada score1 mõju score2 väärtusele.

```{r}
#df2 <- read.csv( "data/schools.csv")
df2 <- schools
plot(df2$score2, df2$score1)
abline(lm(score1~score2, data=df2))
```

Kõigepealt lihtne regressioon lm()-ga (see ei ole hierarhiline mudel)
```{r}
lm(score1~ score2, data=df2)
```

score2 tõus 1 punkti võrra tõstab score1-e 0.39 punkti võrra.


Modelleerime seost üle Bayesi hierarhilise mudeli, kus ainult Intercept on vabaks lastud.

```{r}
f <- glimmer(score1~score2 + (1 | school), data=df2)

```



```{r fig.height=10, fig.width=6}
m1 <- map2stan(alist(
    score1 ~ dnorm( mu , sigma ),
    mu <- Intercept +
        b_score2*score2 +
        v_Intercept[school],
    Intercept ~ dnorm(50,50),
    b_score2 ~ dnorm(0,10),
    v_Intercept[school] ~ dnorm(0,sigma_school),
    sigma_school ~ dcauchy(0,2),
    sigma ~ dcauchy(0,2)
), data=f$d)
plot(precis(m1, depth = 2))
```

Siin ei ole individuaalsed interceptid tõlgenduslikult informatiivsed, aga nende sissepanek parandab mudeli ennustust beta koefitsiendile (beta läheb väiksemaks ja ebakindlus selle hinnangu ümber kasvab).

```{r}
precis(m1)
```

Siin tuleb beta veidi väiksem - 0.36. Kuna sigma_school < sigma, siis tundub, et koolide vaheline varieeruvus on väiksem kui laste vaheline varieeruvus (sigma on üle kõigi koolide). iga kooli baastase tuleb Intercept + v_Intercept[] aga selle mudeli järgi on kõikide koolide score2 ja score1 sõltuvus sama tugevusega.

Laseme siis ka tõusud vabaks
```{r}
f1 <- glimmer(score1~score2 + (1 +  score2 | school), data=df2)
```

```{r fig.height=10, fig.width=6}
m2 <- map2stan(alist(
    score1 ~ dnorm( mu , sigma ),
    mu <- Intercept +
        b_score2*score2 +
        v_Intercept[school] +
        v_score2[school]*score2,
    Intercept ~ dnorm(50,50),
    b_score2 ~ dnorm(0,10),
    c(v_Intercept,v_score2)[school] ~ dmvnorm2(0,sigma_school,Rho_school),
    sigma_school ~ dcauchy(0,2),
    Rho_school ~ dlkjcorr(2),
    sigma ~ dcauchy(0,2)
), data=f1$d)

plot(precis(m2, depth = 2))
```

nüüd saame igale koolile arvutada oma intercepti ja oma tõusu (ikka samamoodi: Intercept + v_intercept[] ja b_score2 + v_score2[])

```{r}
precis(m2)
```



```{r warning=F}
m0 <- map2stan( alist(score1 ~ dnorm( mu , sigma ),
    mu <- Intercept + b_score2*score2 ,
    Intercept ~ dnorm(50,50),
    b_score2 ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
    ), data=f$d )
compare(m0,m1,m2)
```
m2 on selgelt parem mudel, kuigi m3 hinnangud interceptidele on suurema ebakindlusega. beta on nyyd 0.35

```{r}
precis(m0)
```
0-mudel, mis on kõige kehvem, on kõige suurema betaga ja kõige väiksema ebakindlusega selle ümber. See on tavaline --- hierarhiline mudel modelleerib ebakindlust paremini (realistlikumalt) ja vähendab üle-fittimise ohtu (beta tuleb selle võrra väiksem).

