---
title: "brms ja rstanarm"
---

```{r message=FALSE, warning=FALSE, error=FALSE}
library(tidyverse)
#library(rstanarm)
library("brms")
```


#Hierarchical models

##brms



```{r echo=FALSE}
 data("kidney")
 head(kidney, n = 3)
```

Variable time represents the recurrence time of the infection, censored indicates if time is right censored (1) or not censored (0), variable patient is the patient id, and recur indicates if it is the first or second recurrence in that patient. Finally, age, sex, and disease make up the predictors.

fit1 <- brm(formula = time | cens(censored) ~ age * sex + disease
            + (1 + age|patient),
            data = kidney, family = lognormal(),
            prior = c(set_prior("normal(0,5)", class = "b"),
                      set_prior("cauchy(0,2)", class = "sd"),
                      set_prior("lkj(2)", class = "cor")),
            warmup = 1000, iter = 2000, chains = 4,
            control = list(adapt_delta = 0.95))
            
            
Everything before the ∼ sign relates to the response part of formula. Usually this is just one variable name. To incorporate additional information about the response, add one or more terms of the form | fun(variable). fun may be one of a few functions defined internally in brms and variable corresponds to a variable in the data supplied by the user. In this example, cens makes up the function that handles censored data, and censored is the variable that contains information on the censoring. Other available functions are weights and disp to allow different sorts of weighting, se to specify known standard errors primarily for meta-analysis, trunc to define truncation boundaries, trials for binomial models, and cat to specify the number of categories for ordinal models.

Everything on the right side of ∼ specifies predictors. Group-level terms are of the form (coefs | group), where coefs contains one or more variables whose effects are assumed to vary with the levels of the grouping factor given in group. Multiple grouping factors each with multiple group-level coefficients are possible. In the present example, only one group-level term is specified in which 1 + age are the coefficients varying with the grouping factor patient. This implies that the intercept of the model as well as the effect of age is supposed to vary between patients. By default, group-level coefficients within a grouping factor are assumed to be correlated. 

Argument family: a call to a family function or a character string naming the family. If not otherwise specified, default link functions are applied. Linear and robust linear regression can be performed using the gaussian or student family combined with the identity link. For dichotomous and categorical data, families bernoulli, binomial, and categorical combined with the logit link, by default. Families poisson, negbinomial, and geometric allow for modeling count data. Families lognormal, Gamma, exponential, and weibull can be used (among others) for survival regression. Ordinal regression can be performed using the families cumulative, cratio, sratio, and acat. Finally, families zero_inflated_poisson, zero_inflated_negbinomial, zero_inflated_binomial, zero_inflated_beta, hurdle_poisson, hurdle_negbinomial, and hurdle_gamma can be used to model excess zeros in the response. 

In our example, we use family = lognormal() implying a log-normal “survival” model for the response variable time.

###Priors

population-level effects have their corresponding regression parameter, which are named as b_<coef>, where <coef> represents the name of the population-level effect. **The default prior is an improper flat prior.**

check which parameters can have priors
get_prior(rating ~ treat + period + carry + (1|subject),
          data = inhaler, family = cumulative())
          
          ## define some priors          
prior <- c(prior_string("normal(0,10)", class = "b"),
           prior(normal(1,2), class = b, coef = treat),
           prior_(~cauchy(0,2), class = ~sd, 
                  group = ~subject, coef = ~Intercept))
                  
The functions prior, prior_, and prior_string are aliases of set_prior each allowing for a differnt kind of argument specification. prior allows specifying arguments as expression without quotation marks using non-standard evaluation. prior_ allows specifying arguments as one-sided formulas or wrapped in quote. prior_string allows specifying arguments as strings just as set_prior itself.

1. Population-level ('fixed') effects: x1 and x2 have regression parameters b_x1 and b_x2 respectively. a normal prior with mean 0 and standard deviation 5 for x1, and a unit student-t prior with 10 degrees of freedom for x2:

set_prior("normal(0,5)", class = "b", coef = "x1") and

set_prior("student_t(10,0,1)", class = "b", coef = "x2").

To put the same prior on all population-level effects at once.

set_prior("<prior>", class = "b"). 

This also leads to faster sampling. 

set_prior("normal(0,2)", class = "b"),
set_prior("normal(0,10)", class = "b", coef = "x1") 

will set a normal(0,10) prior on the effect of x1 and a normal(0,2) prior on all other population-level effects.

 general priors on class "b" will not affect the intercept. Instead, the intercept has its own parameter class named "Intercept" and priors can thus be specified via set_prior("<prior>", class = "Intercept"). Technially, this prior is set on an intercept that results when internally centering all population-level predictors around zero to improve sampling efficiency. On this centered intercept, specifying a prior is actually much easier and intuitive than on the original intercept, since the former represents the expected response value when all predictors are at their means. 
 
 If desired, population-level effects can be restricted to fall only within a certain interval using the lb and ub arguments of set_prior. This is often required when defining priors that are not defined everywhere on the real line, such as uniform or gamma priors. When defining a uniform(2,4) prior, you should write set_prior("uniform(2,4)", lb = 2, ub = 4). When using a prior that is defined on the postive reals only (such as a gamma prior) set lb = 0. 
 
Standard deviations of group-level ('random') effects

Each group-level effect of each grouping factor has a standard deviation named sd_<group>_<coef>. Consider, for instance, the formula y ~ x1 + x2 + (1 + x1 | g). We see that the intercept as well as x1 are group-level effects nested in the grouping factor g. The corresponding standard deviation parameters are named as sd_g_Intercept and sd_g_x1 respectively. These parameters are restriced to be non-negative and, by default, have a half student-t prior with 3 degrees of freedom and a scale parameter that depends on the standard deviation of the response after applying the link function. Minimally, the scale parameter is 10. This prior is used (a) to be only very weakly informative in order to influence results as few as possible, while (b) providing at least some regularization to considerably improve convergence and sampling efficiency. To define a prior distribution only for standard deviations of a specific grouping factor, use 
set_prior("<prior>", class = "sd", group = "<group>"). To define a prior distribution only for a specific standard deviation of a specific grouping factor, you may write 
set_prior("<prior>", class = "sd", group = "<group>", coef = "<coef>"). 
              
 **verify that the priors indeed found their way into Stan's model code**
 
make_stancode(rating ~ treat + period + carry + (1|subject),
              data = inhaler, family = cumulative(),
              prior = prior)
              
```{r}
get_prior(rating ~ treat + period + carry + (1|subject),
          data = inhaler, family = cumulative())
prior <- c(prior_string("normal(0,10)", class = "b"),
           prior(normal(1,2), class = b, coef = treat),
           prior_(~cauchy(0,2), class = ~sd, 
                  group = ~subject, coef = ~Intercept))
make_stancode(rating ~ treat + period + carry + (1|subject),
              data = inhaler, family = cumulative(),
              prior = prior)
```



    A special shrinkage prior to be applied on population-level effects is the horseshoe prior. It is symmetric around zero with fat tails and an infinitely large spike at zero. This makes it ideal for sparse models that have many regression coefficients, although only a minority of them is non-zero. It can be applied on all population-level effects at once (excluding the intercept) by using set_prior("horseshoe(1)"). The 1 implies that the Student-t prior of the local shrinkage parameters has 1 degrees of freedom.
    
Each group-level effect of each grouping factor has a standard deviation parameter, which is restricted to be non-negative and, by default, has a half Student-t prior with 3 degrees of freedom and a scale parameter that is minimally 10.

In brms, standard deviation parameters are named as sd_<group>_<coef> so that sd_patient_Intercept and sd_patient_age are the parameter names in the example. If desired, it is possible to set a different prior on each parameter, but statements such as 

set_prior("student_t(3,0,5)", class = "sd", group = "patient") or even 

set_prior("student_t(3,0,5)", class = "sd") 

may also be used and are again faster because of vectorization.
    
If there is more than one group-level effect per grouping factor, correlations between group-level effects are estimated. the LKJ-Correlation prior with pa- rameter ζ > 0 is used. In brms correlation matrix parameters are named as cor_<group>, (e.g., cor_patient), so that set_prior("lkj(2)", class = "cor", group = "patient") is a valid statement. To set the same prior on every correlation matrix in the model, set_prior("lkj(2)", class = "cor") is also allowed   

```{r}
library(gapminder)
gapminder <- gapminder
#select only data from year 2007:
g2007 <- gapminder %>% filter(year==2007)
head(g2007)
g2007 <- g2007 %>% mutate(l_GDP=log10(gdpPercap))

get_prior(lifeExp ~ l_GDP + 
            + (1 + l_GDP|country) + (1 + l_GDP|continent),
            data = g2007)

prior <-  c(set_prior("normal(0,10)", class = "b"),
                      set_prior("cauchy(0,1)", class = "sd"),
                      set_prior("lkj(2)", class = "cor"))
make_stancode(lifeExp ~ l_GDP + 
            + (1 + l_GDP|country) + (1 + l_GDP|continent),
            data = g2007, family = gaussian(),
              prior = prior)

#all combinations of country and continent modelled
fit1 <- brm(lifeExp ~ l_GDP + (1 + l_GDP|country) + (1 + l_GDP|continent),
            data = g2007, family = gaussian(),
            prior = prior,
            warmup = 1000, iter = 2000, chains = 2,
            control = list(adapt_delta = 0.95))

#continent ignored
fit2 <- brm(lifeExp ~ l_GDP +  (1 + l_GDP|country),
            data = g2007, family = gaussian(),
            prior = prior,
            warmup = 1000, iter = 2000, chains = 2,
            control = list(adapt_delta = 0.95))

#country ignored 
fit3 <- brm(lifeExp ~ l_GDP +  (1 + l_GDP|continent),
            data = g2007, family = gaussian(),
            prior = prior,
            warmup = 1000, iter = 2000, chains = 2,
            control = list(adapt_delta = 0.95))

#nested model töötab valesti!!!
fit4 <- brm(lifeExp ~ l_GDP +  (1 +  l_GDP|continent/country),
            data = g2007, family = gaussian(),
            prior = prior,
            warmup = 1000, iter = 2000, chains = 2,
            control = list(adapt_delta = 0.95))
summary(fit4)


 
LOO(fit1, fit2, fit3, fit4)
```

```{r}
summary(fit1)
```

##Graphical checks

```{r}
fit3_data <- as.data.frame(fit3)
names(fit3_data)
datafit <- fit3$data
```

```{r}
cond <- data.frame(continent="Africa")
plot(marginal_effects(fit3), condition=cond, points=T)
aaa <- marginal_effects(fit3, condition=cond) 
aaa <- as.data.frame(aaa$l_GDP)
```


### the posterior predictive check

the dark line represents the density of the observed response, while each light blue line represents draws from the posterior-predictive distribution, that is the distribution of the response as predicted by the model. 

    The posterior predictive distribution is the distribution of the outcome variable implied by a model after using the observed data y (a vector of outcome values), and typically predictors X. For each draw of the parameters from the posterior distribution we generate an entire vector of outcomes. The result is an S x N matrix of simulations, where S is the the number of draws from the posterior distribution and N is the number of data points in y. That is, each row of the matrix is an individual "replicated" dataset of N observations. 

Similar densities of observed and model-implied responses give a first indication of the appropriateness of the model, although two models with similar posterior-predictive distribution might perform differently when it comes to actual prediction of new data. There is an increasing number of posterior-predictive checks to apply via pp_check --- help("PPC-overview"). To get a sense of bad model fit, try modeling skewed data (e.g., response or survival times) using a normal model. 

```{r}
pp_check(fit3)
#help("PPC-overview")
```


alternatiivne vaade - 5 ennustust heledalt ja tegelikud y andmed.
```{r}
library(bayesplot)
yrep <- posterior_predict(fit3, draws = 500)
ppc_hist(g2007$lifeExp, yrep[1:5,])
```

### Visualizing the posteriors

```{r}
fit3d <- as.data.frame(fit3$fit)
pars <- names(fit3d)
pars
mcmc_intervals(fit3d, pars=pars[-17]) #with pars left out the last parameter lp_
```


```{r}
mcmc_areas(fit3d, pars= c("b_l_GDP", "r_continent[Africa,Intercept]"))
```


## control the sampling process

In addition to choosing the number of iterations, warmup samples, and chains, the **control argument**. The most important reason to use control is to decrease the number of divergent transitions that cause a bias in the posterior. If you see the warning "There were x divergent transitions after warmup.", you should increase adapt_delta. To do this, write **control = list(adapt_delta = <x>)**, where <x> should be a value between 0.8 (current default) and 1. 

Stan will throw out a warning suggesting to increase max_treedepth, which can be accomplished by writing control = list(max_treedepth = <x>) with a positive integer <x> that should usually be larger than the current default of 10.

The model code and data for the present example can be extracted through **stancode(fit1)** and **standata(fit1)**. 

model summary with **summary(fit1)**

In general, every parameter is summarized using the mean (Estimate) and the standard deviation (Est.Error) of the posterior distribution as well as two-sided 95% Credible intervals (l-95% CI and u-95% CI) based on quantiles. 

An even more detailed investigation can be achieved by applying the shinystan package: **launch_shiny**

Looking at the group-level effects, the standard deviation parameter of age is suspiciously small. To test whether it is smaller than the standard deviation parameter of Intercept, we apply the hypothesis method:

`hypothesis(fit1, "Intercept - age > 0", class = "sd", group = "patient")`

Hypothesis Tests for class sd_patient:
                 Estimate Est.Error l-95% CI u-95% CI Evid.Ratio
Intercept-age > 0    0.39     0.27     0.03    Inf         67.97 

The one-sided 95% credibility interval does not contain zero, thus indicating that the standard deviations differ from each other in the expected direction. In accordance with this finding, the Evid.Ratio shows that the hypothesis being tested (i.e., Intercept - age > 0) is about 68 times more likely than the alternative hypothesis Intercept - age < 0.









Laseme 2s grupis SD-d vabaks ja hindame nende erinevuse.
```{r}
group <- rep(c("treat", "placebo"), each = 30)
symptom_post <- c(rnorm(30, mean = 1, sd = 2), rnorm(30, mean = 0, sd = 1))
dat1 <- data.frame(group, symptom_post)
head(dat1)
```

```{r}
fit1 <- brm(bf(symptom_post ~ group, sigma ~ group), 
            data = dat1, family = gaussian())
```

```{r}
summary(fit1)
```

me saame kaks regressioonijoont: keskmisele (mu=Intercept + grouptreat x group) ja sd-le (sigma= sigma_intercept + sigma_grouptreat x group). Arvesta, et group= 1 või 0 ja grouptreat=1. 
```{r}
plot(fit1, N=2, ask=F)
```

sigma_grouptreat, which is the contrast of the two residual standard deviations on the log-scale. we can compute the residual standard deviations on the original scale using the hypothesis method.

**Marginal effect** definitsioon: y väärtus, kui x1 = a, x2=b jne.

Marginal effects plot: Display marginal effects of one or more numeric and/or categorical predictors including two-way interaction effects.
```{r}
plot(marginal_effects(fit1), points = TRUE)
```


```{r}
hyp <- c("exp(sigma_Intercept) = 0",
         "exp(sigma_Intercept + sigma_grouptreat) = 0")
hypothesis(fit1, hyp)
```

We may also directly compare them and plot the posterior distribution of their difference.
```{r}
hyp <- "exp(sigma_Intercept + sigma_grouptreat) > exp(sigma_Intercept)"
(hyp <- hypothesis(fit1, hyp))
```
```{r}
plot(hyp, chars = NULL)
```
See on delta sigma posteerior

Nii saab mudeli koefitsientide fitid (posteeriorid)
```{r}
f <- fit1$fit %>% as.data.frame()
```


 In many applications, we have no or only a very vaque idea how the relationship between a predictor and the response looks like. A very flexible approach to tackle this problems is to use splines and let them figure out the form of the relationship. 4 term additive model.
 
```{r}
dat_smooth <- mgcv::gamSim(eg = 6, n = 200, scale = 2, verbose = FALSE)
head(dat_smooth)
```

The data contains the predictors x0 to x3 as well as the grouping factor fac indicating the nested structure of the data. We predict the response variable y using smooth terms of x1 and x2 and a varying intercept of fac. In addition, we assume the sigma to vary by a smoothing term of x0 and a varying intercept of fac.
```{r}
fit_smooth1 <- brm(bf(y ~ s(x1) + s(x2) + (1|fac), sigma ~ s(x0) + (1|fac)),
                   data = dat_smooth, family = gaussian(),
                   chains = 2, control = list(adapt_delta = 0.95))
```

```{r}
summary(fit_smooth1)
```

```{r}
plot(marginal_effects(fit_smooth1), points = TRUE, ask = FALSE)
```

## Kui x on ordered factor

monotooniline mudel - X-i väärtused on järjestatud kuid ei asu üksteisest ühekaugusel. Kui me tähistame need integer numbritega 1, 2 ja 3 siis 1 ja 3 võivad olla 2-st erineval kaugusel. brms-s töötavad nii ordered factor kui integer. 

Näide: rakkude kasv: puudub (0), väga vilets (1) enam-vähem (2), hea (3), kiire (4).

```{r}
income_options <- c("below_20", "20_to_40", "40_to_100", "greater_100")
income <- factor(sample(income_options, 100, TRUE), 
                 levels = income_options, ordered = TRUE)
mean_ls <- c(30, 60, 70, 75)
ls <- mean_ls[income] + rnorm(100, sd = 7)
dat <- data.frame(income, ls)

```

modeling income as a monotonic effect
```{r}
fit1 <- brm(ls ~ monotonic(income), data = dat)
```

```{r}
summary(fit1)
```
```{r}
plot(fit1, pars = "simplex")
```

```{r}
plot(marginal_effects(fit1))
```

all differences between adjacent categories had the same prior distribution. This can be changed. Suppose that, before looking at the data, we expected that the same amount of additional money matters more for people who generally have less money. We choose α1=2 and α2=α3=1, the latter being the default value of α. To fit the model we write:
```{r eval=FALSE}
prior4 <- prior(dirichlet(c(2, 1, 1)), class = "simplex", coef = "income")
fit4 <- brm(ls ~ monotonic(income), data = dat,
           prior = prior4, sample_prior = TRUE)
```

**hierarchical monotonic model**
Suppose that the 100 people in our sample data were drawn from 10 different cities; 10 people per city. Thus, we add an identifier for city to the data and add some city-related variation to ls. monotonic group-level effects have to be specified in separate terms in the model formula. Further, we have used the abbrevation mo for monotonic, which helps in shortening the formula.
```{r eval=FALSE}
dat$city <- rep(1:10, each = 10)
var_city <- rnorm(10, sd = 10)
dat$ls <- dat$ls + var_city[dat$city]

#hierarchical model:
fit5 <- brm(ls ~ mo(income) + (1 | city) + (mo(income) | city), data = dat)
```




## rstanarm

The goal of the rstanarm package is to make Bayesian estimation routine for the most common regression models. The default priors in rstanarm are designed to be weakly informative, by which we mean that they avoid placing unwarranted prior weight on nonsensical parameter values and provide some regularization to avoid overfitting, but also do allow for extreme values if warranted by the data. If additional information is available, the weakly informative defaults can be replaced with more informative priors.


womensrole dataset: whether a survey respondent agrees or disagrees with a conservative statement about the role of women in society. Modeled as a function of the gender and education of the respondents.


This is ordinary frequentist logistic regression
```{r}
data("womensrole", package = "HSAUR3")
womensrole$total <- womensrole$agree + womensrole$disagree
womensrole_glm_1 <- glm(cbind(agree, disagree) ~ education + gender,
                        data = womensrole, family = binomial(link = "logit"))
round(coef(summary(womensrole_glm_1)), 3)
```

Now Bayes:
Suppose we believe — prior to seeing the data — that α, β1, and β2 are probably close to zero, are as likely to be positive as they are to be negative, but have a small chance of being quite far from zero. These beliefs can be represented by Student t distributions with a few degrees of freedom in order to produce moderately heavy tails. In particular, we will specify 7 degrees of freedom. 
```{r}
library(rstanarm)
womensrole_bglm_1 <- stan_glm(cbind(agree, disagree) ~ education + gender,
                              data = womensrole,
                              family = binomial(link = "logit"), 
                              prior = student_t(df = 7), 
                              prior_intercept = student_t(df = 7),
                              chains = 1, cores = 1)
womensrole_bglm_1
```

Here we see the priors used:
```{r}
prior_summary(womensrole_bglm_1)
```

To specify your own prior
```{r eval=FALSE}
my_prior <- normal(location = c(-10, 0), scale = c(5, 2), autoscale = FALSE)
stan_glm(y ~ x1 + x2, data = dat, prior = my_prior)
```

 
 
 the “Bayesian point estimates” — which are represented by the posterior medians — are very similar to the maximum likelihood estimates. Here we have estimates of the standard deviation of the marginal posterior distributions, which are based on a scaling of the Median Absolute Deviation (MAD) from the posterior medians. 
 
 we can use the posterior_interval function to obtain a Bayesian uncertainty interval for β1
```{r}
ci95 <- posterior_interval(womensrole_bglm_1, prob = 0.95, pars = "education")
round(ci95, 3)
```

Model qoefs:

```{r}
cbind(Median = coef(womensrole_bglm_1), MAD_SD = se(womensrole_bglm_1))
```

 covariance matrix
 
```{r}
cov2cor(vcov(womensrole_bglm_1))
```

The launch_shinystan function in the shinystan package provides almost all the tools you need to visualize the posterior distribution and diagnose any problems with the Markov chains.
```{r}
launch_shinystan(womensrole_bglm_1)
```

posterior_predict, which can be passed a new data.frame to predict out-of-sample, but in this case is omitted to obtain in-sample posterior predictions:
```{r}
y_rep <- posterior_predict(womensrole_bglm_1)
dim(y_rep)
```

The resulting matrix has rows equal to the number of posterior simulations, which in this case is 2000 and columns equal to the number of observations in the original dataset, which is 42 combinations of education and gender. Each element of this matrix is a predicted number of respondents with that value of education and gender who agreed with the survey question and thus should be reasonably close to the observed proportion of agreements in the data. We can create a plot to check this:


```{r}
par(mfrow = 1:2, mar = c(5,3.7,1,0) + 0.1, las = 3)
boxplot(sweep(y_rep[,womensrole$gender == "Male"], 2, STATS = 
               womensrole$total[womensrole$gender == "Male"], FUN = "/"), 
        axes = FALSE, main = "Male", pch = NA,
        xlab = "Years of Education", ylab = "Proportion of Agrees")
with(womensrole, axis(1, at = education[gender == "Male"] + 1, 
                      labels = 0:20))
axis(2, las = 1)
with(womensrole[womensrole$gender == "Male",], 
     points(education + 1,  agree / (agree + disagree), 
            pch = 16, col = "red"))
boxplot(sweep(y_rep[,womensrole$gender == "Female"], 2, STATS = 
          womensrole$total[womensrole$gender == "Female"], FUN = "/"), 
          axes = FALSE, main = "Female", pch = NA,
        xlab = "Years of Education", ylab = "")
with(womensrole, axis(1, at = education[gender == "Female"] + 1,
     labels = 0:20))
with(womensrole[womensrole$gender == "Female",], 
     points(education + 1,  agree / (agree + disagree), 
            pch = 16, col = "red"))
```

As can be seen, the model predicts the observed data fairly well for six to sixteen years of education but predicts less well for very low or very high levels of education where there are less data.
Consequently, we might consider a model where education has a quadratic effect on agreement, which is easy to specify using R’s formula-based syntax.
```{r}
(womensrole_bglm_2 <- update(womensrole_bglm_1, formula. = . ~ . + I(education^2)))
```

Frequentists would test the null hypothesis that the coefficient on the squared level of education is zero. Bayesians might ask whether such a model is expected to produce better out-of-sample predictions than a model with only the level of education. The latter question can be answered using leave-one-out cross-validation or the approximation thereof provided by the loo function in the loo package.

```{r}
loo_bglm_1 <- loo(womensrole_bglm_1)
loo_bglm_2 <- loo(womensrole_bglm_2)
```
```{r}
par(mfrow = 1:2, mar = c(5,3.8,1,0) + 0.1, las = 3)
plot(loo_bglm_1, label_points = TRUE)
plot(loo_bglm_2, label_points = TRUE)
```

There are only one or two moderate outliers (whose statistics are greater than 0.5, which should not have too much of an effect on the resulting model comparison:
```{r}
compare_models(loo_bglm_1, loo_bglm_2)
```
In this case, there is little difference in the expected log pointwise deviance between the two models, so we are essentially indifferent between them after taking into account that the second model estimates an additional parameter. The “LOO Information Criterion (LOOIC)” has the same purpose as the Aikaike Information Criterion (AIC). This only assumes that any one observation can be omitted without having a major effect on the posterior distribution, which can be judged using the plots above.
```{r}
loo_bglm_1
```

Frequentists attempt to interpret the estimates of the model, which is difficult except when the model is linear, has no inverse link function, and contains no interaction terms. Bayesians can avoid this difficulty simply by inspecting the posterior predictive distribution at different levels of the predictors. For example,
```{r}
# note: in newdata we want agree and disgree to sum to the number of people we
# want to predict for. the values of agree and disagree don't matter so long as
# their sum is the desired number of trials. we need to explicitly imply the
# number of trials like this because our original data are aggregate. if we had
# bernoulli data then it would be a given we wanted to predict for single
# individuals.
newdata <- data.frame(agree = c(0,0), 
                      disagree = c(100,100), 
                      education = c(12,16), 
                      gender = factor("Female", levels = c("Male", "Female")))
y_rep <- posterior_predict(womensrole_bglm_2, newdata)
summary(apply(y_rep, 1, diff))
```
out of 100 women who have a college degree versus 100 women with only a high school degree, we would expect about 20 fewer college-educated women to agree with the question. There is an even chance that the difference is between 24
24 and 16, a one-in-four chance that it is greater, and one-in-four chance that it is less.





###Troubleshooting
####chains did not converge
By default, all rstanarm modeling functions will run four randomly initialized Markov chains, each for 2000 iterations (including a warmup period of 1000 iterations that is discarded). All chains must converge to the target distribution for inferences to be valid. If a warning message about Markov chains not converging, the first thing is to increase the number of iterations (iter = 3000). 

One way to monitor whether a chain has converged to the equilibrium distribution is to compare its behavior to other randomly initialized chains. This is the motivation for the Gelman and Rubin potential scale reduction statistic Rhat, which measures the ratio of the average variance of the draws within each chain to the variance of the pooled draws across chains. If all chains are at equilibrium, these will be the same and Rhat will be one. If the chains have not converged to a common distribution, the Rhat statistic will tend to be greater than one. Gelman and Rubin’s recommendation is that the independent Markov chains be initialized with diffuse starting values for the parameters and sampled until all values for Rhat are below 1.1. When any Rhat values are above 1.1 rstanarm will print a warning message.

####Divergent transitions

rstanarm will print a warning if there are any divergent transitions after the warmup period, in which case the posterior sample may be biased. The recommended method is to **increase the adapt_delta parameter** – target average proposal acceptance probability in the adaptation – which will in turn reduce the step size. Each of the modeling functions accepts an adapt_delta argument, so to increase adapt_delta you can simply change the value from the default value to a value closer to 1. The downside to increasing the target acceptance rate – and, as a consequence, decreasing the step size – is that sampling will tend to be slower. A smaller step size means that more steps are required to explore the posterior distribution.

####Maximum treedepth exceeded

Configuring the variant of HMC used by Stan involves putting a cap on the depth of the trees that it evaluates during each iteration. This is controlled through a maximum depth parameter max_treedepth. If rstanarm prints a warning about transitions exceeding the maximum treedepth you should try increasing the max_treedepth parameter using the optional control argument. For example, to increase max_treedepth to 20 (the default used rstanarm is 15) you can provide the argument **control = list(max_treedepth = 20)** to any of the rstanarm modeling functions. 

#Linear models lm

An experiment where clouds were seeded with different amounts of silver iodide to see if there was increased rainfall. This effect could vary according to covariates, which (except for time) are interacted with the treatment variable. Most people would probably be skeptical that cloud hacking could explain very much of the variation in rainfall and thus the prior mode of the R2 would probably be fairly small. 

    NB! here you only specify one prior, and that for the r squared. If you wish instead to give priors to every model qoefficient, as in rethinking, use the function stan_glm().

ordinary least squares:
```{r}
data("clouds", package = "HSAUR3")
ols <- lm(rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) +
            time, data = clouds)
round(coef(ols), 3)
```

Bayes:
```{r}
library(rstanarm)
post <- stan_lm(rainfall ~ seeding * (sne + cloudcover + prewetness + 
                                        echomotion) + time, data = clouds,
                prior = R2(location = 0.2) 
                )
post
```

The “Bayesian point estimates” appear quite different from the ordinary least squares estimates. However, the log-fit_ratio (i.e. lnω) is quite small, indicating that the model only slightly overfits the data when the prior derived above is utilized. Thus, it would be safe to conclude that the ordinary least squares estimator considerably overfits the data since there are only 24 observations to estimate 12 parameters with and no prior information on the parameters.

Also, it is not obvious what the estimated average treatment effect is since the treatment variable, seeding, is interacted with four other correlated predictors. However, it is easy to estimate or visualize the average treatment effect (ATE) using rstanarm’s posterior_predict function.
```{r}
clouds_cf <- clouds
clouds_cf$seeding[] <- "yes"
y1_rep <- posterior_predict(post, newdata = clouds_cf)
clouds_cf$seeding[] <- "no"
y0_rep <- posterior_predict(post, newdata = clouds_cf)
qplot(x = c(y1_rep - y0_rep), geom = "histogram", xlab = "Estimated ATE")
```
the treatment effect is not estimated precisely and is as almost as likely to be negative as it is to be positive.

#Generalized Linear Models for Continuous Data glm()

predict cognitive test scores of three- and four-year-old children given characteristics of their mothers. two predictors – a binary indicator for whether the mother has a high-school degree (mom_hs) and the mother’s score on an IQ test (mom_iq). we’ll use the default weakly informative priors for stan_glm, which are currently set to normal(0,10) for the intercept and normal(0,5) for the other regression coefficients. 
```{r}
data(kidiq)
post1 <- stan_glm(kid_score ~ mom_hs, data = kidiq, 
                  family = gaussian(link = "identity") 
                  )
post2 <- update(post1, formula = . ~ mom_iq)
post3 <- update(post1, formula = . ~ mom_hs + mom_iq)
post4 <- update(post1, formula = . ~ mom_hs * mom_iq)
post4
```

overlaying the regression lines on the data
```{r}
base <- ggplot(kidiq, aes(x = mom_hs, y = kid_score)) + 
  geom_point(size = 1, position = position_jitter(height = 0.05, width = 0.1)) + 
  scale_x_continuous(breaks = c(0,1), labels = c("No HS", "HS"))
  
base + geom_abline(intercept = coef(post1)[1], slope = coef(post1)[2], 
                   color = "skyblue4", size = 1)
```

There several ways we could add the uncertainty in our estimates to the plot. One way is to also plot the estimated regression line at each draw from the posterior distribution. To do this we can extract the posterior draws from the fitted model object using the as.matrix or as.data.frame methods:
```{r}
draws <- as.data.frame(post1)
colnames(draws)[1:2] <- c("a", "b")

base + 
  geom_abline(data = draws, aes(intercept = a, slope = b), 
              color = "skyblue", size = 0.1, alpha = 0.1) + 
  geom_abline(intercept = coef(post1)[1], slope = coef(post1)[2], 
              color = "skyblue4", size = 1)
```
```{r}
draws <- as.data.frame(as.matrix(post2))
colnames(draws)[1:2] <- c("a", "b")
ggplot(kidiq, aes(x = mom_iq, y = kid_score)) + 
  geom_point(size = 1) +
  geom_abline(data = draws, aes(intercept = a, slope = b), 
              color = "skyblue", size = 0.1, alpha = 0.05) + 
  geom_abline(intercept = coef(post2)[1], slope = coef(post2)[2], 
              color = "skyblue4", size = 1)
```

For the third and fourth models, each of which uses both predictors, we can plot the continuous mom_iq on the x-axis and use color to indicate which points correspond to the different subpopulatations defined by mom_hs. We also now plot two regression lines, one for each subpopulation:
```{r}
reg0 <- function(x, ests) cbind(1, 0, x) %*% ests 
reg1 <- function(x, ests) cbind(1, 1, x) %*% ests

args <- list(ests = coef(post3))
kidiq$clr <- factor(kidiq$mom_hs, labels = c("No HS", "HS"))
lgnd <- guide_legend(title = NULL)

base2 <- ggplot(kidiq, aes(x = mom_iq, y = kid_score, fill = relevel(clr, ref = "HS"))) + 
  geom_point( shape = 21, stroke = .2, size = 1) + 
  guides(color = lgnd, fill = lgnd) 
base2 + 
  stat_function(fun = reg0, args = args, aes(color = "No HS"), size = 1.5) +
  stat_function(fun = reg1, args = args, aes(color = "HS"), size = 1.5)
```

```{r}
reg0 <- function(x, ests) cbind(1, 0, x, 0 * x) %*% ests 
reg1 <- function(x, ests) cbind(1, 1, x, 1 * x) %*% ests
args <- list(ests = coef(post4))
base2 +
  stat_function(fun = reg0, args = args, aes(color = "No HS"), size = 1.5) + 
  stat_function(fun = reg1, args = args, aes(color = "HS"), size = 1.5)
```
```{r}
# Compare them with loo
loo1 <- loo(post1)
loo2 <- loo(post2)
loo3 <- loo(post3)
loo4 <- loo(post4)
(comp <- compare_models(loo1, loo2, loo3, loo4))
```
the fourth model is preferred as it has the lowest value of the LOO Information Criterion (looic). 


The pp_check function generates a variety of plots comparing the observed outcome y to simulated datasets yrep from the posterior predictive distribution using the same observations of the predictors X as we used to fit the model. If the model is a good fit to the data we should be able to generate data yrep from the posterior predictive distribution that looks a lot like the observed data y. 
```{r}
pp_check(post4, plotfun = "hist", nreps = 5)
```

posterior_predict to generate predictions of the outcome kid_score for a range of different values of mom_iq and for both subpopulations defined by mom_hs.
```{r}
IQ_SEQ <- seq(from = 75, to = 135, by = 5)
y_nohs <- posterior_predict(post4, newdata = data.frame(mom_hs = 0, mom_iq = IQ_SEQ))
y_hs <- posterior_predict(post4, newdata = data.frame(mom_hs = 1, mom_iq = IQ_SEQ))
dim(y_hs)
```
We now have two matrices, y_nohs and y_hs. Each matrix has as many columns as there are values of IQ_SEQ and as many rows as the size of the posterior sample. One way to show the predictors is to plot the predictions for the two groups of kids side by side:

```{r}
par(mfrow = c(1:2), mar = c(5,4,2,1))
boxplot(y_hs, axes = FALSE, outline = FALSE, ylim = c(10,170),
        xlab = "Mom IQ", ylab = "Predicted Kid IQ", main = "Mom HS")
axis(1, at = 1:ncol(y_hs), labels = IQ_SEQ, las = 3)
axis(2, las = 1)
boxplot(y_nohs, outline = FALSE, col = "red", axes = FALSE, ylim = c(10,170),
        xlab = "Mom IQ", ylab = NULL, main = "Mom No HS")
axis(1, at = 1:ncol(y_hs), labels = IQ_SEQ, las = 3)
```

