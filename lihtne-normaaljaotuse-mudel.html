<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Bayesi statistika kasutades R keelt" />
<meta property="og:type" content="book" />

<meta property="og:image" content="img/cyclo.png" />
<meta property="og:description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs R keeles’ Bayesi statistika materjalid." />
<meta name="github-repo" content="rstats-tartu/bayesiraamat" />

<meta name="author" content="Taavi Päll" />
<meta name="author" content="Ülo Maiväli" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs R keeles’ Bayesi statistika materjalid.">

<title>Bayesi statistika kasutades R keelt</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>

<script src="https://use.fontawesome.com/e4ba4259a1.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#saateks">Saateks</a></li>
<li class="part"><span><b>I OSA</b></span></li>
<li class="has-sub"><a href="1-sissejuhatus-maailm-teooria-ja-mudel.html#sissejuhatus-maailm-teooria-ja-mudel"><span class="toc-section-number">1</span> Sissejuhatus: maailm, teooria ja mudel</a><ul>
<li><a href="suur-ja-vaike-maailm.html#suur-ja-vaike-maailm">Suur ja väike maailm</a></li>
<li><a href="mudeli-vaike-maailm.html#mudeli-vaike-maailm">Mudeli väike maailm</a></li>
</ul></li>
<li class="has-sub"><a href="2-lineaarsed-mudelid.html#lineaarsed-mudelid"><span class="toc-section-number">2</span> Lineaarsed mudelid</a><ul>
<li><a href="ennustus-lineaarsest-mudelist.html#ennustus-lineaarsest-mudelist">Ennustus lineaarsest mudelist</a></li>
<li><a href="neli-moistet.html#neli-moistet">Neli mõistet</a></li>
<li><a href="mudeli-fittimine.html#mudeli-fittimine">Mudeli fittimine</a></li>
<li><a href="ule-ja-alafittimine.html#ule--ja-alafittimine">Üle- ja alafittimine</a></li>
</ul></li>
<li class="has-sub"><a href="3-kaks-lineaarse-mudeli-laiendust.html#kaks-lineaarse-mudeli-laiendust"><span class="toc-section-number">3</span> Kaks lineaarse mudeli laiendust</a><ul>
<li><a href="mitme-soltumatu-prediktoriga-mudel.html#mitme-soltumatu-prediktoriga-mudel">Mitme sõltumatu prediktoriga mudel</a></li>
<li><a href="interaktsioonimudel.html#interaktsioonimudel">Interaktsioonimudel</a></li>
<li class="has-sub"><a href="veamudel.html#veamudel">Veamudel</a><ul>
<li><a href="veamudel.html#enimkasutatud-veamudel-on-normaaljaotus">Enimkasutatud veamudel on normaaljaotus</a></li>
<li><a href="veamudel.html#normaaljaotuse-mudel-vaikestel-valimitel">Normaaljaotuse mudel väikestel valimitel</a></li>
<li><a href="veamudel.html#normaaljaotuse-ja-lognormaaljaotuse-erilisus">Normaaljaotuse ja lognormaaljaotuse erilisus</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-kusimused-mida-statistika-kusib.html#kusimused-mida-statistika-kusib"><span class="toc-section-number">4</span> Küsimused, mida statistika küsib</a><ul>
<li><a href="jata-meelde.html#jata-meelde">Jäta meelde</a></li>
</ul></li>
<li class="has-sub"><a href="5-kuidas-naevad-valja-teie-andmed.html#kuidas-naevad-valja-teie-andmed"><span class="toc-section-number">5</span> Kuidas näevad välja teie andmed</a><ul>
<li><a href="summaarsed-statistikud.html#summaarsed-statistikud">Summaarsed statistikud</a></li>
<li><a href="keskvaartused.html#keskvaartused">Keskväärtused</a></li>
<li><a href="muutuja-sisene-varieeruvus.html#muutuja-sisene-varieeruvus">Muutuja sisene varieeruvus</a></li>
<li><a href="logaritmi-andmed.html#logaritmi-andmed">Logaritmi andmed</a></li>
<li><a href="iseloomusta-andmeid-algses-skaalas-mediaan-mad.html#iseloomusta-andmeid-algses-skaalas-mediaan-mad">Iseloomusta andmeid algses skaalas: mediaan (MAD)</a></li>
<li><a href="muutujate-koosvarieeruvus.html#muutujate-koosvarieeruvus">Muutujate koosvarieeruvus</a></li>
</ul></li>
<li class="has-sub"><a href="6-eda-eksploratoorne-andmeanaluus.html#eda-eksploratoorne-andmeanaluus"><span class="toc-section-number">6</span> EDA — eksploratoorne andmeanalüüs</a><ul>
<li><a href="6-1-eda-kokkuvote.html#eda-kokkuvote"><span class="toc-section-number">6.1</span> EDA kokkuvõte</a></li>
</ul></li>
<li class="has-sub"><a href="7-jareldav-statistika.html#jareldav-statistika"><span class="toc-section-number">7</span> Järeldav statistika</a><ul>
<li class="has-sub"><a href="jareldav-statistika-on-toenaosusteooria-kaepikendus.html#jareldav-statistika-on-toenaosusteooria-kaepikendus">Järeldav statistika on tõenäosusteooria käepikendus</a><ul>
<li><a href="jareldav-statistika-on-toenaosusteooria-kaepikendus.html#formaalsed-tuletised-toenaosusteooria-aksioomidest">Formaalsed tuletised tõenäosusteooria aksioomidest</a></li>
<li><a href="jareldav-statistika-on-toenaosusteooria-kaepikendus.html#naited-toenaosusteooria-tuletiste-rakendamisest">Näited tõenäosusteooria tuletiste rakendamisest</a></li>
<li><a href="jareldav-statistika-on-toenaosusteooria-kaepikendus.html#toenaosuse-tolgendus">Tõenäosuse tõlgendus</a></li>
<li><a href="jareldav-statistika-on-toenaosusteooria-kaepikendus.html#toenaosusteooriast-tulenevad-statistika-pohiprintsiibid">Tõenäosusteooriast tulenevad statistika põhiprintsiibid</a></li>
</ul></li>
<li><a href="andmed-ei-ole-sama-mis-tegelikkus.html#andmed-ei-ole-sama-mis-tegelikkus">Andmed ei ole sama, mis tegelikkus</a></li>
</ul></li>
<li class="part"><span><b>II OSA</b></span></li>
<li class="has-sub"><a href="8-bootstrappimine.html#bootstrappimine"><span class="toc-section-number">8</span> Bootstrappimine</a><ul>
<li><a href="veidi-keerulisem-bootstrap.html#veidi-keerulisem-bootstrap">Veidi keerulisem bootstrap</a></li>
<li><a href="bayesboot.html#bayesboot">bayesboot()</a></li>
<li><a href="parameetriline-bootstrap.html#parameetriline-bootstrap">Parameetriline bootstrap</a></li>
<li><a href="bootstrappimine-ei-ole-kogu-tode.html#bootstrappimine-ei-ole-kogu-tode">Bootstrappimine ei ole kogu tõde</a></li>
</ul></li>
<li class="has-sub"><a href="9-bayesi-pohimote.html#bayesi-pohimote"><span class="toc-section-number">9</span> Bayesi põhimõte</a><ul>
<li><a href="esimene-naide.html#esimene-naide">Esimene näide</a></li>
<li><a href="teine-naide-sonastame-oma-probleemi-umber.html#teine-naide-sonastame-oma-probleemi-umber">Teine näide: sõnastame oma probleemi ümber</a></li>
<li><a href="kui-n-1.html#kui-n-1">Kui n = 1</a></li>
</ul></li>
<li class="has-sub"><a href="10-mudelite-keel.html#mudelite-keel"><span class="toc-section-number">10</span> Mudelite keel</a><ul>
<li><a href="beta-prior.html#beta-prior">Beta prior</a></li>
<li><a href="prioritest-uldiselt.html#prioritest-uldiselt">Prioritest üldiselt</a></li>
</ul></li>
<li class="has-sub"><a href="ennustame-pidevat-suurust.html#ennustame-pidevat-suurust">Ennustame pidevat suurust</a><ul>
<li class="has-sub"><a href="lihtne-normaaljaotuse-mudel.html#lihtne-normaaljaotuse-mudel">Lihtne normaaljaotuse mudel</a><ul>
<li><a href="lihtne-normaaljaotuse-mudel.html#kui-lai-on-meie-toeparafunktsioon">Kui lai on meie tõepärafunktsioon?</a></li>
<li><a href="lihtne-normaaljaotuse-mudel.html#lihtne-voi-robustne-normaalne-mudel">Lihtne või robustne normaalne mudel?</a></li>
<li><a href="lihtne-normaaljaotuse-mudel.html#mcmc-ahelate-kvaliteet">MCMC ahelate kvaliteet</a></li>
<li><a href="lihtne-normaaljaotuse-mudel.html#naide-usa-presidentide-keskmine-pikkus">Näide: USA presidentide keskmine pikkus</a></li>
</ul></li>
<li><a href="lineaarne-regressioon.html#lineaarne-regressioon">Lineaarne regressioon</a></li>
<li><a href="lm-vahimruutude-meetodiga-fititud-lineaarsed-mudelid.html#lm---vahimruutude-meetodiga-fititud-lineaarsed-mudelid"><code>lm()</code> - vähimruutude meetodiga fititud lineaarsed mudelid</a></li>
<li><a href="bayesi-meetodil-lineaarse-mudeli-fittimine.html#bayesi-meetodil-lineaarse-mudeli-fittimine">Bayesi meetodil lineaarse mudeli fittimine</a></li>
<li class="has-sub"><a href="ennustused-mudelist.html#ennustused-mudelist">Ennustused mudelist</a><ul>
<li><a href="ennustused-mudelist.html#lognormaalne-toeparamudel">Lognormaalne tõepäramudel</a></li>
</ul></li>
<li class="has-sub"><a href="mitme-prediktoriga-lineaarne-regressioon.html#mitme-prediktoriga-lineaarne-regressioon">Mitme prediktoriga lineaarne regressioon</a><ul>
<li><a href="mitme-prediktoriga-lineaarne-regressioon.html#mudeldamine-standardiseeritud-andmetega">Mudeldamine standardiseeritud andmetega</a></li>
</ul></li>
<li class="has-sub"><a href="keerulisemate-mudelitega-tootamine.html#keerulisemate-mudelitega-tootamine">Keerulisemate mudelitega töötamine</a><ul>
<li><a href="keerulisemate-mudelitega-tootamine.html#predictor-residual-plots">Predictor residual plots</a></li>
<li><a href="keerulisemate-mudelitega-tootamine.html#ennustavad-plotid">Ennustavad plotid</a></li>
<li><a href="keerulisemate-mudelitega-tootamine.html#posterior-prediction-plots">Posterior prediction plots</a></li>
<li><a href="keerulisemate-mudelitega-tootamine.html#interaktsioonid-prediktorite-vahel">Interaktsioonid prediktorite vahel</a></li>
<li><a href="keerulisemate-mudelitega-tootamine.html#interaktsioonid-pidevatele-tunnustele">Interaktsioonid pidevatele tunnustele</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="11-hierarhilised-mudelid.html#hierarhilised-mudelid"><span class="toc-section-number">11</span> Hierarhilised mudelid</a><ul>
<li><a href="shrinkage.html#shrinkage">Shrinkage</a></li>
<li><a href="anova-laadne-mudel.html#anova-laadne-mudel">ANOVA-laadne mudel</a></li>
<li><a href="vabad-interceptid-klassikalises-regressioonimudelis.html#vabad-interceptid-klassikalises-regressioonimudelis">Vabad interceptid klassikalises regressioonimudelis</a></li>
<li><a href="vabad-tousud-ja-interceptid.html#vabad-tousud-ja-interceptid">Vabad tõusud ja interceptid</a></li>
<li><a href="hierarhiline-mudel-pidevate-prediktoritega.html#hierarhiline-mudel-pidevate-prediktoritega">Hierarhiline mudel pidevate prediktoritega</a></li>
</ul></li>
<li class="appendix"><span><b>Lisa</b></span></li>
<li class="has-sub"><a href="A-bayesi-ja-sagedusliku-statistika-vordlus.html#bayesi-ja-sagedusliku-statistika-vordlus"><span class="toc-section-number">A</span> Bayesi ja sagedusliku statistika võrdlus</a><ul>
<li><a href="kaks-statistikat-ajaloost-ja-toenaosusest.html#kaks-statistikat-ajaloost-ja-toenaosusest">Kaks statistikat: ajaloost ja tõenäosusest</a></li>
<li><a href="poleemika-kumbki-toenaosus-pole-paris-see-mida-uldiselt-arvatakse.html#poleemika-kumbki-toenaosus-pole-paris-see-mida-uldiselt-arvatakse">Poleemika: kumbki tõenäosus pole päris see, mida üldiselt arvatakse</a></li>
<li class="has-sub"><a href="vordlev-naide-kahe-grupi-vordlus.html#vordlev-naide-kahe-grupi-vordlus">Võrdlev näide: kahe grupi võrdlus</a><ul>
<li><a href="vordlev-naide-kahe-grupi-vordlus.html#bayesiaan">Bayesiaan</a></li>
<li><a href="vordlev-naide-kahe-grupi-vordlus.html#sageduslik-statistik">Sageduslik statistik</a></li>
<li><a href="vordlev-naide-kahe-grupi-vordlus.html#tulemuste-tolgendamine">Tulemuste tõlgendamine</a></li>
</ul></li>
<li><a href="kahe-paradigma-erinevused.html#kahe-paradigma-erinevused">Kahe paradigma erinevused</a></li>
<li><a href="statistiline-ennustus-kui-mitmetasandiline-protsess.html#statistiline-ennustus-kui-mitmetasandiline-protsess">Statistiline ennustus kui mitmetasandiline protsess</a></li>
</ul></li>
<li><a href="B-sonastik.html#sonastik"><span class="toc-section-number">B</span> Sõnastik</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="lihtne-normaaljaotuse-mudel" class="section level2 unnumbered">
<h2>Lihtne normaaljaotuse mudel</h2>
<p>Kui me eelmises peatükis modelleerisime diskreetseid binaarseid sündmusi (elus või surnud) üle binoomjaotuse, siis edasi tegeleme pidevate suurustega ehk parameetritega, millele saab omistada iga väärtuse vahemikus -Inf kuni Inf.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(gridExtra)</code></pre></div>
<p>Proovime veelkord USA presidentide keskmist pikkust ennustada (sama näide oli bootstrappimisel). Selleks on meil on vaja kahte asja: (1) tõepära mudelit ning (2) igale tõepära mudeli parameetrile oma priorit.</p>
<p>Selline on täismudeli (tõepära ja priorid) struktuur:</p>
<pre><code>heights ~ dnorm(mu, sigma)  # normal likelihood
mu ~ dnorm(mean = 0, sd = 200) # normal prior for mean
sigma ~ dcauchy(0, 20) #half-cauchy prior for sd </code></pre>
<p>Tõepära on siin modeleeritud normaaljaotusena, milles on 2 tuunitavat parameetrit: mu (keskmine) ja sigma (standardhälve). Pelgalt nende kahe parameetri fikseerimine annab meile unikaalse normaaljaotuse. See, et keskmise pikkuse prior on tsentreeritud nullile viib õige pisukesele (nõnda laia priori juures küll pigem märkamatule) mu hinnangu nihkumisele nulli suunas. Selle nihke õigustus on püüd vältida mudeli üle-fittimist ehk teisisõnu ülespoole kallutatud hinnangut keskmisele pikkusele. Sama hästi võiksime kasutada ka priorit <code>mu ~ dnorm(mean = 178, sd = 10)</code>, kus 178 on ameerika meeste keskmine pikkus.</p>
<p>Alati tasub mudeli priorid välja plottida, et veenduda, et nad tõesti kajastavad meile taustateadmisi ja on sobivas parameetrivahemikus (bayesi programmide default priorid on sageli kas liiga laiad või vastupidi eeldavad, et parameetriväärtused jäävad alla 10 ühiku).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">100</span>
y &lt;-<span class="st"> </span><span class="kw">dcauchy</span>(x, <span class="dv">0</span>, <span class="dv">20</span>)
<span class="kw">plot</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span> , <span class="dt">main =</span> <span class="st">&quot;Cauchy prior for sd&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-3-1.png" alt="Cauchy prior" width="70%" />
<p class="caption">
Joonis .: Cauchy prior
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">150</span><span class="op">:</span><span class="dv">200</span>
y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">200</span>)
<span class="kw">plot</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Normal prior for mean = 0 and sd = 200&quot;</span>)
x &lt;-<span class="st"> </span><span class="dv">150</span><span class="op">:</span><span class="dv">200</span>
y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dv">178</span>, <span class="dv">10</span>)
<span class="kw">plot</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Normal prior for mean = 178 and sd = 10&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-4"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-4-1.png" alt="Kaks normaaljaotuse prior" width="48%" /><img src="11_pidev_files/figure-html/unnamed-chunk-4-2.png" alt="Kaks normaaljaotuse prior" width="48%" />
<p class="caption">
Joonis .: Kaks normaaljaotuse prior
</p>
</div>
<p>Siin on valida kahe priori vahel mu-le. Võib-olla eelistaksid sina mõnda kolmandat? Kui jah, siis pole muud kui tee valmis ja kasuta!</p>
<p>Sama hästi võiksime tõepära modelleerida ka mõne muu jaotusega (Studenti t jaotus, eksponentsiaalne jaotus, lognormaaljaotus jne). Sel juhul oleksid meil erinevad parameetrid, mida tuunida, aga põhimõte on sama. Bayes on modulaarne — kui sa põhimõtet tead, pole tehniliselt suurt vahet, millist mudelit soovid kasutada.</p>
<p>Näiteks:</p>
<pre><code>heights ~ student_t(nu, mu, sigma) # t likelihood
nu ~ dunif(1, 100) # uniform prior for the shape parameter
mu ~ dnorm(mean = 0, sd = 200) # normal prior for mean
sigma ~ dcauchy(0, 20) # half-cauchy prior for sd</code></pre>
<p>Normaaljaotusel on kaks parameetrit, millele posteerior arvutada: mu (mean) ja sigma (sd). Seega on vaja ka kahte priorit, üks mu-le ja teine sigma-le. Studenti t jaotuse korral lisandub veel üks parameeter: nu ehk jaotuse kuju määrav parameeter. nu-d saab tuunida 1 ja lõpmatuse vahel. Mida väiksem on nu, seda paksemad tulevad jaotuse sabad. Kui nu on suur, siis on t jaotuse kuju sama, mis normaaljaotusel. Siin andsime nu-le tasase priori 1 ja 100 vahel, hiljem proovime ka teisi prioreid nu-le.</p>
<p>Studenti t jaotus on põnev alternatiiv normaaljaotusele, sest see on vähem tundlik outlieritele. Kuna normaaljaotus langeb servades väga kiiresti siis, kui meil on mõni andmepunkt, mis jääb jaotuse tipust kaugele, on ainus võimalus selle punkti normaaljaotuse alla mahutamiseks omistada jaotusele väga suur standardhälve. See muudab outlierit sisaldava normaaljaotuse ülemäära laiaks, mis viib analüüsis asjatult kaotatud efektidele. Seevastu t jaotuse sabasid saab nu abil üles-alla liigutada vastavalt sellele, kas andmed sisaldavad outliereid (selleks tuleb lihtsalt fittida nu parameeter andmete põhjal).</p>
<p>Outlierid toovad meile paksema sabaga jaotuse, mis tipu ümber ei lähe aga kaugeltki nii laiaks, kui samade andmetega fititud normaaljaotus.</p>
<div id="kui-lai-on-meie-toeparafunktsioon" class="section level3 unnumbered">
<h3>Kui lai on meie tõepärafunktsioon?</h3>
<p>Normaaljaotusega modelleeritud tõepärafunktsioon on normaaljaotus, mille <code>keskväärtus = mean(valim)</code> ja mille <code>standardhälve = sd(valim) / sqrt(N)</code>, kus N on valimi suurus. See tõepärafunktsioon modelleerib meie valimi keskväärtuse kohtamise tõenäosust igal võimalikul parameetriväärtusel. Kui oleme huvitatud USA presidentide keskmisest pikkusest, siis tõepärafunktsioon ütleb iga võimaliku pikkuse kohta, millise tõenäosusega kohtaksime oma valimi keskväärtust juhul, kui just see oleks tegelik presidentide keskmine pikkus. Sigma, mille posteeriori me mudelist arvutame, on aga standardhälve algsete andmepunktide tasemel. See on väga oluline eristus, sest sigma kaudu saab simueerida uusi andmepunkte.</p>
</div>
<div id="lihtne-voi-robustne-normaalne-mudel" class="section level3 unnumbered">
<h3>Lihtne või robustne normaalne mudel?</h3>
<p>Proovime mudeldada simuleeritud andmete keskväärtust.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">890775</span>)
a &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">20</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="co"># expected mean = 0, sd = 1</span>
b &lt;-<span class="st"> </span><span class="kw">c</span>(a, <span class="dv">5</span>, <span class="dv">9</span>) <span class="co"># plus 2 outliers</span></code></pre></div>
<p>Siin kasutame andmeid, mille keskväärtus on 0.38 ja sd = 1 ja millele on lisatud kaks outlierit (5 ja 9). Proovime neid andmeid mudeldada normaaljaotusega tõepäramudeliga ja seejärel üle studenti t jaotuse. Me fitime 4 mudelit, neist 3 koos outlieritega. Mudeli fittimine käib nii, et mcmc ahelad sammuvad parameetriruumis ja iga samm annab meile ühe juhusliku väärtuse posteeriorist. Defaultina on meil üks ahel, mis teeb 1000 sammu (seda saab muuta: vt <code>?map2stan</code>). Kuna ahelad veedavad rohkem aega seal, kus posterioorne tõenäosuspilv on tihedam, siis saab nõnda sämplitud posteeriori juhuvalimi histogrammist posterioorse jaotuse kuju. Veelgi enam, selle asemel, et tegeleda posterioorsete jaotuste matemaatilise analüüsiga (integreerimisega) võime analüüsida oma mcmc sämpleid otse, mis tähendab, et kõrgema matemaatika asemel vajame 2. klassi aritmeetikat.</p>
<p>Kõigepealt ilma outlieriteta mudel normaalse tõepärafuktsiooniga. Me kasutame sd priorina pool-Cauchy jaotust, mille tipp on 0 kohal ja millel on piisavalt paks saba suuremate numbrite poole. See on väheinformatiivne prior, mis on nähtud sd-de puhul mcmc algoritmides hästi töötavat. Andmed võime <code>map2stan()</code> funktsiooni sisestada nii listina kui data.frame-na (aga mitte tibble kujul).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Ilma outlierita andmed</span>
m0 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    y <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),  <span class="co"># normal likelihood</span>
    mu <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="co"># normal prior for mean</span>
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>) <span class="co"># half-cauchy prior from sd </span>
  ),
  <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> a))</code></pre></div>
<p>Sama mudel, aga outlieritega andmed. <code>map2stan()</code> tõlgib sisestatud mudeli Stan keelde ja see mudel kompileeritakse C++ keelde, milles on kodeeritud Stani mcmc mootor. Kuna kompileerimine on ajakulukas, kasutame m1 fittimiseks rstan raamatukogu (see loetakse sisse rethinkingu depency-na) ja juba komplieeritud m0 mudelit, millele lisame andmed kahe elemendina: N annab andmete arvu ja y tegelikud andmeväärtused. Selline andmete sisestamise viis on omane Stanile - <code>map2stan()</code> arvutab ise kapoti all N-i.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">stan</span>(<span class="dt">fit =</span> m0<span class="op">@</span>stanfit,
           <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">length</span>(b), 
                       <span class="dt">y =</span> b),
           <span class="dt">chains =</span> <span class="dv">4</span>)</code></pre></div>
<p>Nüüd studenti t jaotusega tõepäramudel. Argumendid cores = 4, chains = 4 tähendavad, et me jooksutame 4 mcmc ahelat kasutades selleks oma arvuti 4 tuuma. Mudeli m2 juures tähendab argument constraints(list(nu = “lower=1”)), et mcmc sämpleri ahelad ei lähe kunagi allapoole ühte. See on siin kuna definitsiooni kohaselt ei saa nu olla väiksem kui 1. Argument start annab listi, mis annab iga parameetri jaoks väärtuse, millest mcmc ahel posteeriori sämplimist alustab. See on vahest vajalik, sest kui mcmc ahelad hakkavad posteeriori tõenäosuspilve otsima kaugel selle tegelikust asukohast n-mõõtmelises ruumis (n = mudeli parameetrite arv), siis võib juhtuda, et mudeli fittimine ebaõnnestub ja te saate veateate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    y <span class="op">~</span><span class="st"> </span><span class="kw">student_t</span>(nu, mu, sigma),
    nu <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">5</span>, <span class="dv">10</span>), 
    mu <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">5</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>)
    ),
  <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> b),
  <span class="dt">constraints =</span> <span class="kw">list</span>(<span class="dt">nu =</span> <span class="st">&quot;lower=1&quot;</span>),
  <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">mu =</span> <span class="kw">mean</span>(b), <span class="dt">sigma =</span> <span class="kw">sd</span>(b), <span class="dt">nu =</span> <span class="dv">10</span>),
  <span class="dt">cores =</span> <span class="dv">4</span>,
  <span class="dt">chains =</span> <span class="dv">4</span>
)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&quot;data/stan_m2.rds&quot;</span>)
m2<span class="op">@</span>stanfit
<span class="co">#&gt; Inference for Stan model: y ~ student_t(nu, mu, sigma).</span>
<span class="co">#&gt; 4 chains, each with iter=2000; warmup=1000; thin=1; </span>
<span class="co">#&gt; post-warmup draws per chain=1000, total post-warmup draws=4000.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;         mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat</span>
<span class="co">#&gt; mu      0.28    0.00 0.22  -0.11   0.14   0.27   0.41   0.76  2066    1</span>
<span class="co">#&gt; sigma   0.78    0.01 0.27   0.39   0.59   0.74   0.92   1.40  1254    1</span>
<span class="co">#&gt; nu      2.21    0.04 1.48   1.04   1.39   1.84   2.53   5.57  1644    1</span>
<span class="co">#&gt; dev    78.68    0.10 3.35  74.84  76.19  77.81  80.25  87.47  1057    1</span>
<span class="co">#&gt; lp__  -27.23    0.04 1.45 -31.06 -27.86 -26.88 -26.16 -25.55  1323    1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Samples were drawn using NUTS(diag_e) at Mon Oct 23 15:51:33 2017.</span>
<span class="co">#&gt; For each parameter, n_eff is a crude measure of effective sample size,</span>
<span class="co">#&gt; and Rhat is the potential scale reduction factor on split chains (at </span>
<span class="co">#&gt; convergence, Rhat=1).</span></code></pre></div>
<p>Ja viimasena studenti t mudel, kus nu on fikseeritud konstandina. Kuna me ei fiti nu-d mudeli parameetrina, pole meil vaja ka priorit nu-le. Me teeme selle mudeli, sest nu täpsel väärtusel pole väga suurt mõju tulemustele. Me lihtsalt fikseerime nu suvalisele väärtusele, mis annab t jaotusele piisavalt paksud sabad.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    y <span class="op">~</span><span class="st"> </span><span class="kw">student_t</span>(<span class="dv">4</span>, mu, sigma),
    mu <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">5</span>),
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>)
  ),
  <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> b),
  <span class="dt">constraints =</span> <span class="kw">list</span>(<span class="dt">nu =</span> <span class="st">&quot;lower=1&quot;</span>),
  <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">mu =</span> <span class="kw">mean</span>(b), <span class="dt">sigma =</span> <span class="kw">sd</span>(b)),
  <span class="dt">cores =</span> <span class="dv">4</span>,
  <span class="dt">chains =</span> <span class="dv">4</span>)</code></pre></div>
<p>Üks esimesi asju mida koos parameetrite vaatamisega teha on lisaks vaadata, kas ka ahelad konvergeerusid. Selleks saab mugavalt kasutada <code>rethinking::tracerplot()</code> funktsiooni.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tracerplot</span>(m2)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-14"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-14-1.png" alt="Traceplot markovi ahelate inspekteerimiseks" width="70%" />
<p class="caption">
Joonis 2.11: Traceplot markovi ahelate inspekteerimiseks
</p>
</div>
<p>Pildilt on näha, et neli ahelat (4 värvi) on hästi konvergeerunud. Hall ala on nn warmup ala, mille tulemusi ei salvestata. Muidu astub iga ahel sammu kaupa ja iga edukas samm salvestatakse ühe posteeriori väärtusena. Ahel sämplib korraga mu, sigma ja nu väärtusi n-mõõtmelises ruumis (n = mudeli parameetrite arv), mis tähendab, et ahela iga samm salvestatakse n kõrvuti numbrina.</p>
<p>Kui näit sigma kõrgema väärtusega kaasneb keskeltäbi kõrgem (või madalam) mu väärtus, on sigma ja mu omavahel korreleeritud. Et kontrollida parameetrite posterioorsete väärtuste korrelatsioone kasutame funktsiooni <code>rethinking::pairs()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairs</span>(m2)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-15"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-15-1.png" alt="korrelatsiooniplot mudeli parameetritele." width="70%" />
<p class="caption">
Joonis 2.5: korrelatsiooniplot mudeli parameetritele.
</p>
</div>
<p>Normaaljaotus on selle poolest eriline, et tema parameetrid mu ja sigma ei ole korreleeritud. Paljud teised mudelid ei ole nii lahked. Siin on meil mõõdukas korrelatsioon nu ja sigma vahel. See on igati loogiline ja ei häiri meid.</p>
</div>
<div id="mcmc-ahelate-kvaliteet" class="section level3 unnumbered">
<h3>MCMC ahelate kvaliteet</h3>
<p>Kui Rhat on 1, siis see tähendab, et MCMC ahelad on ilusti jooksnud ja posteeriori sämplinud. Kui Rhat &gt; 1.1, siis on probleem. Suur Rhat viitab, et ahel(ad) pole jõudnud konvergeeruda. Kui ahelad ei konvergeeru, siis võib karta, et nad ei sämpli ka sama posteeriori jaotust. Kontrolli, kas mudeli kood ei sisalda vigu. Kui ei, siis vahest aitab, kui pikendada warm-up perioodi (<code>map2stan(..., iter = 3000, warmup = 2000)</code> pikendab <em>default</em> warm-upi 2 korda). Vahest aitab mudeli re-parametriseerimine (siin on lihtne trikk tekitada priorid, mis ei erineks väga palju oma vahemiku poolest; sellega kaasneb sageli andmete tsentreerimine või standardiseerimine; vt allpool).</p>
<p>n_eff on efektiivne valimi suurus, mis hindab iseseisvalt sämplitud andmete arvu ning see ei tohi olla väga väike. Kui n_eff on palju väiksem kui jooksutatud markovi ahela pikkus (iga ahel on defaultina 1000 iteratsiooni pikk), on ahel jooksnud ebaefektiivselt. See ei tähenda tingimata, et posteerior vale oleks. Reegilina peaks Neff/N &gt; 0.1</p>
<p>Ahelad peavad plotitud kujul välja nägema nagu karvased tõugud, mis on ilma paljaste laikudeta. Kui ahelad omavad pikki sirgeid lõike (n_eff tuleb siis väga madal), kus ahel ei ole töötanud, siis see rikub korralikult posteeriori. Tüüpiliselt aitavad nõrgalt informatiivsed priorid — priorite õige valik on sama palju arvutuslik vajadus kui taustainfo lisamine. Igal juhul tuleb vältida aladefineeritud tasaseid prioreid, mis võimaldavad ahelatel sämplida lõpmatust ja sel viisil õige tee kaotada. Peale selle, tasased priorid, mis ütlevad, et kõik parameetri väärtused on võrdselt tõenäolised, kajastavad harva meie tegelikke taustateadmisi.</p>
<p>Halvad WARNING-ud: divergent transitions (too many), BMFI too low — võivad tähendada, et ahelad ei tööta korralikult. WARNING-ute kohta saad abi siit <a href="http://mc-stan.org/misc/warnings.html" class="uri">http://mc-stan.org/misc/warnings.html</a>.</p>
<p>Ilusamad parameetriplotid saab kasutades “bayesplot” raamatukogu funktsioone.</p>
<p>Esiteks usalduspiirid:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bayesplot)
fit2d &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(m2<span class="op">@</span>stanfit)
pars &lt;-<span class="st"> </span><span class="kw">names</span>(fit2d)

<span class="co"># inner interval = 50% CI and outer interval = 95% CI.</span>
<span class="kw">mcmc_intervals</span>(fit2d, 
               <span class="dt">pars =</span> pars[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], 
               <span class="dt">prob =</span> <span class="fl">0.5</span>, 
               <span class="dt">prob_outer =</span> <span class="fl">0.90</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-16"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-16-1.png" alt="Posteeriorite CI plot" width="70%" />
<p class="caption">
Joonis 2.12: Posteeriorite CI plot
</p>
</div>
<p>Ja teiseks täis posteeriorid.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_areas</span>(fit2d, <span class="dt">pars =</span> pars[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dt">prob =</span> <span class="fl">0.8</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-17-1.png" alt="Posteeriorite tihedusplot." width="70%" />
<p class="caption">
Joonis 2.6: Posteeriorite tihedusplot.
</p>
</div>
<p>Funktsiooniga <code>rethinking::extract.samples()</code> saame koos sämplitud parameetrite numbrid kõrvuti (rea kaupa) tabelisse.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2sampl &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(m2) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">CV =</span> sigma <span class="op">/</span><span class="st"> </span>mu)</code></pre></div>
<p>Sellest tabelist võib arvutada posteerioreid ka uutele “väljamõeldud” parameetritele. Näiteks arvutame posteeriori CV-le:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(m2sampl, <span class="kw">aes</span>(CV)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlim</span>(<span class="dv">0</span>, <span class="dv">10</span>)
<span class="co">#&gt; Warning: Ignoring unknown parameters: breaks</span>
<span class="co">#&gt; Warning: Removed 609 rows containing non-finite values (stat_density).</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-19"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-19-1.png" alt="Posteerior uuele parameetrile" width="70%" />
<p class="caption">
Joonis 10.1: Posteerior uuele parameetrile
</p>
</div>
<p>Kuna posteerior iseloomustab meie teadmiste piire, siis võime selle abil küsida, kui suure tõenäosusega jääb tõeline CV näiteks parameetrivahemikku 2 kuni 5?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">intv &lt;-<span class="st"> </span><span class="kw">filter</span>(m2sampl, <span class="kw">between</span>(CV, <span class="dv">2</span>, <span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nrow</span>(.) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(m2sampl)
intv
<span class="co">#&gt; [1] 0.415</span></code></pre></div>
<p>Vastus on, et me arvame 42 kindlusega, et tõde jääb kuskile sellesse vahemikku.</p>
<p>Võime ka küsida, millesesse vahemikku jääb näiteks 67% meie usust mu tõelise väärtuse kohta?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">HPDI</span>(m2sampl<span class="op">$</span>CV, <span class="dt">prob =</span> <span class="fl">0.67</span>)
<span class="co">#&gt; |0.67 0.67| </span>
<span class="co">#&gt; 0.964 4.058</span></code></pre></div>
<p>Nüüd võrdleme nelja fititud mudelit, et otsustada, milline mudel kirjeldab kõige paremini outlieritega andmeid. m0 on ilma outlierita mudel ja me tahame teada, milline mudel m1, m2 või m3 annab sellele kõige lähedasemad tulemused.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coeftab_plot</span>(<span class="kw">coeftab</span>(m0, m1, m2, m3), 
             <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>), 
             <span class="dt">prob =</span> <span class="fl">0.5</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-22"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-22-1.png" alt="Võrdlev plot mitme mudeli posteerioritele." width="70%" />
<p class="caption">
Joonis 10.2: Võrdlev plot mitme mudeli posteerioritele.
</p>
</div>
<p>Me sättisime usalduspiirid 0.5 peale, mis tähendab, et need ennustavad, kuhu peaks mudeli järgi jääma parameetri tegelik väärtus 50%-se tõenäosusega. Nagu näha, on m2 ja m3 posteeriorid palju lähemal m0-le kui normaaljaotusega fititud m1 oma. Eriti drastilised on erinevused sigma hinnangule. Lisaks, m1 mudeli mu usaldusintervall on palju laiem kui m0, m2 ja m3 oma — mudel nagu saaks aru, et andmed lõhnavad kala järgi.</p>
</div>
<div id="naide-usa-presidentide-keskmine-pikkus" class="section level3 unnumbered">
<h3>Näide: USA presidentide keskmine pikkus</h3>
<p>Läheme tagasi normaaljatuse ja USA presidentide juurde. Kõigepealt defineerime priorid. Alati on mõistlik priorid välja joonistada ja vaadata, kas nad vastavad meie ootustele. Pea meeles, et sigma ehk sd on samades ühikutes, mis mõõtmisandmed.</p>
<p>Kui sulle need priorid ei meeldi, tuuni priorite parameetreid ja proovi uuesti plottida.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">500</span><span class="op">:</span><span class="dv">500</span>
y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">200</span>)
<span class="kw">plot</span>(x, y, <span class="dt">main =</span> <span class="st">&quot;Prior for mu&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-23"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-23-1.png" alt="Prior keskmisele." width="70%" />
<p class="caption">
Joonis 10.3: Prior keskmisele.
</p>
</div>
<p>Siin kasutame nõrgalt informatiivseid prioreid. Idee on selles, et normaaljaotus, mis on tsentreeritud 0 ümber, tõmbab meie posteeriorit nõrgalt nulli poole (nõrgalt, sest jaotus on hästi lai võrreldes tõepärafunktsiooniga). Pane tähele, et oma priori kohaselt usume me, et 50% tõenäususega on USA presidentide keskmine pikkus negatiivne. See prior on tehniline abivahend, mitte meie tegelike uskumuste peegeldus presidentide kohta. Aga tehniliselt kõik töötab selles mõttes, et andmed domineerivad posteeriori üle ja priori sisuliselt ainus ülesanne on veidi MCMC mootori tööd lihtsustada.</p>
<p>Sigma priorina kasutame half-Cauchy jaotust, mis on samuti väheinformatiivne. Half-Cauchy ei saa olla &lt; 0 ja on meile soodsa kujuga sest annab suurema tõenäosuse nullile lähemal asuvatele sd-väärtustele — aga samas, kuna ta on paksu sabaga, ei välista see ka päris suuri sd väärtusi.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">200</span>
y &lt;-<span class="st"> </span><span class="kw">dcauchy</span>(x , <span class="dv">0</span>, <span class="dv">10</span>)
<span class="kw">plot</span>(x, y, <span class="dt">main =</span> <span class="st">&quot;Prior for sigma&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-24"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-24-1.png" alt="Prior SD-le" width="70%" />
<p class="caption">
Joonis 10.4: Prior SD-le
</p>
</div>
<p>Tekitame andmeraami analüüsiks ja mudeli, mis põhineb normaalsel tõepärafunktsioonil.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">heights &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">183</span>, <span class="dv">192</span>, <span class="dv">182</span>, <span class="dv">183</span>, <span class="dv">177</span>, <span class="dv">185</span>, <span class="dv">188</span>, <span class="dv">188</span>, <span class="dv">182</span>, <span class="dv">185</span>)
us_presidents &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">Height =</span> heights, <span class="dt">id =</span> <span class="st">&quot;usa&quot;</span>)
potusm1 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    Height <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), <span class="co"># normal likelihood</span>
    mu <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">200</span>), <span class="co"># normal prior for mean</span>
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># half-cauchy prior from sd </span>
  ), <span class="dt">data =</span> us_presidents
)</code></pre></div>
<p>Mudeli koefitsiendid:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(potusm1)
<span class="co">#&gt;        Mean StdDev lower 0.89 upper 0.89 n_eff Rhat</span>
<span class="co">#&gt; mu    184.5    1.5     181.90     186.71   482    1</span>
<span class="co">#&gt; sigma   4.7    1.3       2.87       6.36   471    1</span></code></pre></div>
<p>Nüüd teeme katse võrrelda USA presidentide ja Euroopa ning mujalt pärit riigijuhtide keskmisi pikkusi. Kõigepealt loome analüüsitava andmeraami.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">world_leaders &lt;-<span class="st"> </span><span class="kw">read_csv2</span>(<span class="st">&quot;data/world_leaders.csv&quot;</span>)
presidents &lt;-<span class="st"> </span>world_leaders <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Country, Height) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(us_presidents)
knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">head</span>(presidents))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Country</th>
<th align="right">Height</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Canada</td>
<td align="right">188</td>
</tr>
<tr class="even">
<td align="left">Cuba</td>
<td align="right">190</td>
</tr>
<tr class="odd">
<td align="left">France</td>
<td align="right">170</td>
</tr>
<tr class="even">
<td align="left">France</td>
<td align="right">165</td>
</tr>
<tr class="odd">
<td align="left">France</td>
<td align="right">189</td>
</tr>
<tr class="even">
<td align="left">France</td>
<td align="right">172</td>
</tr>
</tbody>
</table>
<p>Ja siin on mudel. Nüüd on mu ümber defineeritud kui mu1[indeks], mis tähendab, et mu1 saab kaks hulka väärtusi, üks kummagil indeks muutuja tasemel. Sellega jagame oma andmed kahte ossa (USA versus Euroopa ja muu maailm), mida analüüsime eraldi. Sigma on mõlemale kontinendile sama, mis tähendab, et mudel eeldab, et presidentide pikkuste jaotus on mõlemal kontinendil identne.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Split into 2 groups</span>
presidents &lt;-<span class="st"> </span>presidents <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Groups =</span> <span class="kw">case_when</span>(
    Country <span class="op">==</span><span class="st"> &quot;USA&quot;</span> <span class="op">~</span><span class="st"> &quot;USA&quot;</span>,
    Country <span class="op">!=</span><span class="st"> &quot;USA&quot;</span> <span class="op">~</span><span class="st"> &quot;World&quot;</span>
  ))</code></pre></div>
<p>Adult human height varies country-by-country, we take 170 cm as relatively safe prior for male height.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">potusm2 &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    Height <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),
    mu &lt;-<span class="st"> </span>mu_<span class="dv">1</span>[Groups], <span class="co"># mu is redifined as mu_1, which takes values at each indeks level</span>
    mu_<span class="dv">1</span>[Groups] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">170</span>, <span class="dv">10</span>), <span class="co"># normal prior for mean</span>
    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># half-cauchy prior from sd </span>
  ),
  <span class="dt">data =</span> presidents)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(potusm2, <span class="dt">depth =</span> <span class="dv">2</span>)
<span class="co">#&gt;          Mean StdDev lower 0.89 upper 0.89 n_eff Rhat</span>
<span class="co">#&gt; mu_1[1] 182.8   3.57     177.11      188.2   885    1</span>
<span class="co">#&gt; mu_1[2] 176.3   1.85     173.33      179.2   836    1</span>
<span class="co">#&gt; sigma    11.7   1.26       9.86       13.8   628    1</span></code></pre></div>
<p>Me võime ka vaadata 2 grupi standardhälbeid lahus. Järgnevas mudelis on mõistlik ahelale stardipositsioon ette anda.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Calculate start values
startvalues &lt;-<span class="st"> </span>presidents <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Groups) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_at</span>(<span class="kw">vars</span>(Height), <span class="kw">funs</span>(mean, sd))
## Fit model
potusm2.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">map2stan</span>(
  <span class="kw">alist</span>(
    Height <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma),
    mu &lt;-<span class="st"> </span>mu_<span class="dv">1</span>[Groups],
    sigma &lt;-<span class="st"> </span>sigma_<span class="dv">1</span>[Groups],
    mu_<span class="dv">1</span>[Groups] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">170</span>, <span class="dv">10</span>), <span class="co"># normal prior for mean</span>
    sigma_<span class="dv">1</span>[Groups] <span class="op">~</span><span class="st"> </span><span class="kw">dcauchy</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># half-cauchy prior from sd </span>
  ),
  <span class="dt">data =</span> presidents, 
  <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">mu_1 =</span> startvalues<span class="op">$</span>mean,
               <span class="dt">sigma_1 =</span> startvalues<span class="op">$</span>sd)
)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tracerplot</span>(potusm2.<span class="dv">1</span>, <span class="dt">n_cols =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-35"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-35-1.png" alt="Traceplot." width="70%" />
<p class="caption">
Joonis 10.5: Traceplot.
</p>
</div>
<p>Tulemus ES-i osas tuleb üsna sarnane.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">coeftab</span>(potusm2, potusm2.<span class="dv">1</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-36"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-36-1.png" alt="mudelite võrdlusplot." width="70%" />
<p class="caption">
Joonis 10.6: mudelite võrdlusplot.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">precis</span>(potusm2, <span class="dt">depth =</span> <span class="dv">2</span>)
<span class="co">#&gt;          Mean StdDev lower 0.89 upper 0.89 n_eff Rhat</span>
<span class="co">#&gt; mu_1[1] 182.8   3.57     177.11      188.2   885    1</span>
<span class="co">#&gt; mu_1[2] 176.3   1.85     173.33      179.2   836    1</span>
<span class="co">#&gt; sigma    11.7   1.26       9.86       13.8   628    1</span></code></pre></div>
<p>Siin tuleb kasulik trikk: me lahutame rea kaupa mu1[1] posteeriori sampli liikmed mu1[2] sampli liikmetest. Nii saame posteeriori efekti suurusele ehk hinnangu sellele, mitme cm võrra on USA presidendid keskmiselt pikemad kui Euroopa omad!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samplespm2 &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(potusm2) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ES =</span> mu_<span class="fl">1.1</span> <span class="op">-</span><span class="st"> </span>mu_<span class="fl">1.2</span>)
<span class="kw">dens</span>(samplespm2<span class="op">$</span>ES)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-38"></span>
<img src="11_pidev_files/figure-html/unnamed-chunk-38-1.png" alt="Posteerior ES-le." width="70%" />
<p class="caption">
Joonis 10.7: Posteerior ES-le.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">median</span>(samplespm2<span class="op">$</span>ES)
<span class="co">#&gt; [1] 6.56</span>
rethinking<span class="op">::</span><span class="kw">HPDI</span>(samplespm2<span class="op">$</span>ES, <span class="dt">prob =</span> <span class="fl">0.9</span>)
<span class="co">#&gt;  |0.9  0.9| </span>
<span class="co">#&gt; -1.09 12.02</span>
<span class="kw">mean</span>(samplespm2<span class="op">$</span>ES <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.065</span></code></pre></div>
<p>Võrdse SD-ga mudeli järgi on USA presidendid keskeltläbi 6.6 cm pikemad, ebakindlus selle hinnangu ümber on suur – 90% HDI on -1.1 kuni 12 ja tõenäosus et pikkuste erinevus on väiksem kui 0 on 0.06.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samplesm2.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(potusm2.<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ES =</span> mu_<span class="fl">1.1</span> <span class="op">-</span><span class="st"> </span>mu_<span class="fl">1.2</span>)
<span class="kw">median</span>(samplesm2.<span class="dv">1</span><span class="op">$</span>ES)
<span class="co">#&gt; [1] 7.54</span>
<span class="kw">HPDI</span>(samplesm2.<span class="dv">1</span><span class="op">$</span>ES, <span class="dt">prob =</span> <span class="fl">0.9</span>)
<span class="co">#&gt;  |0.9  0.9| </span>
<span class="co">#&gt;  3.39 12.16</span>
<span class="kw">mean</span>(samplesm2.<span class="dv">1</span><span class="op">$</span>ES <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)
<span class="co">#&gt; [1] 0.001</span></code></pre></div>
<p>Erineva SD-ga mudeli järgi on riigijuhtide pikkuste vahe 7.5 cm, ebakindlus väiksem – 90% HDI on 3.4 kuni 12.2 ja tõenäosus et pikkuste erinevus on väiksem kui 0 on 0.</p>
<p>See ei tähenda tingimata, et me peaksime eelistama teist mudelit. Oluline on, mida me teoreetiliselt usume, kas seda, et tegelik presidentide varieeruvus on USAs ja Euroopas võrdne, või mitte.</p>
</div>
</div>
<p style="text-align: center;">
<a href="ennustame-pidevat-suurust.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/rstats-tartu/lectures/edit/master/11_pidev.Rmd"><button class="btn btn-default">Editeeri</button></a>
<a href="lineaarne-regressioon.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
